{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117171,"databundleVersionId":14089262,"sourceType":"competition"},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256},{"sourceId":166355,"sourceType":"modelInstanceVersion","modelInstanceId":141552,"modelId":164048}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":881.724544,"end_time":"2025-10-13T08:26:55.016349","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-13T08:12:13.291805","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\nTarget: 0.99+ CV AUC by implementing L2 Stacking, improved\nfeature engineering, and tuned hyperparameters.\n\nv3: ANTI-OVERFITTING VERSION\n- Drastically reduced TF-IDF features to combat overfitting.\n- Simplified L1 stack to only LGBM + CatBoost (removed noisy models).\n- Changed to 5-Folds for a more stable validation set.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\nimport warnings\n\n# Suppress all warnings for a cleaner output\nwarnings.filterwarnings('ignore')\n\nprint(\"All libraries imported successfully!\")\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR\n# -------------------------------------------------------------------\n\nclass ChampionFeatureExtractor:\n    \"\"\"\n    Feature Extractor focused on high-impact, proven features\n    for AI text detection.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes lists of keywords proven to be effective.\"\"\"\n        \n        # Words and phrases commonly overused by AI\n        self.ai_connectors = [\n            'in conclusion', 'in summary', 'furthermore', 'moreover', \n            'additionally', 'however', 'therefore', 'thus', 'consequently',\n            'as a result', 'on the other hand', 'for instance', 'for example',\n            'it is important to note', 'it is worth noting', 'that being said'\n        ]\n        \n        # Formal or \"business-speak\" words often preferred by AI\n        self.formal_words = [\n            'utilize', 'facilitate', 'implement', 'methodology', 'paradigm',\n            'leverage', 'robust', 'optimal', 'enhance', 'demonstrate',\n            'comprehensive', 'articulate'\n        ]\n        \n        # Hedging words AI uses to avoid absolute claims\n        self.hedging_words = [\n            'may', 'might', 'could', 'possibly', 'perhaps', \n            'suggests', 'seems', 'appears', 'likely'\n        ]\n        \n        # Simple passive voice indicators\n        self.passive_indicators = [\n            'is made', 'was made', 'is given', 'was given', \n            'is shown', 'was shown', 'is considered', 'was considered'\n        ]\n\n    def extract_champion_features(self, df):\n        \"\"\"\n        Extracts a DataFrame of high-impact features.\n        \"\"\"\n        features = pd.DataFrame(index=df.index)\n        \n        # Handle potential nulls in 'answer' column\n        answers = df['answer'].fillna('')\n        \n        # === Basic Text Statistics ===\n        features['text_length'] = answers.str.len()\n        features['word_count'] = answers.str.split().str.len()\n        features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6)\n        \n        # === Sentence Analysis ===\n        features['sentence_count'] = answers.str.count(r'[.!?]+')\n        features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6)\n        \n        # === Punctuation Patterns ===\n        features['comma_count'] = answers.str.count(',')\n        features['period_count'] = answers.str.count(r'\\.')\n        features['exclamation_count'] = answers.str.count(r'!')\n        features['question_count'] = answers.str.count(r'\\?')\n        features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6)\n\n        # === Lexical Richness ===\n        features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split())))\n        features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6) # Type-Token Ratio\n        \n        # === AI-Specific Patterns ===\n        def count_phrases(text, phrases):\n            text_lower = str(text).lower()\n            return sum(1 for phrase in phrases if phrase in text_lower)\n            \n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors))\n        features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words))\n        features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators))\n        \n        # === NEW: Hedging Words (AI tell) ===\n        features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words))\n        \n        # === Ratios (Density is often more powerful) ===\n        features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6)\n        features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6)\n        features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6)\n        features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n\n        # === Structural Features ===\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6)\n        \n        # === NEW: Paragraph Count ===\n        features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1\n        features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6)\n        \n        # === Consistency Metrics ===\n        features['word_length_std'] = answers.apply(\n            lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0\n        )\n        \n        # === Topic Features ===\n        topic_dummies = pd.get_dummies(df['topic'], prefix='topic', dtype=int)\n        \n        # Replace inf/-inf with 0 (e.g., from 0/0)\n        features.replace([np.inf, -np.inf], 0, inplace=True)\n        # Fill any remaining NaNs (e.g., from std of 1 word) with 0\n        features.fillna(0, inplace=True)\n        \n        return pd.concat([features, topic_dummies], axis=1)\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (STACKING ENSEMBLE)\n# -------------------------------------------------------------------\n\nclass ChampionAIDetector:\n    \"\"\"\n    Trains a powerful L2 Stacking Ensemble of LGBM, XGB, CatBoost, and LR\n    on a rich feature set (handcrafted + TF-IDF).\n    \"\"\"\n    \n    # *** CHANGE 1: Using 5 folds for a more stable validation set ***\n    def __init__(self, n_folds=5):\n        self.feature_extractor = ChampionFeatureExtractor()\n        self.n_folds = n_folds\n        self.models = {}\n        self.meta_model = None\n        self.calibrator = IsotonicRegression(out_of_bounds='clip')\n        self.is_trained = False\n        print(f\"ChampionAIDetector initialized with {self.n_folds} folds.\")\n\n    def prepare_champion_features(self, train_df, test_df):\n        \"\"\"\n        Prepares handcrafted + TF-IDF features for training and testing.\n        TF-IDF vectorizers are fit ONLY on the train_df.\n        \"\"\"\n        print(\"Extracting handcrafted features...\")\n        train_features_df = self.feature_extractor.extract_champion_features(train_df)\n        test_features_df = self.feature_extractor.extract_champion_features(test_df)\n        \n        # Align columns to ensure test set has same features as train set\n        test_features_df = test_features_df.reindex(columns=train_features_df.columns, fill_value=0)\n        \n        # Scale handcrafted features\n        print(\"Scaling handcrafted features...\")\n        self.scaler = StandardScaler()\n        train_features_scaled = self.scaler.fit_transform(train_features_df)\n        test_features_scaled = self.scaler.transform(test_features_df)\n        \n        # --- TF-IDF Features (Tuned for high performance) ---\n        print(\"Creating Word TF-IDF features...\")\n        \n        # *** CHANGE 2: Drastically reducing features to prevent overfitting ***\n        self.tfidf_word = TfidfVectorizer(\n            max_features=500,        # Was 5000\n            ngram_range=(1, 3),\n            min_df=3,\n            max_df=0.9,\n            sublinear_tf=True,\n            stop_words='english'\n        )\n        \n        train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna(''))\n        test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n        \n        print(\"Creating Char TF-IDF features...\")\n        self.tfidf_char = TfidfVectorizer(\n            max_features=250,        # Was 2000\n            analyzer='char_wb',\n            ngram_range=(3, 5),\n            min_df=3,\n            sublinear_tf=True\n        )\n        \n        train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna(''))\n        test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        \n        # Combine all features\n        print(\"Combining all feature sets...\")\n        X_train = np.hstack([\n            train_tfidf_word.toarray(),\n            train_tfidf_char.toarray(),\n            train_features_scaled\n        ])\n        \n        X_test = np.hstack([\n            test_tfidf_word.toarray(),\n            test_tfidf_char.toarray(),\n            test_features_scaled\n        ])\n        \n        print(f\"Final training feature shape: {X_train.shape}\")\n        print(f\"Final testing feature shape: {X_test.shape}\")\n        \n        return X_train, X_test, train_features_df.columns\n\n    def train_champion_ensemble(self, train_df):\n        \"\"\"\n        Trains the full L2 Stacking ensemble using Stratified K-Fold.\n        Level 1: LGBM, CatBoost (Simplified Stack)\n        Level 2: Logistic Regression (Meta-Model)\n        \"\"\"\n        \n        y_train = train_df['is_cheating'].values\n        \n        print(f\"Training set size: {len(train_df)}\")\n        print(f\"Positive class (cheating) ratio: {y_train.mean():.6f}\")\n        \n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n        \n        # Arrays to store Out-of-Fold (OOF) predictions from L1 models\n        # *** CHANGE 3: Simplified stack, removed xgb and lr ***\n        oof_preds = {\n            'lgb': np.zeros(len(train_df)),\n            'cat': np.zeros(len(train_df)),\n        }\n        \n        # --- Step 2: K-Fold Training of L1 Models ---\n        for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, y_train)):\n            print(f\"\\n{'='*20} FOLD {fold+1}/{self.n_folds} {'='*20}\")\n            \n            # Create fold-specific data\n            train_fold_df, val_fold_df = train_df.iloc[train_idx], train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            \n            # --- CRITICAL: Feature prep is done INSIDE the fold ---\n            X_train_fold, X_val_fold, _ = self.prepare_champion_features(train_fold_df, val_fold_df)\n            \n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n\n            # === LightGBM (Tuned) ===\n            print(\"Training LightGBM...\")\n            lgb_model = lgb.LGBMClassifier(\n                n_estimators=2500,\n                learning_rate=0.01,\n                max_depth=7,\n                num_leaves=48,\n                min_child_samples=10,\n                subsample=0.8,\n                colsample_bytree=0.7,\n                reg_alpha=0.1,\n                reg_lambda=0.1,\n                random_state=42 + fold,\n                verbose=-1,\n                n_jobs=-1\n            )\n            lgb_model.fit(\n                X_train_fold, y_train_fold,\n                eval_set=[(X_val_fold, y_val_fold)],\n                callbacks=[lgb.early_stopping(200, verbose=False)]\n            )\n            oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            \n            \n            # === XGBoost (REMOVED - TOO NOISY) ===\n            # print(\"Training XGBoost...\")\n            \n            \n            # === CatBoost (Tuned) ===\n            print(\"Training CatBoost...\")\n            cat_model = CatBoostClassifier(\n                iterations=2500,\n                learning_rate=0.02,\n                depth=6,\n                l2_leaf_reg=3,\n                random_seed=42 + fold,\n                verbose=0,\n                early_stopping_rounds=200,\n                task_type=\"CPU\" # or \"GPU\" if available\n            )\n            cat_model.fit(\n                X_train_fold, y_train_fold,\n                eval_set=(X_val_fold, y_val_fold),\n                verbose=False\n            )\n            oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            \n            \n            # === Logistic Regression (REMOVED - TOO NOISY) ===\n            # print(\"Training Logistic Regression...\")\n            \n\n            # --- Fold AUC Score ---\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx])\n            fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx])\n            \n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\")\n            print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\")\n\n        # --- Step 3: Evaluate OOF L1 Models ---\n        print(\"\\n\" + \"=\"*50)\n        print(\"L1 Model OOF (Out-of-Fold) Scores:\")\n        for name, preds in oof_preds.items():\n            auc = roc_auc_score(y_train, preds)\n            print(f\"  {name.upper()} OOF AUC: {auc:.8f}\")\n            \n        # --- Step 4: Train L2 Meta-Model ---\n        print(\"\\nTraining L2 Meta-Model (Stacking)...\")\n        # *** CHANGE 4: Meta-feature matrix now only has 2 columns ***\n        X_meta_train = np.stack([oof_preds['lgb'], oof_preds['cat']], axis=1)\n        \n        self.meta_model = LogisticRegression(C=1.0, solver='liblinear', random_state=42)\n        self.meta_model.fit(X_meta_train, y_train)\n        \n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]\n        oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        \n        print(f\"\\nCHAMPION L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\")\n        \n        # --- Step 5: Train Calibrator ---\n        print(\"Training Isotonic Regression Calibrator...\")\n        self.calibrator.fit(oof_ensemble_preds, y_train)\n        \n        self.is_trained = True\n        return oof_ensemble_auc, oof_ensemble_preds\n\n    def predict_champion(self, train_df, test_df):\n        \"\"\"\n        Generates final predictions on the test set.\n        \"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Model has not been trained yet! Call train_champion_ensemble() first.\")\n        \n        print(\"\\n\" + \"=\"*50)\n        print(\"Generating Test Set Predictions...\")\n        print(\"=\"*50)\n\n        # --- Step 1: Prepare features for full training and testing ---\n        X_train_full, X_test, feature_names = self.prepare_champion_features(train_df, test_df)\n        y_train_full = train_df['is_cheating'].values\n        \n        # *** CHANGE 5: Simplified test_preds dictionary ***\n        test_preds = {}\n\n        # === Step 2: Train Final L1 Models on Full Data ===\n\n        # === LightGBM Final ===\n        print(\"Training final LightGBM model...\")\n        lgb_final = lgb.LGBMClassifier(\n            n_estimators=2000, \n            learning_rate=0.01, max_depth=7, num_leaves=48, min_child_samples=10,\n            subsample=0.8, colsample_bytree=0.7, reg_alpha=0.1, reg_lambda=0.1,\n            random_state=42, verbose=-1, n_jobs=-1\n        )\n        lgb_final.fit(X_train_full, y_train_full)\n        test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        \n        \n        # === XGBoost Final (REMOVED) ===\n        \n        \n        # === CatBoost Final ===\n        print(\"Training final CatBoost model...\")\n        cat_final = CatBoostClassifier(\n            iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=3,\n            random_seed=42, verbose=0, task_type=\"CPU\"\n        )\n        cat_final.fit(X_train_full, y_train_full)\n        test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        \n        \n        # === Logistic Regression Final (REMOVED) ===\n\n\n        # --- Step 3: Apply L2 Meta-Model ---\n        print(\"Applying L2 Meta-Model to test predictions...\")\n        # *** CHANGE 6: Meta-test matrix now only has 2 columns ***\n        X_meta_test = np.stack([test_preds['lgb'], test_preds['cat']], axis=1)\n        \n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        \n        # --- Step 4: Calibrate Final Predictions ---\n        print(\"Applying Isotonic Calibration...\")\n        calibrated_proba = self.calibrator.transform(final_proba)\n        \n        # Clip probabilities to avoid 0/1, as AUC dislikes extremes\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        \n        return calibrated_proba, final_proba\n\n# -------------------------------------------------------------------\n# 3. FALLBACK MODEL\n# -------------------------------------------------------------------\n\ndef champion_fallback():\n    \"\"\"\n    A simple, robust fallback model (LGBM on features)\n    in case the main ensemble fails for any reason.\n    \"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    \n    try:\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv')\n        test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        \n        # Use the same high-quality feature extractor\n        feature_extractor = ChampionFeatureExtractor()\n        train_features = feature_extractor.extract_champion_features(train_df)\n        test_features = feature_extractor.extract_champion_features(test_df)\n        \n        test_features = test_features.reindex(columns=train_features.columns, fill_value=0)\n        \n        # Simpler TF-IDF\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english')\n        train_tfidf = tfid.fit_transform(train_df['answer'].fillna(''))\n        test_tfidf = tfid.transform(test_df['answer'].fillna(''))\n        \n        # Combine features\n        X_train = np.hstack([train_tfidf.toarray(), train_features.values])\n        X_test = np.hstack([test_tfidf.toarray(), test_features.values])\n        y_train = train_df['is_cheating']\n        \n        # Scale data\n        scaler = StandardScaler()\n        X_train = scaler.fit_transform(X_train)\n        X_test = scaler.transform(X_test)\n        \n        # Train robust LGBM\n        model = lgb.LGBMClassifier(\n            n_estimators=1200,\n            learning_rate=0.01,\n            max_depth=7,\n            num_leaves=63,\n            random_state=42,\n            verbose=-1,\n            n_jobs=-1\n        )\n        \n        model.fit(X_train, y_train)\n        test_proba = model.predict_proba(X_test)[:, 1]\n        \n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba})\n        submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        \n        print(\"Fallback submission.csv created successfully.\")\n        return submission\n        \n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\")\n        # As a last resort, create a submission of all 0.5s\n        test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5})\n        submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\")\n        return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION\n# -------------------------------------------------------------------\n\ndef champion_main():\n    \"\"\"\n    Main function to run the full training and prediction pipeline.\n    \"\"\"\n    print(\"=\" * 60)\n    print(\"  Mercor AI Text Detection - CHAMPION STACKING v3 (ANTI-OVERFITTING)\")\n    print(\"=\" * 60)\n    \n    # Load data\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv')\n    test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    \n    print(f\"Training data shape: {train_df.shape}\")\n    print(f\"Test data shape: {test_df.shape}\")\n    \n    # Pre-fill NaNs\n    train_df['answer'] = train_df['answer'].fillna('')\n    test_df['answer'] = test_df['answer'].fillna('')\n    \n    # Initialize detector\n    detector = ChampionAIDetector(n_folds=5) # Using 5 folds\n    \n    # Train model\n    print(\"\\nStarting Champion Ensemble Training...\")\n    oof_auc, oof_predictions = detector.train_champion_ensemble(train_df)\n    \n    # Predict on test set\n    print(\"\\nStarting Test Set Prediction...\")\n    calibrated_proba, base_proba = detector.predict_champion(train_df, test_df)\n    \n    # Create submission file (as requested)\n    submission_calibrated = pd.DataFrame({\n        'id': test_df['id'],\n        'is_cheating': calibrated_proba\n    })\n    \n    # Create a non-calibrated version just in case\n    submission_base = pd.DataFrame({\n        'id': test_df['id'],\n        'is_cheating': base_proba\n    })\n    \n    # Save files\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f')\n    submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\")\n    print(f\"Final OOF (Out-of-Fold) AUC: {oof_auc:.8f}\")\n    print(\"\\nSubmission files created:\")\n    print(f\"  1. submission.csv (RECOMMENDED - Calibrated L2 Stack)\")\n    print(f\"  2. submission_base_uncalibrated.csv (Uncalibrated L2 Stack)\")\n    \n    # Display statistics of final predictions\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\")\n    print(f\"  Min: {calibrated_proba.min():.6f}\")\n    print(f\"  Max: {calibrated_proba.max():.6f}\")\n    print(f\"  Mean: {calibrated_proba.mean():.6f}\")\n    print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    \n    print(\"\\nTop 10 Predictions:\")\n    print(submission_calibrated.head(10).to_string(index=False))\n    print(\"=\" * 60)\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    try:\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback\n        traceback.print_exc()\n        champion_fallback()","metadata":{}},{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv14: FIXED Accelerate Device Conflict\n- Removed the conflicting 'device' argument from the pipeline()\n  call when using device_map=\"auto\" during model loading.\n- Pipeline now correctly uses the device(s) assigned by accelerate.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nimport warnings\nimport torch\nimport gc # Garbage Collection\n\n# --- Imports for Local LLM ---\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom tqdm.auto import tqdm\nfrom scipy.sparse import hstack, csr_matrix\n\n# Suppress warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"All libraries imported successfully!\")\n\n# --- CONFIGURATION ---\n# *** REPLACE WITH YOUR ACTUAL KAGGLE INPUT PATH ***\nQWEN_MODEL_PATH = \"/kaggle/input/qwen2.5/transformers/7b-instruct-awq/1\" # <-- SET THIS PATH\n\n# -------------------------------------------------------------------\n# 0. LOCAL LLM PREDICTION LAYER (Qwen - Fixed Pipeline Init)\n# -------------------------------------------------------------------\n\ndef get_llm_predictions(texts, model_path):\n    \"\"\"\n    Uses a local Qwen model to classify text as 'AI' or 'Human' via prompting,\n    then assigns probabilities.\n    \"\"\"\n    print(f\"Loading LOCAL LLM detector from: {model_path}...\")\n    # NOTE: We don't specify device here, let device_map handle it\n    print(f\"Device mapping will be handled by accelerate.\")\n\n    try:\n        print(\"Loading tokenizer...\")\n        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n        print(\"Loading model (AWQ) with device_map='auto'...\")\n        model = AutoModelForCausalLM.from_pretrained(\n            model_path,\n            torch_dtype=torch.float16, # Using float16 based on previous warning\n            device_map=\"auto\",\n            trust_remote_code=True\n        )\n        model.eval()\n        # Get the device the model (or its first part) ended up on for logging\n        loaded_device = model.device\n        print(f\"Model loaded successfully on device(s) via accelerate (example device: {loaded_device})\")\n\n    except Exception as e:\n        print(f\"Error loading local Qwen model: {e}\")\n        print(\"Falling back to assigning 0.5 probability to all.\")\n        return np.full(len(texts), 0.5)\n\n    # Use a pipeline for easier text generation handling\n    print(\"Initializing text-generation pipeline...\")\n    pipe = pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        # --- THIS IS THE FIX ---\n        # REMOVED device=model.device, # <--- REMOVED THIS ARGUMENT\n        max_new_tokens=5,\n        temperature=0.01,\n        do_sample=False\n    )\n    print(f\"Pipeline initialized, will use device(s): {pipe.device}\") # Log pipeline device\n\n    print(f\"Running Qwen inference on {len(texts)} texts...\")\n    qwen_probs = []\n    batch_size = 8\n    prompt_template = \"Analyze the following text. Was it written by a human or generated by an AI? Respond with ONLY the word 'Human' or the word 'AI'. Text: {}\"\n\n    for i in tqdm(range(0, len(texts), batch_size)):\n        batch_texts = texts[i : i + batch_size].tolist()\n        # Truncate input text to avoid overly long prompts\n        batch_prompts = [prompt_template.format(text[:1500]) for text in batch_texts] # Increased limit slightly\n\n        try:\n            # Generate responses\n            outputs = pipe(batch_prompts, batch_size=len(batch_prompts)) # Process batch\n\n            for output in outputs:\n                # Extract only the newly generated text\n                # Accessing the first (and likely only) generated sequence\n                full_generated_text = output[0]['generated_text']\n\n                # Find where the prompt ends in the output. This is more robust.\n                prompt_end_index = full_generated_text.find(batch_prompts[outputs.index(output)][-20:]) # Find ~end of prompt\n                if prompt_end_index != -1:\n                     response_start = prompt_end_index + len(batch_prompts[outputs.index(output)][-20:])\n                     response = full_generated_text[response_start:].strip().lower()\n                else:\n                    # If prompt not found, try a simpler heuristic (less reliable)\n                    response = full_generated_text.split(\"Text:\")[-1].strip().lower()\n\n\n                # Assign probability based on classification\n                # Check for specific words at the START of the response\n                if response.startswith(\"ai\"):\n                    qwen_probs.append(0.95)\n                elif response.startswith(\"human\"):\n                    qwen_probs.append(0.05)\n                else:\n                    print(f\"Warning: Unexpected Qwen response start: '{response[:20]}...'. Full: '{full_generated_text}'. Assigning 0.5.\")\n                    qwen_probs.append(0.5)\n\n        except Exception as e:\n            print(f\"Error during Qwen batch inference {i // batch_size}: {e}\")\n            qwen_probs.extend([0.5] * len(batch_texts))\n\n        # Memory cleanup\n        gc.collect(); torch.cuda.empty_cache()\n\n    print(\"Qwen prediction feature generated successfully.\")\n    del model; del tokenizer; del pipe; gc.collect(); torch.cuda.empty_cache()\n    return np.array(qwen_probs)\n\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (Extracts base + adds qwen_pred later)\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, topic dummies handled later.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']\n        self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']\n        self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']\n        self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n\n    def extract_base_features(self, df):\n        \"\"\"Extracts NON-TOPIC features and adds qwen_pred if present.\"\"\"\n        features = pd.DataFrame(index=df.index)\n        if 'qwen_pred' in df.columns: features['qwen_pred'] = df['qwen_pred']\n        answers = df['answer'].fillna('')\n        features['text_length'] = answers.str.len()\n        features['word_count'] = answers.str.split().str.len()\n        features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6)\n        features['sentence_count'] = answers.str.count(r'[.!?]+')\n        features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6)\n        features['comma_count'] = answers.str.count(',')\n        features['period_count'] = answers.str.count(r'\\.')\n        features['exclamation_count'] = answers.str.count(r'!')\n        features['question_count'] = answers.str.count(r'\\?')\n        features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6)\n        features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split())))\n        features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors))\n        features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words))\n        features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators))\n        features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words))\n        features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6)\n        features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6)\n        features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6)\n        features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6)\n        features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1\n        features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6)\n        features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True)\n        return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (Unchanged from v12)\n# -------------------------------------------------------------------\n\nclass ChampionAIDetector:\n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats including the Qwen feature.\"\"\"\n    def __init__(self, n_folds=5, n_features=750):\n        self.feature_extractor = ChampionFeatureExtractor()\n        self.n_folds = n_folds; self.n_features = n_features\n        self.models = {}; self.meta_model = None\n        self.calibrator = IsotonicRegression(out_of_bounds='clip')\n        self.scaler = StandardScaler(); self.tfidf_word = None\n        self.tfidf_char = None; self.selector = None\n        self.topic_columns = None; self.is_trained = False\n        print(f\"Detector initialized: {n_folds} folds, SelectKBest(k={n_features}).\")\n\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        \"\"\"Gets dummy variables for topics, ensuring consistent columns.\"\"\"\n        dummies = pd.get_dummies(series, prefix='topic', dtype=int)\n        if fit_columns: self.topic_columns = dummies.columns; print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates qwen_pred.\"\"\"\n        print(\"Extracting base handcrafted + Qwen features...\")\n        train_base_features_df = self.feature_extractor.extract_base_features(train_df)\n        test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        if is_training_fold or is_full_training: fit_topic_cols = (self.topic_columns is None) or is_full_training; train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        else: train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=False); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        qwen_train_feat = train_base_features_df.pop('qwen_pred').values.reshape(-1, 1); qwen_test_feat = test_base_features_df.pop('qwen_pred').values.reshape(-1, 1)\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. Qwen) with StandardScaler...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. Qwen) using fitted StandardScaler...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2000)\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1000)\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        print(\"Combining all feature sets...\"); X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(qwen_train_feat)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(qwen_test_feat)]).tocsr()\n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            self.selector.fit(X_train_full, y_train); X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n\n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n        oof_preds = {'lgb': np.zeros(len(full_train_df)), 'cat': np.zeros(len(full_train_df)), 'ridge': np.zeros(len(full_train_df))}\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, y_train)):\n            print(f\"\\n{'='*20} FOLD {fold+1}/{self.n_folds} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            is_first_fold = (fold == 0); X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=is_first_fold, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=0.5, random_state=42 + fold, verbose=-1, n_jobs=-1)\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=5, random_seed=42 + fold, verbose=0, early_stopping_rounds=200, task_type=\"CPU\")\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.0, random_state=42 + fold); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds['ridge'][val_idx] = ridge_probs\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds['ridge'][val_idx])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"L1 Model OOF Scores:\"); [print(f\"  {name.upper()} OOF AUC: {roc_auc_score(y_train, preds):.8f}\") for name, preds in oof_preds.items()]\n        print(\"\\nTraining L2 Meta-Model...\"); X_meta_train = np.stack(list(oof_preds.values()), axis=1)\n        self.meta_model = LogisticRegression(C=1.0, solver='liblinear', random_state=42); self.meta_model.fit(X_meta_train, y_train)\n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCHAMPION L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\"); print(\"Training Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Test Set Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final model training and prediction...\")\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=True)\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=0.5, random_state=42, verbose=-1, n_jobs=-1)\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=5, random_seed=42, verbose=0, task_type=\"CPU\")\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.0, random_state=42); ridge_final.fit(X_train_full_scaled, y_train_full)\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        print(\"Applying L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n# -------------------------------------------------------------------\n# 3. FALLBACK MODEL (Unchanged from v12)\n# -------------------------------------------------------------------\ndef champion_fallback():\n    \"\"\"Fallback using LGBM, fixed scaler.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler\n        from scipy.sparse import hstack, csr_matrix\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor()\n        train_base_features = feature_extractor.extract_base_features(train_df); test_base_features = feature_extractor.extract_base_features(test_df)\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns\n        test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1)\n        test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english')\n        train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr()\n        y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1200, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=42, verbose=-1, n_jobs=-1, reg_alpha=0.3, reg_lambda=0.3)\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\")\n        test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION (Modified for Qwen Feature)\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Runs Qwen feature gen + classical stack.\"\"\"\n    print(\"=\" * 60); print(\"  Mercor AI Text Detection - CHAMPION v14 (Local Qwen + Fix)\"); print(\"=\" * 60)\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n    print(\"\\nStarting Qwen Feature Generation...\")\n    all_texts = pd.concat([train_df['answer'], test_df['answer']])\n    qwen_preds = get_llm_predictions(all_texts, QWEN_MODEL_PATH)\n    train_df['qwen_pred'] = qwen_preds[:len(train_df)]; test_df['qwen_pred'] = qwen_preds[len(train_df):]\n    print(\"Qwen feature ('qwen_pred') added to dataframes.\")\n    detector = ChampionAIDetector(n_folds=5, n_features=750)\n    print(\"\\nStarting Champion Ensemble Training (with Qwen feature)...\")\n    oof_auc, oof_predictions = detector.train_champion_ensemble(train_df)\n    print(\"\\nStarting Test Set Prediction...\")\n    calibrated_proba, base_proba = detector.predict_champion(train_df, test_df)\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\"); print(f\"Final OOF (Out-of-Fold) AUC: {oof_auc:.8f}\")\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback\n        traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2025-10-26T09:29:25.794609Z","iopub.execute_input":"2025-10-26T09:29:25.794928Z","iopub.status.idle":"2025-10-26T09:35:42.684657Z","shell.execute_reply.started":"2025-10-26T09:29:25.794907Z","shell.execute_reply":"2025-10-26T09:35:42.683994Z"}}},{"cell_type":"markdown","source":"# === Hugging Face Imports ===\n# Install necessary libraries silently\nprint(\"Installing specific pyarrow version...\")\n# Force install pyarrow 14.0.1 FIRST to resolve conflicts\nos.system('pip install -q pyarrow==14.0.1')\nprint(\"Installing/Updating Hugging Face libraries...\")\n# Now install the HF libraries\nos.system('pip install -q datasets evaluate accelerate transformers')\nprint(\"Libraries installed.\")\n\n# (Rest of your imports)\nimport torch\nfrom datasets import Dataset, DatasetDict\n# ... etc ...","metadata":{}},{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv21: Inference-Only Feature from abhi099k + Classical Ensemble\n- ABANDONED fine-tuning due to persistent pyarrow/datasets import errors.\n- Uses the 'abhi099k/ai-text-detector-v-n4.0' model purely for INFERENCE.\n- Loads model/tokenizer directly using transformers (no datasets/Trainer).\n- Creates 'llm_pred' feature via manual batch inference loop.\n- Adds 'llm_pred' feature to the v12 classical pipeline\n  (SelectKBest + LGBM + CatBoost + Ridge).\n- Simplified installation - no datasets/evaluate/accelerate.\n\"\"\"\n\n# === General Imports ===\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport gc\nimport warnings\nimport time\nimport os\n\n# === Sklearn Imports ===\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom scipy.sparse import hstack, csr_matrix\n\n# === GBDT Imports ===\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n# === Hugging Face Imports ===\n# Simplified Install - ONLY transformers + torch\nprint(\"Installing/Updating transformers...\")\nos.system('pip install -q transformers torch') # Keep torch for GPU\nprint(\"Libraries installed.\")\n\ntry:\n    import torch\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n    from tqdm.auto import tqdm\n    # Set transformers verbosity to error\n    import transformers\n    transformers.logging.set_verbosity_error()\nexcept ImportError as e:\n    print(f\"FATAL ERROR during imports: {e}\")\n    raise e\n\n\nprint(\"All libraries imported successfully!\")\n\n# === Configuration ===\nLLM_MODEL_NAME = \"abhi099k/ai-text-detector-v-n4.0\"\nN_SPLITS_CLASSICAL = 5\nN_FEATURES_CLASSICAL = 750 # For SelectKBest\nMAX_LEN_LLM = 512 # Max sequence length for tokenizer\n\n# -------------------------------------------------------------------\n# 0. LLM INFERENCE FUNCTION (Manual Loop)\n# -------------------------------------------------------------------\n\ndef get_llm_predictions(texts, model_name):\n    \"\"\"Generates predictions using the specified model via manual inference.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\")\n    model = None; tokenizer = None\n    # Determine device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\")\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n        print(f\"Loading Model: {model_name}...\")\n        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n        model.to(device) # Move model to GPU/CPU\n        model.eval() # Set to evaluation mode\n        print(\"Model and Tokenizer loaded successfully.\")\n        \n        # --- Determine positive label ID ---\n        # Assuming label '1' corresponds to AI/Cheating\n        positive_label_id = 1\n        if hasattr(model.config, \"label2id\"):\n             print(f\"Model labels found: {model.config.label2id}\")\n             # You could add logic here to find the 'AI' label if needed,\n             # but assuming ID 1 is standard for binary tasks like this.\n        print(f\"Assuming positive label ID (AI/Cheating) is: {positive_label_id}\")\n\n\n    except Exception as e:\n        print(f\"Error loading model or tokenizer {model_name}: {e}\\nFalling back to 0.5 probability.\")\n        del model; del tokenizer; gc.collect(); torch.cuda.empty_cache()\n        return np.full(len(texts), 0.5)\n\n    print(f\"Running LLM inference on {len(texts)} texts...\")\n    llm_probs = []\n    batch_size = 32 # Can likely use a larger batch size for inference\n\n    # Disable gradient calculations for inference\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=\"LLM Inference Batches\"):\n            batch_texts = texts[i : i + batch_size].tolist()\n            if not batch_texts: continue\n\n            try:\n                # Tokenize batch\n                inputs = tokenizer(\n                    batch_texts,\n                    return_tensors=\"pt\",\n                    truncation=True,\n                    padding=True,\n                    max_length=MAX_LEN_LLM\n                ).to(device) # Move tokenized inputs to the same device as the model\n\n                # Get model outputs (logits)\n                outputs = model(**inputs)\n                logits = outputs.logits\n\n                # Apply Softmax to get probabilities\n                # Check shape to handle potential single-output models (less likely for classification)\n                if logits.shape[-1] == 1: # Single output logit\n                    probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n                elif logits.shape[-1] == 2: # Two output logits\n                    probs_all = torch.softmax(logits, dim=-1)\n                    # Get probability of the positive class (assumed index 1)\n                    probs = probs_all[:, positive_label_id].cpu().numpy()\n                else:\n                     print(f\"Warning: Unexpected logit shape {logits.shape} in batch {i//batch_size}. Assigning 0.5.\")\n                     probs = np.full(len(batch_texts), 0.5)\n\n                llm_probs.extend(probs.tolist())\n\n            except Exception as e:\n                 print(f\"Error during LLM inference batch {i // batch_size}: {e}\")\n                 print(f\"Assigning 0.5 for {len(batch_texts)} failed batch items.\")\n                 llm_probs.extend([0.5] * len(batch_texts))\n\n            # Minimal cleanup within loop\n            if i % (batch_size * 20) == 0:\n                gc.collect()\n\n    print(\"LLM prediction feature generated successfully.\")\n    del model; del tokenizer; gc.collect(); torch.cuda.empty_cache() # Final cleanup\n    print(\"--- Finished LLM Inference ---\")\n\n    # Final length check\n    if len(llm_probs) != len(texts):\n        print(f\"CRITICAL WARNING: Output probability list length ({len(llm_probs)}) != input text length ({len(texts)}). Padding/Truncating.\")\n        llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)] # Pad/truncate\n\n    return np.array(llm_probs)\n\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (Handles 'llm_pred') - Unchanged\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, includes llm_pred if present.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']; self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']; self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']; self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n    def extract_base_features(self, df):\n        features = pd.DataFrame(index=df.index);\n        if 'llm_pred' in df.columns: features['llm_pred'] = df['llm_pred']\n        answers = df['answer'].fillna(''); features['text_length'] = answers.str.len(); features['word_count'] = answers.str.split().str.len(); features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6); features['sentence_count'] = answers.str.count(r'[.!?]+'); features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6); features['comma_count'] = answers.str.count(','); features['period_count'] = answers.str.count(r'\\.'); features['exclamation_count'] = answers.str.count(r'!'); features['question_count'] = answers.str.count(r'\\?'); features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6); features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split()))); features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors)); features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words)); features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators)); features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words)); features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6); features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6); features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6); features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6); features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1; features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6); features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True); return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (Handles llm_pred) - Unchanged\n# -------------------------------------------------------------------\nclass ChampionAIDetector:\n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats including llm_pred.\"\"\"\n    def __init__(self, n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL):\n        self.feature_extractor = ChampionFeatureExtractor(); self.n_folds = n_folds; self.n_features = n_features; self.models = {}; self.meta_model = None; self.calibrator = IsotonicRegression(out_of_bounds='clip'); self.scaler = StandardScaler(); self.tfidf_word = None; self.tfidf_char = None; self.selector = None; self.topic_columns = None; self.is_trained = False; print(f\"\\nClassical Detector initialized: {n_folds} folds, SelectKBest(k={n_features}).\")\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        dummies = pd.get_dummies(series, prefix='topic', dtype=int);\n        if fit_columns: self.topic_columns = dummies.columns; print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates llm_pred.\"\"\"\n        print(\"Extracting base handcrafted + LLM features...\"); train_base_features_df = self.feature_extractor.extract_base_features(train_df); test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        if is_training_fold or is_full_training: fit_topic_cols = (self.topic_columns is None) or is_full_training; train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        else: train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=False); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        llm_train_feat = train_base_features_df.pop('llm_pred').values.reshape(-1, 1); llm_test_feat = test_base_features_df.pop('llm_pred').values.reshape(-1, 1)\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2000)\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1000)\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        print(\"Combining all feature sets...\"); X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(llm_train_feat)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(llm_test_feat)]).tocsr()\n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            self.selector.fit(X_train_full, y_train); X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"\\n--- Starting Classical Ensemble Training ---\")\n        print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n        oof_preds = {'lgb': np.zeros(len(full_train_df)), 'cat': np.zeros(len(full_train_df)), 'ridge': np.zeros(len(full_train_df))}\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, y_train)):\n            print(f\"\\n{'='*20} Classical Fold {fold+1}/{self.n_folds} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            is_first_fold = (fold == 0); X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=is_first_fold, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=0.3, random_state=42 + fold, verbose=-1, n_jobs=-1)\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=4, random_seed=42 + fold, verbose=0, early_stopping_rounds=200, task_type=\"CPU\")\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.0, random_state=42 + fold); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds['ridge'][val_idx] = ridge_probs\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds['ridge'][val_idx])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"Classical L1 Model OOF Scores:\"); [print(f\"  {name.upper()} OOF AUC: {roc_auc_score(y_train, preds):.8f}\") for name, preds in oof_preds.items()]\n        print(\"\\nTraining Classical L2 Meta-Model...\"); X_meta_train = np.stack(list(oof_preds.values()), axis=1)\n        self.meta_model = LogisticRegression(C=1.0, solver='liblinear', random_state=42); self.meta_model.fit(X_meta_train, y_train)\n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCLASSICAL L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\"); print(\"Training Classical Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted classical components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Classical model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Final Classical Ensemble Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final classical model training and prediction...\")\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=True)\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=0.3, random_state=42, verbose=-1, n_jobs=-1)\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=4, random_seed=42, verbose=0, task_type=\"CPU\")\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.0, random_state=42); ridge_final.fit(X_train_full_scaled, y_train_full)\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        print(\"Applying Classical L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Classical Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n# --- (Fallback model - unchanged) ---\ndef champion_fallback():\n    \"\"\"Fallback using basic LGBM, fixed scaler.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler; from scipy.sparse import hstack, csr_matrix\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor(); train_base_features = feature_extractor.extract_base_features(train_df.drop(columns=['llm_pred'], errors='ignore')) # Generic drop\n        test_base_features = feature_extractor.extract_base_features(test_df.drop(columns=['llm_pred'], errors='ignore'))\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns; test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1); test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english'); train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr(); y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1200, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=42, verbose=-1, n_jobs=-1, reg_alpha=0.3, reg_lambda=0.3)\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\"); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f'); print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Runs LLM inference feature gen + classical stack.\"\"\"\n    print(\"=\" * 60); print(f\"  Mercor AI Text Detection - CHAMPION v21 ({LLM_MODEL_NAME} Inference + Classical)\"); print(\"=\" * 60)\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n\n    # --- Step 1: Generate LLM predictions ---\n    all_texts = pd.concat([train_df['answer'], test_df['answer']])\n    llm_preds = get_llm_predictions(all_texts, LLM_MODEL_NAME)\n    train_df['llm_pred'] = llm_preds[:len(train_df)]; test_df['llm_pred'] = llm_preds[len(train_df):]\n    print(\"LLM feature ('llm_pred') added to dataframes.\")\n\n    # --- Step 2: Run Classical Ensemble ---\n    classical_detector = ChampionAIDetector(n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL)\n    oof_auc_classical, oof_preds_classical = classical_detector.train_champion_ensemble(train_df)\n    print(\"\\nStarting Final Test Set Prediction using Classical Ensemble...\")\n    calibrated_proba, base_proba = classical_detector.predict_champion(train_df, test_df)\n\n    # Create submission files\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n\n    # Final Output\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\");\n    print(f\"Final Classical Ensemble OOF AUC (with LLM feature): {oof_auc_classical:.8f}\")\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    start_time = time.time()\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback\n        traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache()\n        end_time = time.time()\n        print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"execution":{"iopub.status.busy":"2025-10-26T14:20:56.329840Z","iopub.execute_input":"2025-10-26T14:20:56.330608Z","iopub.status.idle":"2025-10-26T14:24:54.701077Z","shell.execute_reply.started":"2025-10-26T14:20:56.330580Z","shell.execute_reply":"2025-10-26T14:24:54.700442Z"}}},{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv22: Hyperparameter Tuning on v21\n- Increased SelectKBest k from 750 to 850.\n- Increased TF-IDF max_features pool (Word: 2500, Char: 1250).\n- LGBM: Increased num_leaves back to 31.\n- L2 Logistic Regression Meta-Model: Changed C from 1.0 to 0.5.\n- Kept abhi099k model for inference feature.\n\"\"\"\n\n# === General Imports ===\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport gc\nimport warnings\nimport time\nimport os\n\n# === Sklearn Imports ===\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom scipy.sparse import hstack, csr_matrix\n\n# === GBDT Imports ===\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n# === Hugging Face Imports ===\n# Simplified Install - ONLY transformers + torch\nprint(\"Installing/Updating transformers...\")\nos.system('pip install -q transformers torch')\nprint(\"Libraries installed.\")\n\ntry:\n    import torch\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n    from tqdm.auto import tqdm\n    import transformers\n    transformers.logging.set_verbosity_error()\nexcept ImportError as e:\n    print(f\"FATAL ERROR during imports: {e}\"); raise e\n\nprint(\"All libraries imported successfully!\")\n\n# === Configuration ===\nLLM_MODEL_NAME = \"abhi099k/ai-text-detector-v-n4.0\"\nN_SPLITS_CLASSICAL = 5\n# --- TUNED ---\nN_FEATURES_CLASSICAL = 850 # Increased k\nMAX_LEN_LLM = 512\n\n# -------------------------------------------------------------------\n# 0. LLM INFERENCE FUNCTION (Manual Loop - Unchanged from v21)\n# -------------------------------------------------------------------\ndef get_llm_predictions(texts, model_name):\n    \"\"\"Generates predictions using the specified model via manual inference.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\"); model = None; tokenizer = None\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\"); tokenizer = AutoTokenizer.from_pretrained(model_name)\n        print(f\"Loading Model: {model_name}...\"); model = AutoModelForSequenceClassification.from_pretrained(model_name); model.to(device); model.eval()\n        print(\"Model and Tokenizer loaded successfully.\")\n        positive_label_id = 1; # Assume AI is label 1\n        if hasattr(model.config, \"label2id\"): print(f\"Model labels found: {model.config.label2id}\")\n        print(f\"Assuming positive label ID (AI/Cheating) is: {positive_label_id}\")\n    except Exception as e:\n        print(f\"Error loading model/tokenizer {model_name}: {e}\\nFalling back to 0.5.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); return np.full(len(texts), 0.5)\n    print(f\"Running LLM inference on {len(texts)} texts...\"); llm_probs = []\n    batch_size = 32\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=\"LLM Inference Batches\"):\n            batch_texts = texts[i : i + batch_size].tolist();\n            if not batch_texts: continue\n            try:\n                inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN_LLM).to(device)\n                outputs = model(**inputs); logits = outputs.logits\n                if logits.shape[-1] == 1: probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n                elif logits.shape[-1] == 2: probs_all = torch.softmax(logits, dim=-1); probs = probs_all[:, positive_label_id].cpu().numpy()\n                else: print(f\"Warning: Unexpected logit shape {logits.shape}. Assigning 0.5.\"); probs = np.full(len(batch_texts), 0.5)\n                llm_probs.extend(probs.tolist())\n            except Exception as e: print(f\"Error during LLM batch {i // batch_size}: {e}\"); llm_probs.extend([0.5] * len(batch_texts))\n            if i % (batch_size * 20) == 0: gc.collect()\n    print(\"LLM prediction feature generated.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); print(\"--- Finished LLM Inference ---\")\n    if len(llm_probs) != len(texts): print(f\"CRITICAL WARNING: Length mismatch {len(llm_probs)} vs {len(texts)}. Padding/Truncating.\"); llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)]\n    return np.array(llm_probs)\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (Handles 'llm_pred') - Unchanged\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, includes llm_pred if present.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']; self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']; self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']; self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n    def extract_base_features(self, df):\n        features = pd.DataFrame(index=df.index);\n        if 'llm_pred' in df.columns: features['llm_pred'] = df['llm_pred']\n        answers = df['answer'].fillna(''); features['text_length'] = answers.str.len(); features['word_count'] = answers.str.split().str.len(); features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6); features['sentence_count'] = answers.str.count(r'[.!?]+'); features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6); features['comma_count'] = answers.str.count(','); features['period_count'] = answers.str.count(r'\\.'); features['exclamation_count'] = answers.str.count(r'!'); features['question_count'] = answers.str.count(r'\\?'); features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6); features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split()))); features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors)); features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words)); features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators)); features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words)); features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6); features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6); features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6); features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6); features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1; features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6); features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True); return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (Handles llm_pred, Tuned Params)\n# -------------------------------------------------------------------\nclass ChampionAIDetector:\n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats including llm_pred.\"\"\"\n    def __init__(self, n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL):\n        self.feature_extractor = ChampionFeatureExtractor(); self.n_folds = n_folds; self.n_features = n_features; self.models = {}; self.meta_model = None; self.calibrator = IsotonicRegression(out_of_bounds='clip'); self.scaler = StandardScaler(); self.tfidf_word = None; self.tfidf_char = None; self.selector = None; self.topic_columns = None; self.is_trained = False; print(f\"\\nClassical Detector initialized: {n_folds} folds, SelectKBest(k={n_features}).\")\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        dummies = pd.get_dummies(series, prefix='topic', dtype=int);\n        if fit_columns: self.topic_columns = dummies.columns; print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates llm_pred.\"\"\"\n        print(\"Extracting base handcrafted + LLM features...\"); train_base_features_df = self.feature_extractor.extract_base_features(train_df); test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        if is_training_fold or is_full_training: fit_topic_cols = (self.topic_columns is None) or is_full_training; train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        else: train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=False); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        llm_train_feat = train_base_features_df.pop('llm_pred').values.reshape(-1, 1); llm_test_feat = test_base_features_df.pop('llm_pred').values.reshape(-1, 1)\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            # --- TUNED ---\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2500) # Increased pool\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1250) # Increased pool\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        print(\"Combining all feature sets...\"); X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(llm_train_feat)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(llm_test_feat)]).tocsr()\n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            # Handle potential warnings/errors during fitting SelectKBest\n            with warnings.catch_warnings():\n                 warnings.filterwarnings('ignore', category=RuntimeWarning) # Ignore division by zero etc.\n                 warnings.filterwarnings('ignore', category=UserWarning) # Ignore constant feature warning\n                 self.selector.fit(X_train_full, y_train)\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n\n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"\\n--- Starting Classical Ensemble Training ---\")\n        print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n        oof_preds = {'lgb': np.zeros(len(full_train_df)), 'cat': np.zeros(len(full_train_df)), 'ridge': np.zeros(len(full_train_df))}\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, y_train)):\n            print(f\"\\n{'='*20} Classical Fold {fold+1}/{self.n_folds} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            is_first_fold = (fold == 0); X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=is_first_fold, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n\n            # --- TUNED ---\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=0.3, random_state=42 + fold, verbose=-1, n_jobs=-1) # leaves=31\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=4, random_seed=42 + fold, verbose=0, early_stopping_rounds=200, task_type=\"CPU\") # l2=4\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.0, random_state=42 + fold); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds['ridge'][val_idx] = ridge_probs\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds['ridge'][val_idx])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"Classical L1 Model OOF Scores:\"); [print(f\"  {name.upper()} OOF AUC: {roc_auc_score(y_train, preds):.8f}\") for name, preds in oof_preds.items()]\n\n        # --- TUNED ---\n        print(\"\\nTraining Classical L2 Meta-Model...\"); X_meta_train = np.stack(list(oof_preds.values()), axis=1)\n        self.meta_model = LogisticRegression(C=0.5, solver='liblinear', random_state=42); self.meta_model.fit(X_meta_train, y_train) # C=0.5\n\n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCLASSICAL L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\"); print(\"Training Classical Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted classical components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Classical model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Final Classical Ensemble Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final classical model training and prediction...\")\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=True)\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        # --- TUNED ---\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=0.3, random_state=42, verbose=-1, n_jobs=-1) # leaves=31\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=4, random_seed=42, verbose=0, task_type=\"CPU\") # l2=4\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.0, random_state=42); ridge_final.fit(X_train_full_scaled, y_train_full)\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        print(\"Applying Classical L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Classical Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n\n# --- (Fallback model - unchanged) ---\ndef champion_fallback():\n    \"\"\"Fallback using basic LGBM, fixed scaler.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler; from scipy.sparse import hstack, csr_matrix\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor(); train_base_features = feature_extractor.extract_base_features(train_df.drop(columns=['llm_pred'], errors='ignore')) # Generic drop\n        test_base_features = feature_extractor.extract_base_features(test_df.drop(columns=['llm_pred'], errors='ignore'))\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns; test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1); test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english'); train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr(); y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1200, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=42, verbose=-1, n_jobs=-1, reg_alpha=0.3, reg_lambda=0.3)\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\"); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f'); print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Runs LLM inference feature gen + classical stack.\"\"\"\n    print(\"=\" * 60); print(f\"  Mercor AI Text Detection - CHAMPION v22 (Tuned {LLM_MODEL_NAME} + Classical)\"); print(\"=\" * 60)\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n    all_texts = pd.concat([train_df['answer'], test_df['answer']])\n    llm_preds = get_llm_predictions(all_texts, LLM_MODEL_NAME)\n    train_df['llm_pred'] = llm_preds[:len(train_df)]; test_df['llm_pred'] = llm_preds[len(train_df):]\n    print(\"LLM feature ('llm_pred') added to dataframes.\")\n    classical_detector = ChampionAIDetector(n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL)\n    oof_auc_classical, oof_preds_classical = classical_detector.train_champion_ensemble(train_df)\n    print(\"\\nStarting Final Test Set Prediction using Classical Ensemble...\")\n    calibrated_proba, base_proba = classical_detector.predict_champion(train_df, test_df)\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\"); print(f\"Final Classical Ensemble OOF AUC (with LLM feature): {oof_auc_classical:.8f}\")\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    start_time = time.time()\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback; traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache(); end_time = time.time()\n        print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"execution":{"iopub.status.busy":"2025-10-26T14:31:57.342548Z","iopub.execute_input":"2025-10-26T14:31:57.342966Z","iopub.status.idle":"2025-10-26T14:35:41.999716Z","shell.execute_reply.started":"2025-10-26T14:31:57.342939Z","shell.execute_reply":"2025-10-26T14:35:41.999100Z"}}},{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv24: External Data Augmentation (DAIGT V2) + v22 Pipeline\n- Adds external data from 'thedrcat/daigt-v2-train-dataset'.\n- Formats DAIGT data to match competition structure.\n- Combines competition train data with DAIGT data (downsampled).\n- Runs the v22 pipeline (inference feature from abhi099k + classical ensemble\n  with tuned params) on the augmented dataset.\n- Aims to significantly boost performance by increasing training data size.\n\"\"\"\n\n# === General Imports ===\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport gc\nimport warnings\nimport time\nimport os\n\n# === Sklearn Imports ===\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler # Keep MinMaxScaler for NB fallback\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.utils import shuffle # To shuffle combined data\n\n# === GBDT Imports ===\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n# === Hugging Face Imports ===\nprint(\"Installing/Updating transformers...\")\nos.system('pip install -q transformers torch') # Keep install simple\nprint(\"Libraries installed.\")\ntry:\n    import torch\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n    from tqdm.auto import tqdm\n    import transformers\n    transformers.logging.set_verbosity_error()\nexcept ImportError as e: print(f\"FATAL ERROR during imports: {e}\"); raise e\n\nprint(\"All libraries imported successfully!\")\n\n# === Configuration ===\nLLM_MODEL_NAME = \"abhi099k/ai-text-detector-v-n4.0\"\nN_SPLITS_CLASSICAL = 5\nN_FEATURES_CLASSICAL = 850 # Keep tuned k from v22\nMAX_LEN_LLM = 512\n# --- NEW: External Data Config ---\n# *** VERIFY THIS PATH IS CORRECT IN YOUR KAGGLE NOTEBOOK ***\nEXTERNAL_DATA_PATH = '/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv'\nMAX_EXTERNAL_SAMPLES = 20000 # Limit external data size (adjust as needed, max ~44k)\nRANDOM_SEED = 42\n\n# -------------------------------------------------------------------\n# 0. LLM INFERENCE FUNCTION (Manual Loop - Unchanged from v21)\n# -------------------------------------------------------------------\n# (Keep the get_llm_predictions function exactly as in v21/v22)\ndef get_llm_predictions(texts, model_name):\n    \"\"\"Generates predictions using the specified model via manual inference.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\"); model = None; tokenizer = None\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\"); tokenizer = AutoTokenizer.from_pretrained(model_name)\n        print(f\"Loading Model: {model_name}...\"); model = AutoModelForSequenceClassification.from_pretrained(model_name); model.to(device); model.eval()\n        print(\"Model and Tokenizer loaded successfully.\")\n        positive_label_id = 1; # Assume AI is label 1\n        if hasattr(model.config, \"label2id\"): print(f\"Model labels found: {model.config.label2id}\")\n        print(f\"Assuming positive label ID (AI/Cheating) is: {positive_label_id}\")\n    except Exception as e:\n        print(f\"Error loading model/tokenizer {model_name}: {e}\\nFalling back to 0.5.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); return np.full(len(texts), 0.5)\n    print(f\"Running LLM inference on {len(texts)} texts...\"); llm_probs = []\n    batch_size = 32\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=\"LLM Inference Batches\"):\n            batch_texts = texts[i : i + batch_size].tolist();\n            if not batch_texts: continue\n            try:\n                inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN_LLM).to(device)\n                outputs = model(**inputs); logits = outputs.logits\n                if logits.shape[-1] == 1: probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n                elif logits.shape[-1] == 2: probs_all = torch.softmax(logits, dim=-1); probs = probs_all[:, positive_label_id].cpu().numpy()\n                else: print(f\"Warning: Unexpected logit shape {logits.shape}. Assigning 0.5.\"); probs = np.full(len(batch_texts), 0.5)\n                llm_probs.extend(probs.tolist())\n            except Exception as e: print(f\"Error during LLM batch {i // batch_size}: {e}\"); llm_probs.extend([0.5] * len(batch_texts))\n            if i % (batch_size * 20) == 0: gc.collect()\n    print(\"LLM prediction feature generated.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); print(\"--- Finished LLM Inference ---\")\n    if len(llm_probs) != len(texts): print(f\"CRITICAL WARNING: Length mismatch {len(llm_probs)} vs {len(texts)}. Padding/Truncating.\"); llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)]\n    return np.array(llm_probs)\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (Handles 'llm_pred') - Unchanged\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, includes llm_pred if present.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']; self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']; self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']; self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n    def extract_base_features(self, df):\n        features = pd.DataFrame(index=df.index);\n        if 'llm_pred' in df.columns: features['llm_pred'] = df['llm_pred']\n        answers = df['answer'].fillna(''); features['text_length'] = answers.str.len(); features['word_count'] = answers.str.split().str.len(); features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6); features['sentence_count'] = answers.str.count(r'[.!?]+'); features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6); features['comma_count'] = answers.str.count(','); features['period_count'] = answers.str.count(r'\\.'); features['exclamation_count'] = answers.str.count(r'!'); features['question_count'] = answers.str.count(r'\\?'); features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6); features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split()))); features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors)); features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words)); features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators)); features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words)); features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6); features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6); features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6); features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6); features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1; features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6); features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True); return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (Handles llm_pred, Tuned Params from v22)\n# -------------------------------------------------------------------\n# (Keep the ChampionAIDetector class exactly as in v22)\nclass ChampionAIDetector:\n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats including llm_pred.\"\"\"\n    def __init__(self, n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL):\n        self.feature_extractor = ChampionFeatureExtractor(); self.n_folds = n_folds; self.n_features = n_features; self.models = {}; self.meta_model = None; self.calibrator = IsotonicRegression(out_of_bounds='clip'); self.scaler = StandardScaler(); self.tfidf_word = None; self.tfidf_char = None; self.selector = None; self.topic_columns = None; self.is_trained = False; print(f\"\\nClassical Detector initialized: {n_folds} folds, SelectKBest(k={n_features}).\")\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        # Handles potential NaN topics gracefully\n        series = series.fillna(\"Unknown_Topic\") # Use a specific name for NaN topics\n        dummies = pd.get_dummies(series, prefix='topic', dtype=int, dummy_na=False) # No dummy_na needed if filled\n        if fit_columns:\n            self.topic_columns = dummies.columns\n            # Ensure 'topic_Unknown_Topic' column exists if NaNs were present\n            if \"topic_Unknown_Topic\" not in self.topic_columns and series.astype(str).str.contains(\"Unknown_Topic\").any():\n                 self.topic_columns = self.topic_columns.append(pd.Index([\"topic_Unknown_Topic\"]))\n            print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates llm_pred.\"\"\"\n        print(\"Extracting base handcrafted + LLM features...\"); train_base_features_df = self.feature_extractor.extract_base_features(train_df); test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        fit_topic_cols = (self.topic_columns is None) or is_full_training\n        train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols)\n        test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        llm_train_feat = train_base_features_df.pop('llm_pred').values.reshape(-1, 1); llm_test_feat = test_base_features_df.pop('llm_pred').values.reshape(-1, 1)\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2500)\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1250)\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        print(\"Combining all feature sets...\"); X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(llm_train_feat)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(llm_test_feat)]).tocsr()\n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            with warnings.catch_warnings(): warnings.filterwarnings('ignore'); self.selector.fit(X_train_full, y_train)\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"\\n--- Starting Classical Ensemble Training ---\"); print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=RANDOM_SEED)\n        oof_preds = {'lgb': np.zeros(len(full_train_df)), 'cat': np.zeros(len(full_train_df)), 'ridge': np.zeros(len(full_train_df))}\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, y_train)):\n            print(f\"\\n{'='*20} Classical Fold {fold+1}/{self.n_folds} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            is_first_fold = (fold == 0); X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=is_first_fold, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=0.3, random_state=RANDOM_SEED + fold, verbose=-1, n_jobs=-1)\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=4, random_seed=RANDOM_SEED + fold, verbose=0, early_stopping_rounds=200, task_type=\"CPU\")\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.0, random_state=RANDOM_SEED + fold); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds['ridge'][val_idx] = ridge_probs\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds['ridge'][val_idx])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"Classical L1 Model OOF Scores:\"); [print(f\"  {name.upper()} OOF AUC: {roc_auc_score(y_train, preds):.8f}\") for name, preds in oof_preds.items()]\n        print(\"\\nTraining Classical L2 Meta-Model...\"); X_meta_train = np.stack(list(oof_preds.values()), axis=1)\n        self.meta_model = LogisticRegression(C=0.5, solver='liblinear', random_state=RANDOM_SEED); self.meta_model.fit(X_meta_train, y_train)\n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCLASSICAL L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\"); print(\"Training Classical Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted classical components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Classical model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Final Classical Ensemble Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final classical model training and prediction...\")\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=True)\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=0.3, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1)\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=4, random_seed=RANDOM_SEED, verbose=0, task_type=\"CPU\")\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.0, random_state=RANDOM_SEED); ridge_final.fit(X_train_full_scaled, y_train_full)\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        print(\"Applying Classical L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Classical Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n# --- (Fallback model - unchanged) ---\ndef champion_fallback():\n    \"\"\"Fallback using basic LGBM, fixed scaler.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler; from scipy.sparse import hstack, csr_matrix; from sklearn.naive_bayes import MultinomialNB\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor(); train_base_features = feature_extractor.extract_base_features(train_df.drop(columns=['llm_pred'], errors='ignore')) # Generic drop\n        test_base_features = feature_extractor.extract_base_features(test_df.drop(columns=['llm_pred'], errors='ignore'))\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns; test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1); test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english'); train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr(); y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1200, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1, reg_alpha=0.3, reg_lambda=0.3)\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\"); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f'); print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION (Loads External Data)\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Augments data, runs LLM inference, runs classical stack.\"\"\"\n    print(\"=\" * 60); print(f\"  Mercor AI Text Detection - CHAMPION v24 (External Data + {LLM_MODEL_NAME})\"); print(\"=\" * 60)\n\n    # --- Load Competition Data ---\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv');\n    test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Original training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n    train_df['source'] = 'competition' # Add source marker\n\n    # --- Load and Prepare External Data ---\n    print(f\"\\nLoading external data from: {EXTERNAL_DATA_PATH}\")\n    try:\n        external_df = pd.read_csv(EXTERNAL_DATA_PATH)\n        print(f\"Loaded external data shape: {external_df.shape}\")\n        # Keep only relevant columns and rename\n        external_df = external_df[['text', 'label', 'source']].copy()\n        external_df.rename(columns={'text': 'answer', 'label': 'is_cheating'}, inplace=True)\n        external_df['is_cheating'] = external_df['is_cheating'].astype(int)\n        # Drop duplicates based on 'answer'\n        external_df.drop_duplicates(subset=['answer'], inplace=True, keep='first')\n        # Assign generic topic\n        external_df['topic'] = 'External_DAIGT'\n        # Add placeholder IDs (optional, but good for structure)\n        external_df['id'] = [f'ext_{i}' for i in range(len(external_df))]\n\n        # Downsample external data\n        if len(external_df) > MAX_EXTERNAL_SAMPLES:\n            print(f\"Downsampling external data from {len(external_df)} to {MAX_EXTERNAL_SAMPLES}...\")\n            # Sample proportionally by class\n            n_samples_per_class = MAX_EXTERNAL_SAMPLES // 2\n            external_df = external_df.groupby('is_cheating', group_keys=False).apply(\n                lambda x: x.sample(min(len(x), n_samples_per_class), random_state=RANDOM_SEED)\n            )\n            print(f\"Downsampled external data shape: {external_df.shape}\")\n\n        # --- Combine Datasets ---\n        print(\"Combining competition and external training data...\")\n        # Select consistent columns before concat\n        cols_to_keep = ['id', 'topic', 'answer', 'is_cheating', 'source']\n        train_df_augmented = pd.concat([train_df[cols_to_keep], external_df[cols_to_keep]], ignore_index=True)\n        train_df_augmented = shuffle(train_df_augmented, random_state=RANDOM_SEED).reset_index(drop=True) # Shuffle and reset index\n        print(f\"Augmented training data shape: {train_df_augmented.shape}\")\n        print(f\"Augmented data cheating ratio: {train_df_augmented['is_cheating'].mean():.4f}\")\n\n    except FileNotFoundError: print(f\"ERROR: External data not found: {EXTERNAL_DATA_PATH}. Using competition data only.\"); train_df_augmented = train_df.copy()\n    except Exception as e: print(f\"ERROR loading external data: {e}. Using competition data only.\"); train_df_augmented = train_df.copy()\n\n    # --- Step 1: Generate LLM predictions ---\n    print(\"\\nGenerating LLM features for combined train data and original test data...\")\n    llm_train_texts = train_df_augmented['answer']\n    llm_test_texts = test_df['answer']\n    llm_preds_combined = get_llm_predictions(pd.concat([llm_train_texts, llm_test_texts]), LLM_MODEL_NAME)\n    train_df_augmented['llm_pred'] = llm_preds_combined[:len(train_df_augmented)]\n    test_df['llm_pred'] = llm_preds_combined[len(train_df_augmented):]\n    print(\"LLM feature ('llm_pred') added to dataframes.\")\n\n    # --- Step 2: Run Classical Ensemble on AUGMENTED data ---\n    classical_detector = ChampionAIDetector(n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL)\n    oof_auc_classical, oof_preds_classical = classical_detector.train_champion_ensemble(train_df_augmented)\n\n    # --- Step 3: Predict on ORIGINAL test data ---\n    print(\"\\nStarting Final Test Set Prediction using Classical Ensemble...\")\n    calibrated_proba, base_proba = classical_detector.predict_champion(train_df_augmented, test_df)\n\n    # Create submission files\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n\n    # Final Output\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\");\n    print(f\"Final Classical Ensemble OOF AUC (on augmented data): {oof_auc_classical:.8f}\")\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    start_time = time.time()\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback; traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache(); end_time = time.time()\n        print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"execution":{"iopub.status.busy":"2025-10-28T06:19:01.704916Z","iopub.execute_input":"2025-10-28T06:19:01.705157Z","iopub.status.idle":"2025-10-28T07:49:22.652218Z","shell.execute_reply.started":"2025-10-28T06:19:01.705139Z","shell.execute_reply":"2025-10-28T07:49:22.651497Z"}}},{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv25: NO External Data + v22 Pipeline + More Regularization\n- REMOVED external data augmentation (DAIGT V2) due to distribution shift.\n- Uses ONLY the original 269 competition training samples.\n- Runs the v22 pipeline:\n    - Inference feature ('llm_pred') from 'abhi099k/ai-text-detector-v-n4.0'.\n    - SelectKBest(k=850).\n    - Classical Ensemble (LGBM, CatBoost, Ridge).\n    - L2 Meta-Model (Logistic Regression).\n- INCREASED regularization slightly again (LGBM alpha/lambda=0.4, CatBoost l2=5, Meta C=0.3).\n\"\"\"\n\n# === General Imports ===\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport gc\nimport warnings\nimport time\nimport os\n\n# === Sklearn Imports ===\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.utils import shuffle # Still useful for internal shuffling if needed\n\n# === GBDT Imports ===\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n# === Hugging Face Imports ===\nprint(\"Installing/Updating transformers...\")\nos.system('pip install -q transformers torch')\nprint(\"Libraries installed.\")\ntry:\n    import torch\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n    from tqdm.auto import tqdm\n    import transformers\n    transformers.logging.set_verbosity_error()\nexcept ImportError as e: print(f\"FATAL ERROR during imports: {e}\"); raise e\n\nprint(\"All libraries imported successfully!\")\n\n# === Configuration ===\nLLM_MODEL_NAME = \"abhi099k/ai-text-detector-v-n4.0\"\nN_SPLITS_CLASSICAL = 5\nN_FEATURES_CLASSICAL = 850\nMAX_LEN_LLM = 512\nRANDOM_SEED = 42\n\n# -------------------------------------------------------------------\n# 0. LLM INFERENCE FUNCTION (Manual Loop - Unchanged)\n# -------------------------------------------------------------------\n# (Keep the get_llm_predictions function exactly as in v21/v22/v25)\ndef get_llm_predictions(texts, model_name):\n    \"\"\"Generates predictions using the specified model via manual inference.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\"); model = None; tokenizer = None\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\"); tokenizer = AutoTokenizer.from_pretrained(model_name)\n        print(f\"Loading Model: {model_name}...\"); model = AutoModelForSequenceClassification.from_pretrained(model_name); model.to(device); model.eval()\n        print(\"Model and Tokenizer loaded successfully.\")\n        positive_label_id = 1; # Assume AI is label 1\n        if hasattr(model.config, \"label2id\"): print(f\"Model labels found: {model.config.label2id}\")\n        print(f\"Assuming positive label ID (AI/Cheating) is: {positive_label_id}\")\n    except Exception as e:\n        print(f\"Error loading model/tokenizer {model_name}: {e}\\nFalling back to 0.5.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); return np.full(len(texts), 0.5)\n    print(f\"Running LLM inference on {len(texts)} texts...\"); llm_probs = []\n    batch_size = 32\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=\"LLM Inference Batches\"):\n            batch_texts = texts[i : i + batch_size].tolist();\n            if not batch_texts: continue\n            try:\n                inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN_LLM).to(device)\n                outputs = model(**inputs); logits = outputs.logits\n                if logits.shape[-1] == 1: probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n                elif logits.shape[-1] == 2: probs_all = torch.softmax(logits, dim=-1); probs = probs_all[:, positive_label_id].cpu().numpy()\n                else: print(f\"Warning: Unexpected logit shape {logits.shape}. Assigning 0.5.\"); probs = np.full(len(batch_texts), 0.5)\n                llm_probs.extend(probs.tolist())\n            except Exception as e: print(f\"Error during LLM batch {i // batch_size}: {e}\"); llm_probs.extend([0.5] * len(batch_texts))\n            if i % (batch_size * 20) == 0: gc.collect(); torch.cuda.empty_cache() # More frequent cleanup\n    print(\"LLM prediction feature generated.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); print(\"--- Finished LLM Inference ---\")\n    if len(llm_probs) != len(texts): print(f\"CRITICAL WARNING: Length mismatch {len(llm_probs)} vs {len(texts)}. Padding/Truncating.\"); llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)]\n    return np.array(llm_probs)\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (Handles 'llm_pred') - Unchanged\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, includes llm_pred if present.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']; self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']; self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']; self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n    def extract_base_features(self, df):\n        features = pd.DataFrame(index=df.index);\n        if 'llm_pred' in df.columns: features['llm_pred'] = df['llm_pred']\n        answers = df['answer'].fillna(''); features['text_length'] = answers.str.len(); features['word_count'] = answers.str.split().str.len(); features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6); features['sentence_count'] = answers.str.count(r'[.!?]+'); features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6); features['comma_count'] = answers.str.count(','); features['period_count'] = answers.str.count(r'\\.'); features['exclamation_count'] = answers.str.count(r'!'); features['question_count'] = answers.str.count(r'\\?'); features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6); features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split()))); features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors)); features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words)); features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators)); features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words)); features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6); features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6); features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6); features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6); features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1; features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6); features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        # --- Added Em Dash Features ---\n        features['em_dash_count'] = answers.str.count('')\n        features['em_dash_ratio'] = features['em_dash_count'] / (features['word_count'] + 1e-6)\n        # --- End Em Dash ---\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True); return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (Handles llm_pred, MORE Regularization)\n# -------------------------------------------------------------------\nclass ChampionAIDetector:\n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats including llm_pred.\"\"\"\n    def __init__(self, n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL):\n        self.feature_extractor = ChampionFeatureExtractor(); self.n_folds = n_folds; self.n_features = n_features; self.models = {}; self.meta_model = None; self.calibrator = IsotonicRegression(out_of_bounds='clip'); self.scaler = StandardScaler(); self.tfidf_word = None; self.tfidf_char = None; self.selector = None; self.topic_columns = None; self.is_trained = False; print(f\"\\nClassical Detector initialized: {n_folds} folds, SelectKBest(k={n_features}).\")\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        series = series.fillna(\"Unknown_Topic\"); dummies = pd.get_dummies(series, prefix='topic', dtype=int, dummy_na=False)\n        if fit_columns:\n            self.topic_columns = dummies.columns\n            if \"topic_Unknown_Topic\" not in self.topic_columns and series.astype(str).str.contains(\"Unknown_Topic\").any(): self.topic_columns = self.topic_columns.append(pd.Index([\"topic_Unknown_Topic\"]))\n            print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates llm_pred.\"\"\"\n        print(\"Extracting base handcrafted + LLM features...\"); train_base_features_df = self.feature_extractor.extract_base_features(train_df); test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        fit_topic_cols = (self.topic_columns is None) or is_full_training\n        train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        llm_train_feat = train_base_features_df.pop('llm_pred').values.reshape(-1, 1); llm_test_feat = test_base_features_df.pop('llm_pred').values.reshape(-1, 1)\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2500) # Keep moderate size\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1250) # Keep moderate size\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        print(\"Combining all feature sets...\"); X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(llm_train_feat)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(llm_test_feat)]).tocsr()\n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            with warnings.catch_warnings(): warnings.filterwarnings('ignore'); self.selector.fit(X_train_full, y_train)\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n\n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"\\n--- Starting Classical Ensemble Training ---\"); print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=RANDOM_SEED)\n        oof_preds = {'lgb': np.zeros(len(full_train_df)), 'cat': np.zeros(len(full_train_df)), 'ridge': np.zeros(len(full_train_df))}\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        # --- Fit preprocessing ONCE before folding ---\n        print(\"\\nFitting Scalers, TFIDF, and Selector on FULL training data...\")\n        _ = self.prepare_champion_features(full_train_df, full_train_df, is_training_fold=True, is_full_training=True) # Fit preprocessing objects\n        print(\"\\nStarting K-Fold Training...\")\n\n        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, y_train)):\n            print(f\"\\n{'='*20} Classical Fold {fold+1}/{self.n_folds} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            # --- Prepare features using FITTED objects ---\n            X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=False, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n\n            fold_seed = RANDOM_SEED + fold\n            # --- MORE Regularization ---\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.4, reg_lambda=0.4, random_state=fold_seed, verbose=-1, n_jobs=-1)\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=5, random_seed=fold_seed, verbose=0, early_stopping_rounds=200, task_type=\"CPU\")\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.0, random_state=fold_seed); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds['ridge'][val_idx] = ridge_probs\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds['ridge'][val_idx])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"Classical L1 Model OOF Scores:\"); [print(f\"  {name.upper()} OOF AUC: {roc_auc_score(y_train, preds):.8f}\") for name, preds in oof_preds.items()]\n        # --- MORE Regularization ---\n        print(\"\\nTraining Classical L2 Meta-Model...\"); X_meta_train = np.stack(list(oof_preds.values()), axis=1)\n        self.meta_model = LogisticRegression(C=0.3, solver='liblinear', random_state=RANDOM_SEED); self.meta_model.fit(X_meta_train, y_train)\n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCLASSICAL L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\"); print(\"Training Classical Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted classical components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Classical model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Final Classical Ensemble Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final classical model training and prediction...\")\n        # Use FITTED preprocessing objects\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=False) # Use is_full_training=False\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        # --- MORE Regularization ---\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.4, reg_lambda=0.4, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1)\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=5, random_seed=RANDOM_SEED, verbose=0, task_type=\"CPU\")\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.0, random_state=RANDOM_SEED); ridge_final.fit(X_train_full_scaled, y_train_full)\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        print(\"Applying Classical L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Classical Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n# --- (Fallback model - unchanged) ---\ndef champion_fallback():\n    \"\"\"Fallback using basic LGBM, basic features.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler; from scipy.sparse import hstack, csr_matrix;\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor(); train_base_features = feature_extractor.extract_base_features(train_df)\n        test_base_features = feature_extractor.extract_base_features(test_df)\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns; test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1); test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english'); train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr(); y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1000, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1, reg_alpha=0.1, reg_lambda=0.1) # Basic params\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\"); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f'); print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION (No External Data)\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Runs LLM inference feature gen + classical stack on original data.\"\"\"\n    print(\"=\" * 60); print(f\"  Mercor AI Text Detection - CHAMPION v25 (No External Data + More Regularization)\"); print(\"=\" * 60)\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n    # --- Step 1: Generate LLM predictions on ORIGINAL train/test ---\n    all_texts = pd.concat([train_df['answer'], test_df['answer']])\n    llm_preds = get_llm_predictions(all_texts, LLM_MODEL_NAME)\n    train_df['llm_pred'] = llm_preds[:len(train_df)]; test_df['llm_pred'] = llm_preds[len(train_df):]\n    print(\"LLM feature ('llm_pred') added to dataframes.\")\n    # --- Step 2: Run Classical Ensemble ---\n    classical_detector = ChampionAIDetector(n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL)\n    oof_auc_classical, oof_preds_classical = classical_detector.train_champion_ensemble(train_df)\n    print(\"\\nStarting Final Test Set Prediction using Classical Ensemble...\")\n    calibrated_proba, base_proba = classical_detector.predict_champion(train_df, test_df)\n    # Create submission files\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n    # Final Output\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\");\n    print(f\"Final Classical Ensemble OOF AUC (NO external data): {oof_auc_classical:.8f}\") # Added note\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    start_time = time.time()\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback; traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache(); end_time = time.time()\n        print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"execution":{"iopub.status.busy":"2025-10-31T19:08:20.221888Z","iopub.execute_input":"2025-10-31T19:08:20.222547Z","iopub.status.idle":"2025-10-31T19:11:35.849659Z","shell.execute_reply.started":"2025-10-31T19:08:20.222514Z","shell.execute_reply":"2025-10-31T19:11:35.848793Z"}}},{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv27: Dual Calibrated LLM Features + L2 Classical Stack\n- FIXES the 'token_type_ids' error for Desklib by manually passing inputs.\n- FIXES the 'size mismatch' error for Abhi by using the STANDARD\n  AutoModelForSequenceClassification loader for it.\n- Generates TWO calibrated LLM features:\n  1. 'llm_pred_desklib' (from desklib/ai-text-detector-v1.01)\n  2. 'llm_pred_abhi' (from abhi099k/ai-text-detector-deberta-v3-large-h1)\n- Feeds BOTH features into the proven v25.3 classical pipeline\n  (L2 Stack, SelectKBest(k=850), all handcrafted features, strong reg).\n\"\"\"\n\n# === General Imports ===\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport gc\nimport warnings\nimport time\nimport os\n\n# === Sklearn Imports ===\nfrom sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.utils import shuffle\n\n# === GBDT Imports ===\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n# === Hugging Face Imports ===\nprint(\"Installing/Updating transformers...\"); os.system('pip install -q transformers torch'); print(\"Libraries installed.\")\ntry:\n    import torch\n    import torch.nn as nn\n    # --- MODIFIED: Need AutoModel, AutoConfig, PreTrainedModel for custom class ---\n    from transformers import AutoTokenizer, AutoModel, AutoConfig, PreTrainedModel, AutoModelForSequenceClassification\n    from tqdm.auto import tqdm\n    import transformers\n    transformers.logging.set_verbosity_error()\nexcept ImportError as e: print(f\"FATAL ERROR during imports: {e}\"); raise e\nprint(\"All libraries imported successfully!\")\n\n# === Configuration ===\n# --- TWO LLM MODELS ---\nLLM_MODEL_NAME_1 = \"desklib/ai-text-detector-v1.01\"\nLLM_MODEL_NAME_2 = \"abhi099k/ai-text-detector-deberta-v3-large-h1\"\nN_SPLITS_CLASSICAL = 5\nN_FEATURES_CLASSICAL = 850\nMAX_LEN_LLM = 512\nRANDOM_SEED = 42\n\n# -------------------------------------------------------------------\n# 0a. CUSTOM LLM CLASS (for Desklib)\n# -------------------------------------------------------------------\nclass DesklibAIDetectionModel(PreTrainedModel):\n    \"\"\"Custom model class for models with this specific head.\"\"\"\n    config_class = AutoConfig\n    def __init__(self, config):\n        super().__init__(config)\n        self.model = AutoModel.from_config(config)\n        self.classifier = nn.Linear(config.hidden_size, 1)\n        self.init_weights()\n    def forward(self, input_ids, attention_mask=None, labels=None):\n        outputs = self.model(input_ids, attention_mask=attention_mask)\n        last_hidden_state = outputs[0]\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, dim=1)\n        sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n        pooled_output = sum_embeddings / sum_mask\n        logits = self.classifier(pooled_output)\n        loss = None\n        if labels is not None:\n            loss_fct = nn.BCEWithLogitsLoss()\n            loss = loss_fct(logits.view(-1), labels.float())\n        output = {\"logits\": logits}\n        if loss is not None: output[\"loss\"] = loss\n        return output\n\n# -------------------------------------------------------------------\n# 0b. LLM INFERENCE FUNCTION (for Desklib - WITH BUG FIX)\n# -------------------------------------------------------------------\ndef get_desklib_predictions(texts, model_name):\n    \"\"\"Generates predictions using the specified CUSTOM Desklib model class.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\"); model = None; tokenizer = None\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\"); tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n        print(f\"Loading Model (Custom Class): {model_name}...\"); \n        model = DesklibAIDetectionModel.from_pretrained(model_name, trust_remote_code=True)\n        model.to(device); model.eval()\n        print(\"Model and Tokenizer loaded successfully.\")\n    except Exception as e:\n        print(f\"Error loading model/tokenizer {model_name}: {e}\\nFalling back to 0.5.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); return np.full(len(texts), 0.5)\n    \n    print(f\"Running LLM inference on {len(texts)} texts...\")\n    batch_size = 16 # Keep batch size small for 'large' models\n    print(f\"Using batch size: {batch_size}\")\n    \n    llm_probs = []\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=f\"LLM 1 ({model_name.split('/')[1]})\"):\n            batch_texts = texts[i : i + batch_size].tolist();\n            if not batch_texts: continue\n            try:\n                inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN_LLM)\n                # --- THE BUG FIX ---\n                input_ids = inputs['input_ids'].to(device)\n                attention_mask = inputs['attention_mask'].to(device)\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n                # --- END BUG FIX ---\n                logits = outputs[\"logits\"]\n                probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n                if batch_size == 1 and isinstance(probs, (float, np.floating)): probs = [probs]\n                llm_probs.extend(probs)\n            except Exception as e: \n                print(f\"Error during LLM batch {i // batch_size}: {e}\")\n                if \"out of memory\" in str(e).lower(): print(\"!!! CUDA Out of Memory. Try reducing batch_size. !!!\")\n                llm_probs.extend([0.5] * len(batch_texts))\n            if i % (batch_size * 20) == 0: gc.collect(); torch.cuda.empty_cache()\n            \n    print(f\"LLM 1 ({model_name.split('/')[1]}) prediction feature generated.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); print(\"--- Finished LLM 1 Inference ---\")\n    if len(llm_probs) != len(texts): print(f\"CRITICAL WARNING: Length mismatch {len(llm_probs)} vs {len(texts)}. Padding/Truncating.\"); llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)]\n    return np.array(llm_probs)\n\n# -------------------------------------------------------------------\n# 0c. LLM INFERENCE FUNCTION (for Generic Classifiers like Abhi)\n# -------------------------------------------------------------------\ndef get_generic_llm_predictions(texts, model_name):\n    \"\"\"Generates predictions using a STANDARD AutoModelForSequenceClassification.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\"); model = None; tokenizer = None\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\"); tokenizer = AutoTokenizer.from_pretrained(model_name)\n        # --- USE STANDARD LOADER ---\n        print(f\"Loading Model (Standard Class): {model_name}...\"); \n        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n        model.to(device); model.eval()\n        print(\"Model and Tokenizer loaded successfully.\")\n        \n        positive_label_id = -1\n        if hasattr(model.config, \"label2id\"):\n            print(f\"Model labels found: {model.config.label2id}\")\n            for name, id_val in model.config.label2id.items():\n                if \"ai\" in name.lower() or \"fake\" in name.lower() or \"generated\" in name.lower() or name == \"LABEL_1\" or name.upper() == \"AI\":\n                    positive_label_id = id_val\n                    print(f\"Determined positive (AI) label ID: {positive_label_id} ('{name}')\")\n                    break\n        if positive_label_id == -1: positive_label_id = 1; print(f\"Could not determine AI label. Assuming ID {positive_label_id} is positive.\")\n            \n    except Exception as e:\n        print(f\"Error loading model/tokenizer {model_name}: {e}\\nFalling back to 0.5.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); return np.full(len(texts), 0.5)\n    \n    print(f\"Running LLM inference on {len(texts)} texts...\")\n    batch_size = 16 # Keep batch size small for 'large' models\n    print(f\"Using batch size: {batch_size}\")\n    \n    llm_probs = []\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=f\"LLM 2 ({model_name.split('/')[1]})\"):\n            batch_texts = texts[i : i + batch_size].tolist();\n            if not batch_texts: continue\n            try:\n                inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN_LLM).to(device)\n                # --- STANDARD CALL ---\n                outputs = model(**inputs); \n                logits = outputs.logits\n                # --- Use Softmax (model has 2 outputs) ---\n                probs_all = torch.softmax(logits, dim=-1)\n                probs = probs_all[:, positive_label_id].cpu().numpy()\n                if batch_size == 1 and isinstance(probs, (float, np.floating)): probs = [probs]\n                llm_probs.extend(probs.tolist())\n            except Exception as e: \n                print(f\"Error during LLM batch {i // batch_size}: {e}\")\n                if \"out of memory\" in str(e).lower(): print(\"!!! CUDA Out of Memory. Try reducing batch_size. !!!\")\n                llm_probs.extend([0.5] * len(batch_texts))\n            if i % (batch_size * 20) == 0: gc.collect(); torch.cuda.empty_cache()\n            \n    print(f\"LLM 2 ({model_name.split('/')[1]}) prediction feature generated.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); print(\"--- Finished LLM 2 Inference ---\")\n    if len(llm_probs) != len(texts): print(f\"CRITICAL WARNING: Length mismatch {len(llm_probs)} vs {len(texts)}. Padding/Truncating.\"); llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)]\n    return np.array(llm_probs)\n\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (Handles BOTH LLM preds)\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, includes llm_preds, + new features.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']; self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']; self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']; self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n        self.stopwords = set(ENGLISH_STOP_WORDS); self.sentence_splitter = re.compile(r'[.!?]+')\n    def _get_sent_len_var(self, text):\n        sentences = self.sentence_splitter.split(text); sentence_lengths = [len(s.split()) for s in sentences if len(s.split()) > 0]\n        if len(sentence_lengths) > 1: return np.var(sentence_lengths)\n        else: return 0\n    def extract_base_features(self, df):\n        features = pd.DataFrame(index=df.index);\n        # --- ADD BOTH LLM PREDS ---\n        if 'llm_pred_desklib' in df.columns: features['llm_pred_desklib'] = df['llm_pred_desklib']\n        if 'llm_pred_abhi' in df.columns: features['llm_pred_abhi'] = df['llm_pred_abhi']\n        \n        answers = df['answer'].fillna(''); words = answers.str.split(); word_counts = words.str.len()\n        features['text_length'] = answers.str.len(); features['word_count'] = word_counts; features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6); features['sentence_count'] = answers.str.count(r'[.!?]+'); features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6); features['comma_count'] = answers.str.count(','); features['period_count'] = answers.str.count(r'\\.'); features['exclamation_count'] = answers.str.count(r'!'); features['question_count'] = answers.str.count(r'\\?'); features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6); features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split()))); features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors)); features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words)); features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators)); features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words)); features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6); features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6); features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6); features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6); features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1; features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6); features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        features['em_dash_count'] = answers.str.count(''); features['em_dash_ratio'] = features['em_dash_count'] / (features['word_count'] + 1e-6)\n        features['question_mark_count'] = answers.str.count(r'\\?'); features['exclamation_mark_count'] = answers.str.count(r'!')\n        features['stopword_count'] = words.apply(lambda x: sum(1 for word in x if word.lower() in self.stopwords)); features['stopword_ratio'] = features['stopword_count'] / (features['word_count'] + 1e-6)\n        features['uppercase_word_count'] = words.apply(lambda x: sum(1 for word in x if word.isascii() and word.istitle())); features['uppercase_ratio'] = features['uppercase_word_count'] / (features['word_count'] + 1e-6)\n        features['sentence_length_variance'] = answers.apply(self._get_sent_len_var)\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True); return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (L2 Stack model - Handles 2 LLM feats)\n# -------------------------------------------------------------------\nclass ChampionAIDetector: \n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats including 2 llm_preds.\"\"\"\n    def __init__(self, n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL):\n        self.feature_extractor = ChampionFeatureExtractor(); self.n_folds = n_folds; self.n_features = n_features; self.models = {}; self.meta_model = None; self.calibrator = IsotonicRegression(out_of_bounds='clip'); self.scaler = StandardScaler(); self.tfidf_word = None; self.tfidf_char = None; self.selector = None; self.topic_columns = None; self.is_trained = False; print(f\"\\nClassical Detector (L2 Stack): {n_folds} folds, SelectKBest(k={n_features}).\")\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        # (Unchanged)\n        series = series.fillna(\"Unknown_Topic\"); dummies = pd.get_dummies(series, prefix='topic', dtype=int, dummy_na=False)\n        if fit_columns:\n            self.topic_columns = dummies.columns\n            if \"topic_Unknown_Topic\" not in self.topic_columns and series.astype(str).str.contains(\"Unknown_Topic\").any(): self.topic_columns = self.topic_columns.append(pd.Index([\"topic_Unknown_Topic\"]))\n            print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates llm_preds.\"\"\"\n        print(\"Extracting base handcrafted + LLM features...\"); train_base_features_df = self.feature_extractor.extract_base_features(train_df); test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        fit_topic_cols = (self.topic_columns is None) or is_full_training\n        train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        \n        # --- SEPARATE BOTH LLM FEATURES ---\n        llm_train_feat_1 = train_base_features_df.pop('llm_pred_desklib').values.reshape(-1, 1)\n        llm_test_feat_1 = test_base_features_df.pop('llm_pred_desklib').values.reshape(-1, 1)\n        llm_train_feat_2 = train_base_features_df.pop('llm_pred_abhi').values.reshape(-1, 1)\n        llm_test_feat_2 = test_base_features_df.pop('llm_pred_abhi').values.reshape(-1, 1)\n\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2500)\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1250)\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        \n        # --- COMBINE ALL FEATURES (incl. BOTH LLM preds) ---\n        print(\"Combining all feature sets...\"); \n        X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(llm_train_feat_1), csr_matrix(llm_train_feat_2)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(llm_test_feat_1), csr_matrix(llm_test_feat_2)]).tocsr()\n        \n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            with warnings.catch_warnings(): warnings.filterwarnings('ignore'); self.selector.fit(X_train_full, y_train)\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n    \n    # --- L2 STACKING (Using v25.3 params) ---\n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"\\n--- Starting Classical Ensemble Training ---\"); print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=RANDOM_SEED)\n        oof_preds = {'lgb': np.zeros(len(full_train_df)), 'cat': np.zeros(len(full_train_df)), 'ridge': np.zeros(len(full_train_df))}\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        print(\"\\nFitting Scalers, TFIDF, and Selector on FULL training data...\")\n        _ = self.prepare_champion_features(full_train_df, full_train_df, is_training_fold=True, is_full_training=True) # Fit preprocessing objects\n        print(\"\\nStarting K-Fold Training...\")\n        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, y_train)):\n            print(f\"\\n{'='*20} Classical Fold {fold+1}/{self.n_folds} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=False, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n            fold_seed = RANDOM_SEED + fold\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.4, reg_lambda=0.4, random_state=fold_seed, verbose=-1, n_jobs=-1)\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=5, random_seed=fold_seed, verbose=0, early_stopping_rounds=200, task_type=\"CPU\")\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.0, random_state=fold_seed); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds['ridge'][val_idx] = ridge_probs\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds['ridge'][val_idx])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"Classical L1 Model OOF Scores:\"); [print(f\"  {name.upper()} OOF AUC: {roc_auc_score(y_train, preds):.8f}\") for name, preds in oof_preds.items()]\n        print(\"\\nTraining Classical L2 Meta-Model...\"); X_meta_train = np.stack(list(oof_preds.values()), axis=1)\n        self.meta_model = LogisticRegression(C=0.3, solver='liblinear', random_state=RANDOM_SEED); self.meta_model.fit(X_meta_train, y_train)\n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCLASSICAL L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\"); print(\"Training Classical Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted classical components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Classical model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Final Classical Ensemble Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final classical model training and prediction...\")\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=True) # Use is_full_training=True\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.4, reg_lambda=0.4, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1)\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=5, random_seed=RANDOM_SEED, verbose=0, task_type=\"CPU\")\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.0, random_state=RANDOM_SEED); ridge_final.fit(X_train_full_scaled, y_train_full)\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        print(\"Applying Classical L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Classical Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n# --- (Fallback model - unchanged) ---\ndef champion_fallback():\n    \"\"\"Fallback using basic LGBM, basic features.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler; from scipy.sparse import hstack, csr_matrix;\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor(); train_base_features = feature_extractor.extract_base_features(train_df.drop(columns=['llm_pred_desklib', 'llm_pred_abhi'], errors='ignore'))\n        test_base_features = feature_extractor.extract_base_features(test_df.drop(columns=['llm_pred_desklib', 'llm_pred_abhi'], errors='ignore'))\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns; test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1); test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english'); train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr(); y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1000, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1, reg_alpha=0.1, reg_lambda=0.1)\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\"); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f'); print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION (Calibrates BOTH LLM Preds, uses L2 Stack)\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Runs 2 LLM inferences, calibrates features, runs classical L2 stack.\"\"\"\n    print(\"=\" * 60); print(f\"  Mercor AI Text Detection - CHAMPION v27 (Dual LLM + L2 Stack)\"); print(\"=\" * 60)\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n    all_texts = pd.concat([train_df['answer'], test_df['answer']])\n    \n    # --- Step 1A: Generate Desklib predictions ---\n    llm_preds_all_1 = get_desklib_predictions(all_texts, LLM_MODEL_NAME_1)\n    llm_oof_preds_1 = llm_preds_all_1[:len(train_df)]; llm_test_preds_1 = llm_preds_all_1[len(train_df):]\n    print(\"\\nCalibrating Desklib predictions...\"); llm_calibrator_1 = IsotonicRegression(out_of_bounds='clip')\n    llm_calibrator_1.fit(llm_oof_preds_1, train_df['is_cheating'].values)\n    llm_oof_calibrated_1 = llm_calibrator_1.transform(llm_oof_preds_1)\n    llm_test_calibrated_1 = lll_calibrator_1.transform(llm_test_preds_1) # --- TYPO WAS HERE ---\n    llm_test_calibrated_1 = llm_calibrator_1.transform(llm_test_preds_1) # --- FIX ---\n    print(f\"Calibrated Desklib OOF AUC: {roc_auc_score(train_df['is_cheating'], llm_oof_calibrated_1):.8f}\")\n    train_df['llm_pred_desklib'] = llm_oof_calibrated_1\n    test_df['llm_pred_desklib'] = llm_test_calibrated_1\n    print(\"CALIBRATED Desklib feature added.\")\n\n    # --- Step 1B: Generate Abhi predictions ---\n    llm_preds_all_2 = get_generic_llm_predictions(all_texts, LLM_MODEL_NAME_2) # Use the generic loader\n    llm_oof_preds_2 = llm_preds_all_2[:len(train_df)]; llm_test_preds_2 = llm_preds_all_2[len(train_df):]\n    print(\"\\nCalibrating Abhi predictions...\"); llm_calibrator_2 = IsotonicRegression(out_of_bounds='clip')\n    llm_calibrator_2.fit(llm_oof_preds_2, train_df['is_cheating'].values)\n    llm_oof_calibrated_2 = llm_calibrator_2.transform(llm_oof_preds_2)\n    llm_test_calibrated_2 = llm_calibrator_2.transform(llm_test_preds_2)\n    print(f\"Calibrated Abhi OOF AUC: {roc_auc_score(train_df['is_cheating'], llm_oof_calibrated_2):.8f}\")\n    train_df['llm_pred_abhi'] = llm_oof_calibrated_2\n    test_df['llm_pred_abhi'] = llm_test_calibrated_2\n    print(\"CALIBRATED Abhi feature added.\")\n    \n    # --- Step 2: Run Classical L2 Stack Ensemble ---\n    classical_detector = ChampionAIDetector(n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL) # L2 Stack class\n    oof_auc_classical, oof_preds_classical = classical_detector.train_champion_ensemble(train_df)\n    print(\"\\nStarting Final Test Set Prediction using L2 Stack...\");\n    calibrated_proba, base_proba = classical_detector.predict_champion(train_df, test_df)\n    \n    # Create submission files\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n    # Final Output\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\");\n    print(f\"Final L2 Stack OOF AUC (with DUAL Calibrated LLM Feats): {oof_auc_classical:.8f}\")\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv (Backup)\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    start_time = time.time()\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback; traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache(); end_time = time.time()\n        print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"execution":{"iopub.status.busy":"2025-11-01T15:51:42.985273Z","iopub.execute_input":"2025-11-01T15:51:42.985618Z","iopub.status.idle":"2025-11-01T15:52:46.812082Z","shell.execute_reply.started":"2025-11-01T15:51:42.985586Z","shell.execute_reply":"2025-11-01T15:52:46.811395Z"}}},{"cell_type":"code","source":"id\tis_cheating\n0\tscr_81822029c661\t0.996701\n1\tscr_52efb19e0ea9\t0.999000\n2\tscr_8fc0f33c559e\t0.494624\n3\tscr_bac3f5d3aa12\t0.137097\n4\tscr_adfbe009984d\t0.015537\n...\t...\t...\n259\tscr_9497704e40c5\t0.494624\n260\tscr_df97a5fa0b8f\t0.997403\n261\tscr_6175540a0c81\t0.927039\n262\tscr_fa79a8d5de1c\t0.935484\n263\tscr_8f2dde6f6734\t0.999000","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"d=pd.read_csv(\"/kaggle/working/submission.csv\")\nd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T12:28:56.321896Z","iopub.execute_input":"2025-10-30T12:28:56.322584Z","iopub.status.idle":"2025-10-30T12:28:56.341178Z","shell.execute_reply.started":"2025-10-30T12:28:56.322558Z","shell.execute_reply":"2025-10-30T12:28:56.340650Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv27.1: The \"Fixed Typo\" Dual LLM Version\n- FIXES the 'lll_calibrator_1' NameError in champion_main.\n- Uses the 'desklib' model with the custom class (FIXED).\n- Uses the 'abhi099k/large' model with the standard class (FIXED).\n- Feeds BOTH calibrated features into the proven v25.3 classical stack.\n\"\"\"\n\n# === General Imports ===\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport gc\nimport warnings\nimport time\nimport os\n\n# === Sklearn Imports ===\nfrom sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.utils import shuffle\n\n# === GBDT Imports ===\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n# === Hugging Face Imports ===\nprint(\"Installing/Updating transformers...\"); os.system('pip install -q transformers torch'); print(\"Libraries installed.\")\ntry:\n    import torch\n    import torch.nn as nn\n    from transformers import AutoTokenizer, AutoModel, AutoConfig, PreTrainedModel, AutoModelForSequenceClassification\n    from tqdm.auto import tqdm\n    import transformers\n    transformers.logging.set_verbosity_error()\nexcept ImportError as e: print(f\"FATAL ERROR during imports: {e}\"); raise e\nprint(\"All libraries imported successfully!\")\n\n# === Configuration ===\nLLM_MODEL_NAME_1 = \"desklib/ai-text-detector-v1.01\"\nLLM_MODEL_NAME_2 = \"abhi099k/ai-text-detector-deberta-v3-large-h1\"\nN_SPLITS_CLASSICAL = 5\nN_FEATURES_CLASSICAL = 850\nMAX_LEN_LLM = 512\nRANDOM_SEED = 42\n\n# -------------------------------------------------------------------\n# 0a. CUSTOM LLM CLASS (for Desklib)\n# -------------------------------------------------------------------\nclass DesklibAIDetectionModel(PreTrainedModel):\n    \"\"\"Custom model class for models with this specific head.\"\"\"\n    config_class = AutoConfig\n    def __init__(self, config):\n        super().__init__(config)\n        self.model = AutoModel.from_config(config)\n        self.classifier = nn.Linear(config.hidden_size, 1)\n        self.init_weights()\n    def forward(self, input_ids, attention_mask=None, labels=None):\n        outputs = self.model(input_ids, attention_mask=attention_mask)\n        last_hidden_state = outputs[0]\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, dim=1)\n        sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n        pooled_output = sum_embeddings / sum_mask\n        logits = self.classifier(pooled_output)\n        loss = None\n        if labels is not None:\n            loss_fct = nn.BCEWithLogitsLoss()\n            loss = loss_fct(logits.view(-1), labels.float())\n        output = {\"logits\": logits}\n        if loss is not None: output[\"loss\"] = loss\n        return output\n\n# -------------------------------------------------------------------\n# 0b. LLM INFERENCE FUNCTION (for Desklib - WITH BUG FIX)\n# -------------------------------------------------------------------\ndef get_desklib_predictions(texts, model_name):\n    \"\"\"Generates predictions using the specified CUSTOM Desklib model class.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\"); model = None; tokenizer = None\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\"); tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n        print(f\"Loading Model (Custom Class): {model_name}...\"); \n        model = DesklibAIDetectionModel.from_pretrained(model_name, trust_remote_code=True)\n        model.to(device); model.eval()\n        print(\"Model and Tokenizer loaded successfully.\")\n    except Exception as e:\n        print(f\"Error loading model/tokenizer {model_name}: {e}\\nFalling back to 0.5.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); return np.full(len(texts), 0.5)\n    \n    print(f\"Running LLM inference on {len(texts)} texts...\")\n    batch_size = 16 # Keep batch size small for 'large' models\n    print(f\"Using batch size: {batch_size}\")\n    \n    llm_probs = []\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=f\"LLM 1 ({model_name.split('/')[1]})\"):\n            batch_texts = texts[i : i + batch_size].tolist();\n            if not batch_texts: continue\n            try:\n                inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN_LLM)\n                input_ids = inputs['input_ids'].to(device)\n                attention_mask = inputs['attention_mask'].to(device)\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n                logits = outputs[\"logits\"]\n                probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n                if not isinstance(probs, (np.ndarray, list)): probs = [probs.item()] # Handle single item\n                elif isinstance(probs, np.ndarray): probs = probs.tolist()\n                llm_probs.extend(probs)\n            except Exception as e: \n                print(f\"Error during LLM batch {i // batch_size}: {e}\")\n                if \"out of memory\" in str(e).lower(): print(\"!!! CUDA Out of Memory. Try reducing batch_size. !!!\")\n                llm_probs.extend([0.5] * len(batch_texts))\n            if i % (batch_size * 20) == 0: gc.collect(); torch.cuda.empty_cache()\n            \n    print(f\"LLM 1 ({model_name.split('/')[1]}) prediction feature generated.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); print(\"--- Finished LLM 1 Inference ---\")\n    if len(llm_probs) != len(texts): print(f\"CRITICAL WARNING: Length mismatch {len(llm_probs)} vs {len(texts)}. Padding/Truncating.\"); llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)]\n    return np.array(llm_probs)\n\n# -------------------------------------------------------------------\n# 0c. LLM INFERENCE FUNCTION (for Generic Classifiers like Abhi)\n# -------------------------------------------------------------------\ndef get_generic_llm_predictions(texts, model_name):\n    \"\"\"Generates predictions using a STANDARD AutoModelForSequenceClassification.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\"); model = None; tokenizer = None\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\"); tokenizer = AutoTokenizer.from_pretrained(model_name)\n        print(f\"Loading Model (Standard Class): {model_name}...\"); \n        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n        model.to(device); model.eval()\n        print(\"Model and Tokenizer loaded successfully.\")\n        \n        positive_label_id = -1\n        if hasattr(model.config, \"label2id\"):\n            print(f\"Model labels found: {model.config.label2id}\")\n            for name, id_val in model.config.label2id.items():\n                if \"ai\" in name.lower() or \"fake\" in name.lower() or \"generated\" in name.lower() or name == \"LABEL_1\" or name.upper() == \"AI\":\n                    positive_label_id = id_val\n                    print(f\"Determined positive (AI) label ID: {positive_label_id} ('{name}')\")\n                    break\n        if positive_label_id == -1: positive_label_id = 1; print(f\"Could not determine AI label by name. Assuming ID {positive_label_id} is positive.\")\n            \n    except Exception as e:\n        print(f\"Error loading model/tokenizer {model_name}: {e}\\nFalling back to 0.5.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); return np.full(len(texts), 0.5)\n    \n    print(f\"Running LLM inference on {len(texts)} texts...\")\n    batch_size = 16\n    print(f\"Using batch size: {batch_size}\")\n    \n    llm_probs = []\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=f\"LLM 2 ({model_name.split('/')[1]})\"):\n            batch_texts = texts[i : i + batch_size].tolist();\n            if not batch_texts: continue\n            try:\n                inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN_LLM).to(device)\n                outputs = model(**inputs); \n                logits = outputs.logits\n                probs_all = torch.softmax(logits, dim=-1)\n                probs = probs_all[:, positive_label_id].cpu().numpy()\n                if batch_size == 1 and isinstance(probs, (float, np.floating)): probs = [probs]\n                elif isinstance(probs, np.ndarray): probs = probs.tolist()\n                llm_probs.extend(probs)\n            except Exception as e: \n                print(f\"Error during LLM batch {i // batch_size}: {e}\")\n                if \"out of memory\" in str(e).lower(): print(\"!!! CUDA Out of Memory. Try reducing batch_size. !!!\")\n                llm_probs.extend([0.5] * len(batch_texts))\n            if i % (batch_size * 20) == 0: gc.collect(); torch.cuda.empty_cache()\n            \n    print(f\"LLM 2 ({model_name.split('/')[1]}) prediction feature generated.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); print(\"--- Finished LLM 2 Inference ---\")\n    if len(llm_probs) != len(texts): print(f\"CRITICAL WARNING: Length mismatch {len(llm_probs)} vs {len(texts)}. Padding/Truncating.\"); llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)]\n    return np.array(llm_probs)\n\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (Handles BOTH LLM preds)\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, includes llm_preds, + new features.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']; self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']; self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']; self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n        self.stopwords = set(ENGLISH_STOP_WORDS); self.sentence_splitter = re.compile(r'[.!?]+')\n    def _get_sent_len_var(self, text):\n        sentences = self.sentence_splitter.split(text); sentence_lengths = [len(s.split()) for s in sentences if len(s.split()) > 0]\n        if len(sentence_lengths) > 1: return np.var(sentence_lengths)\n        else: return 0\n    def extract_base_features(self, df):\n        features = pd.DataFrame(index=df.index);\n        if 'llm_pred_desklib' in df.columns: features['llm_pred_desklib'] = df['llm_pred_desklib']\n        if 'llm_pred_abhi' in df.columns: features['llm_pred_abhi'] = df['llm_pred_abhi']\n        answers = df['answer'].fillna(''); words = answers.str.split(); word_counts = words.str.len()\n        features['text_length'] = answers.str.len(); features['word_count'] = word_counts; features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6); features['sentence_count'] = answers.str.count(r'[.!?]+'); features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6); features['comma_count'] = answers.str.count(','); features['period_count'] = answers.str.count(r'\\.'); features['exclamation_count'] = answers.str.count(r'!'); features['question_count'] = answers.str.count(r'\\?'); features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6); features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split()))); features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors)); features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words)); features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators)); features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words)); features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6); features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6); features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6); features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6); features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1; features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6); features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        features['em_dash_count'] = answers.str.count(''); features['em_dash_ratio'] = features['em_dash_count'] / (features['word_count'] + 1e-6)\n        features['question_mark_count'] = answers.str.count(r'\\?'); features['exclamation_mark_count'] = answers.str.count(r'!')\n        features['stopword_count'] = words.apply(lambda x: sum(1 for word in x if word.lower() in self.stopwords)); features['stopword_ratio'] = features['stopword_count'] / (features['word_count'] + 1e-6)\n        features['uppercase_word_count'] = words.apply(lambda x: sum(1 for word in x if word.isascii() and word.istitle())); features['uppercase_ratio'] = features['uppercase_word_count'] / (features['word_count'] + 1e-6)\n        features['sentence_length_variance'] = answers.apply(self._get_sent_len_var)\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True); return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (L2 Stack model - Handles 2 LLM feats)\n# -------------------------------------------------------------------\nclass ChampionAIDetector: \n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats including 2 llm_preds.\"\"\"\n    def __init__(self, n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL):\n        self.feature_extractor = ChampionFeatureExtractor(); self.n_folds = n_folds; self.n_features = n_features; self.models = {}; self.meta_model = None; self.calibrator = IsotonicRegression(out_of_bounds='clip'); self.scaler = StandardScaler(); self.tfidf_word = None; self.tfidf_char = None; self.selector = None; self.topic_columns = None; self.is_trained = False; print(f\"\\nClassical Detector (L2 Stack): {n_folds} folds, SelectKBest(k={n_features}).\")\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        # (Unchanged)\n        series = series.fillna(\"Unknown_Topic\"); dummies = pd.get_dummies(series, prefix='topic', dtype=int, dummy_na=False)\n        if fit_columns:\n            self.topic_columns = dummies.columns\n            if \"topic_Unknown_Topic\" not in self.topic_columns and series.astype(str).str.contains(\"Unknown_Topic\").any(): self.topic_columns = self.topic_columns.append(pd.Index([\"topic_Unknown_Topic\"]))\n            print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates llm_preds.\"\"\"\n        print(\"Extracting base handcrafted + LLM features...\"); train_base_features_df = self.feature_extractor.extract_base_features(train_df); test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        fit_topic_cols = (self.topic_columns is None) or is_full_training\n        train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        \n        # --- SEPARATE BOTH LLM FEATURES ---\n        llm_train_feat_1 = train_base_features_df.pop('llm_pred_desklib').values.reshape(-1, 1)\n        llm_test_feat_1 = test_base_features_df.pop('llm_pred_desklib').values.reshape(-1, 1)\n        llm_train_feat_2 = train_base_features_df.pop('llm_pred_abhi').values.reshape(-1, 1)\n        llm_test_feat_2 = test_base_features_df.pop('llm_pred_abhi').values.reshape(-1, 1)\n\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2500)\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1250)\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        \n        # --- COMBINE ALL FEATURES (incl. BOTH LLM preds) ---\n        print(\"Combining all feature sets...\"); \n        X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(llm_train_feat_1), csr_matrix(llm_train_feat_2)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(llm_test_feat_1), csr_matrix(llm_test_feat_2)]).tocsr()\n        \n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            with warnings.catch_warnings(): warnings.filterwarnings('ignore'); self.selector.fit(X_train_full, y_train)\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n    \n    # --- L2 STACKING (Using v25.3 params) ---\n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"\\n--- Starting Classical Ensemble Training ---\"); print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=RANDOM_SEED)\n        oof_preds = {'lgb': np.zeros(len(full_train_df)), 'cat': np.zeros(len(full_train_df)), 'ridge': np.zeros(len(full_train_df))}\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        print(\"\\nFitting Scalers, TFIDF, and Selector on FULL training data...\")\n        _ = self.prepare_champion_features(full_train_df, full_train_df, is_training_fold=True, is_full_training=True) # Fit preprocessing objects\n        print(\"\\nStarting K-Fold Training...\")\n        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, y_train)):\n            print(f\"\\n{'='*20} Classical Fold {fold+1}/{self.n_folds} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=False, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n            fold_seed = RANDOM_SEED + fold\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.4, reg_lambda=0.4, random_state=fold_seed, verbose=-1, n_jobs=-1)\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=5, random_seed=fold_seed, verbose=0, early_stopping_rounds=200, task_type=\"CPU\")\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.0, random_state=fold_seed); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds['ridge'][val_idx] = ridge_probs\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds['ridge'][val_idx])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"Classical L1 Model OOF Scores:\"); [print(f\"  {name.upper()} OOF AUC: {roc_auc_score(y_train, preds):.8f}\") for name, preds in oof_preds.items()]\n        print(\"\\nTraining Classical L2 Meta-Model...\"); X_meta_train = np.stack(list(oof_preds.values()), axis=1)\n        self.meta_model = LogisticRegression(C=0.3, solver='liblinear', random_state=RANDOM_SEED); self.meta_model.fit(X_meta_train, y_train)\n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCLASSICAL L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\"); print(\"Training Classical Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted classical components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Classical model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Final Classical Ensemble Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final classical model training and prediction...\")\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=True) # Use is_full_training=True\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.4, reg_lambda=0.4, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1)\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=5, random_seed=RANDOM_SEED, verbose=0, task_type=\"CPU\")\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.0, random_state=RANDOM_SEED); ridge_final.fit(X_train_full_scaled, y_train_full)\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        print(\"Applying Classical L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Classical Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n# --- (Fallback model - unchanged) ---\ndef champion_fallback():\n    \"\"\"Fallback using basic LGBM, basic features.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler; from scipy.sparse import hstack, csr_matrix;\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor(); train_base_features = feature_extractor.extract_base_features(train_df.drop(columns=['llm_pred_desklib', 'llm_pred_abhi'], errors='ignore'))\n        test_base_features = feature_extractor.extract_base_features(test_df.drop(columns=['llm_pred_desklib', 'llm_pred_abhi'], errors='ignore'))\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns; test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1); test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english'); train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr(); y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1000, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1, reg_alpha=0.1, reg_lambda=0.1)\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\"); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f'); print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION (Calibrates BOTH LLM Preds, uses L2 Stack)\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Runs 2 LLM inferences, calibrates features, runs classical L2 stack.\"\"\"\n    print(\"=\" * 60); print(f\"  Mercor AI Text Detection - CHAMPION v27 (Dual LLM + L2 Stack)\"); print(\"=\" * 60)\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n    all_texts = pd.concat([train_df['answer'], test_df['answer']])\n    \n    # --- Step 1A: Generate Desklib predictions ---\n    llm_preds_all_1 = get_desklib_predictions(all_texts, LLM_MODEL_NAME_1)\n    llm_oof_preds_1 = llm_preds_all_1[:len(train_df)]; llm_test_preds_1 = llm_preds_all_1[len(train_df):]\n    print(\"\\nCalibrating Desklib predictions...\"); llm_calibrator_1 = IsotonicRegression(out_of_bounds='clip')\n    llm_calibrator_1.fit(llm_oof_preds_1, train_df['is_cheating'].values)\n    llm_oof_calibrated_1 = llm_calibrator_1.transform(llm_oof_preds_1)\n    # --- *** THE FIX IS HERE *** ---\n    llm_test_calibrated_1 = llm_calibrator_1.transform(llm_test_preds_1) # Fixed typo 'lll_calibrator_1'\n    # --- *** END FIX *** ---\n    print(f\"Calibrated Desklib OOF AUC: {roc_auc_score(train_df['is_cheating'], llm_oof_calibrated_1):.8f}\")\n    train_df['llm_pred_desklib'] = llm_oof_calibrated_1\n    test_df['llm_pred_desklib'] = llm_test_calibrated_1\n    print(\"CALIBRATED Desklib feature added.\")\n\n    # --- Step 1B: Generate Abhi predictions ---\n    llm_preds_all_2 = get_generic_llm_predictions(all_texts, LLM_MODEL_NAME_2) # Use the generic loader\n    llm_oof_preds_2 = llm_preds_all_2[:len(train_df)]; llm_test_preds_2 = llm_preds_all_2[len(train_df):]\n    print(\"\\nCalibrating Abhi predictions...\"); llm_calibrator_2 = IsotonicRegression(out_of_bounds='clip')\n    llm_calibrator_2.fit(llm_oof_preds_2, train_df['is_cheating'].values)\n    llm_oof_calibrated_2 = llm_calibrator_2.transform(llm_oof_preds_2)\n    llm_test_calibrated_2 = llm_calibrator_2.transform(llm_test_preds_2)\n    print(f\"Calibrated Abhi OOF AUC: {roc_auc_score(train_df['is_cheating'], llm_oof_calibrated_2):.8f}\")\n    train_df['llm_pred_abhi'] = llm_oof_calibrated_2\n    test_df['llm_pred_abhi'] = llm_test_calibrated_2\n    print(\"CALIBRATED Abhi feature added.\")\n    \n    # --- Step 2: Run Classical L2 Stack Ensemble ---\n    classical_detector = ChampionAIDetector(n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL) # L2 Stack class\n    oof_auc_classical, oof_preds_classical = classical_detector.train_champion_ensemble(train_df)\n    print(\"\\nStarting Final Test Set Prediction using L2 Stack...\");\n    calibrated_proba, base_proba = classical_detector.predict_champion(train_df, test_df)\n    \n    # Create submission files\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n    # Final Output\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\");\n    print(f\"Final L2 Stack OOF AUC (with DUAL Calibrated LLM Feats): {oof_auc_classical:.8f}\")\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv (Backup)\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    start_time = time.time()\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback; traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache(); end_time = time.time()\n        print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"execution":{"iopub.status.busy":"2025-11-01T15:56:12.915972Z","iopub.execute_input":"2025-11-01T15:56:12.916340Z","iopub.status.idle":"2025-11-01T16:01:38.722889Z","shell.execute_reply.started":"2025-11-01T15:56:12.916314Z","shell.execute_reply":"2025-11-01T16:01:38.722255Z"}}},{"cell_type":"markdown","source":"Installing/Updating transformers...0.98878\nLibraries installed.\nAll libraries imported successfully!\n============================================================\n  Mercor AI Text Detection - CHAMPION v27 (Dual LLM + L2 Stack)\n============================================================\nTraining data shape: (269, 4)\nTest data shape: (264, 3)\n\n--- Starting LLM Inference (desklib/ai-text-detector-v1.01) ---\nUsing device: cuda\nLoading Tokenizer: desklib/ai-text-detector-v1.01...\nLoading Model (Custom Class): desklib/ai-text-detector-v1.01...\nModel and Tokenizer loaded successfully.\nRunning LLM inference on 533 texts...\nUsing batch size: 16\nLLM1(ai-text-detector-v1.01):100%\n34/34[00:57<00:00,1.45s/it]\nLLM 1 (ai-text-detector-v1.01) prediction feature generated.\n--- Finished LLM 1 Inference ---\n\nCalibrating Desklib predictions...\nCalibrated Desklib OOF AUC: 0.96113527\nCALIBRATED Desklib feature added.\n\n--- Starting LLM Inference (abhi099k/ai-text-detector-deberta-v3-large-h1) ---\nUsing device: cuda\nLoading Tokenizer: abhi099k/ai-text-detector-deberta-v3-large-h1...\nLoading Model (Standard Class): abhi099k/ai-text-detector-deberta-v3-large-h1...\nModel and Tokenizer loaded successfully.\nModel labels found: {'LABEL_0': 0, 'LABEL_1': 1}\nDetermined positive (AI) label ID: 1 ('LABEL_1')\nRunning LLM inference on 533 texts...\nUsing batch size: 16\nLLM2(ai-text-detector-deberta-v3-large-h1):100%\n34/34[01:01<00:00,1.55s/it]\nLLM 2 (ai-text-detector-deberta-v3-large-h1) prediction feature generated.\n--- Finished LLM 2 Inference ---\n\nCalibrating Abhi predictions...\nCalibrated Abhi OOF AUC: 0.51463700\nCALIBRATED Abhi feature added.\n\nClassical Detector (L2 Stack): 5 folds, SelectKBest(k=850).\n\n--- Starting Classical Ensemble Training ---\nTraining set size: 269\nPositive class ratio: 0.546468\nFitting topic columns on full training data...\nIdentified 268 topic columns during fit.\n\nFitting Scalers, TFIDF, and Selector on FULL training data...\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nIdentified 268 topic columns during fit.\nFitting/Transforming dense features (excl. LLM)...\nFitting Word TF-IDF...\nFitting Char TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(269, 3684), Test=(269, 3684)\nFitting SelectKBest (k=850)...\nFinal training feature shape: (269, 850)\nFinal testing feature shape: (269, 850)\n\nStarting K-Fold Training...\n\n==================== Classical Fold 1/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3684), Test=(54, 3684)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 1: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nFold 1 LGB AUC: 0.997222\nFold 1 CAT AUC: 0.998611\nFold 1 RIDGE AUC: 0.986111\n\n==================== Classical Fold 2/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3684), Test=(54, 3684)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 2: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nFold 2 LGB AUC: 1.000000\nFold 2 CAT AUC: 1.000000\nFold 2 RIDGE AUC: 0.998611\n\n==================== Classical Fold 3/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3684), Test=(54, 3684)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 3: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nFold 3 LGB AUC: 0.965517\nFold 3 CAT AUC: 0.961379\nFold 3 RIDGE AUC: 0.982069\n\n==================== Classical Fold 4/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3684), Test=(54, 3684)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 4: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nFold 4 LGB AUC: 0.968276\nFold 4 CAT AUC: 0.983448\nFold 4 RIDGE AUC: 0.976552\n\n==================== Classical Fold 5/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(216, 3684), Test=(53, 3684)\nFinal training feature shape: (216, 850)\nFinal testing feature shape: (53, 850)\nFold 5: Train shape (216, 850), Val shape (53, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nFold 5 LGB AUC: 0.987069\nFold 5 CAT AUC: 0.994253\nFold 5 RIDGE AUC: 0.979885\n\n==================================================\nClassical L1 Model OOF Scores:\n  LGB OOF AUC: 0.98488904\n  CAT OOF AUC: 0.98695216\n  RIDGE OOF AUC: 0.98165496\n\nTraining Classical L2 Meta-Model...\n\nCLASSICAL L2 STACKING OOF AUC: 0.98895952\nTraining Classical Isotonic Calibrator...\n\nStarting Final Test Set Prediction using L2 Stack...\n\n==================================================\nGenerating Final Classical Ensemble Predictions...\n==================================================\nPreparing features for final classical model training and prediction...\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nIdentified 268 topic columns during fit.\nFitting/Transforming dense features (excl. LLM)...\nFitting Word TF-IDF...\nFitting Char TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(269, 3684), Test=(264, 3684)\nFitting SelectKBest (k=850)...\nFinal training feature shape: (269, 850)\nFinal testing feature shape: (264, 850)\nTraining final LightGBM...\nTraining final CatBoost...\nTraining final Ridge...\nApplying Classical L2 Meta-Model...\nApplying Classical Isotonic Calibration...\n\n============================================================\nCHAMPION PIPELINE COMPLETED SUCCESSFULLY!\nFinal L2 Stack OOF AUC (with DUAL Calibrated LLM Feats): 0.98895952\n\nSubmission files created:\n  1. submission.csv (RECOMMENDED)\n  2. submission_base_uncalibrated.csv (Backup)\n\nFinal 'submission.csv' prediction statistics:\n  Min: 0.001000\n  Max: 0.999000\n  Mean: 0.552944\n  Median: 0.969697\n\nTop 10 Predictions:\n              id  is_cheating\nscr_81822029c661     0.909091\nscr_52efb19e0ea9     0.999000\nscr_8fc0f33c559e     0.055556\nscr_bac3f5d3aa12     0.001000\nscr_adfbe009984d     0.001000\nscr_9e08ece19277     0.999000\nscr_0e34514f3cd4     0.969697\nscr_b10d808b5528     0.999000\nscr_2024f1e7bf94     0.173913\nscr_aa0b11f10fff     0.001000\n============================================================\n\nTotal execution time: 5.37 minutes","metadata":{}},{"cell_type":"code","source":"d=pd.read_csv(\"/kaggle/working/submission.csv\")\nd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T16:04:41.104544Z","iopub.execute_input":"2025-11-01T16:04:41.105495Z","iopub.status.idle":"2025-11-01T16:04:41.128233Z","shell.execute_reply.started":"2025-11-01T16:04:41.105454Z","shell.execute_reply":"2025-11-01T16:04:41.127611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv27.2: Single *Working* LLM + Max Regularization\n- FIXES the 'llm_oof_calibrated_1' NameError.\n- Uses 'desklib/ai-text-detector-v1.01' loaded with the custom class.\n- KEEPS the RepeatedStratifiedKFold (5 splits, 3 repeats).\n- KEEPS all v25.3 handcrafted features (em dash, stopwords, etc.).\n- KEEPS SelectKBest(k=850).\n- KEEPS L2 Stack (LGBM, CatBoost, Ridge, Meta-LR).\n- INCREASES regularization on all models.\n\"\"\"\n\n# === General Imports ===\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport gc\nimport warnings\nimport time\nimport os\n\n# === Sklearn Imports ===\nfrom sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold # --- Use Repeated ---\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.utils import shuffle\n\n# === GBDT Imports ===\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n# === Hugging Face Imports ===\nprint(\"Installing/Updating transformers...\"); os.system('pip install -q transformers torch'); print(\"Libraries installed.\")\ntry:\n    import torch\n    import torch.nn as nn\n    from transformers import AutoTokenizer, AutoModel, AutoConfig, PreTrainedModel, AutoModelForSequenceClassification\n    from tqdm.auto import tqdm\n    import transformers\n    transformers.logging.set_verbosity_error()\nexcept ImportError as e: print(f\"FATAL ERROR during imports: {e}\"); raise e\nprint(\"All libraries imported successfully!\")\n\n# === Configuration ===\nLLM_MODEL_NAME = \"desklib/ai-text-detector-v1.01\" \nN_SPLITS_CLASSICAL = 5\nN_REPEATS_CLASSICAL = 3\nN_FEATURES_CLASSICAL = 850\nMAX_LEN_LLM = 512\nRANDOM_SEED = 42\n\n# -------------------------------------------------------------------\n# 0a. CUSTOM LLM CLASS (for Desklib)\n# -------------------------------------------------------------------\nclass DesklibAIDetectionModel(PreTrainedModel):\n    \"\"\"Custom model class for models with this specific head.\"\"\"\n    config_class = AutoConfig\n    def __init__(self, config):\n        super().__init__(config)\n        self.model = AutoModel.from_config(config)\n        self.classifier = nn.Linear(config.hidden_size, 1)\n        self.init_weights()\n    def forward(self, input_ids, attention_mask=None, labels=None):\n        outputs = self.model(input_ids, attention_mask=attention_mask)\n        last_hidden_state = outputs[0]\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, dim=1)\n        sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n        pooled_output = sum_embeddings / sum_mask\n        logits = self.classifier(pooled_output)\n        loss = None\n        if labels is not None:\n            loss_fct = nn.BCEWithLogitsLoss()\n            loss = loss_fct(logits.view(-1), labels.float())\n        output = {\"logits\": logits}\n        if loss is not None: output[\"loss\"] = loss\n        return output\n\n# -------------------------------------------------------------------\n# 0b. LLM INFERENCE FUNCTION (for Desklib - WITH BUG FIX)\n# -------------------------------------------------------------------\ndef get_llm_predictions(texts, model_name): # Renamed\n    \"\"\"Generates predictions using the specified CUSTOM Desklib model class.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\"); model = None; tokenizer = None\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\"); tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n        print(f\"Loading Model (Custom Class): {model_name}...\"); \n        model = DesklibAIDetectionModel.from_pretrained(model_name, trust_remote_code=True)\n        model.to(device); model.eval()\n        print(\"Model and Tokenizer loaded successfully.\")\n    except Exception as e:\n        print(f\"Error loading model/tokenizer {model_name}: {e}\\nFalling back to 0.5.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); return np.full(len(texts), 0.5)\n    \n    print(f\"Running LLM inference on {len(texts)} texts...\")\n    batch_size = 16\n    print(f\"Using batch size: {batch_size}\")\n    \n    llm_probs = []\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=f\"LLM ({model_name.split('/')[1]})\"):\n            batch_texts = texts[i : i + batch_size].tolist();\n            if not batch_texts: continue\n            try:\n                inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN_LLM)\n                input_ids = inputs['input_ids'].to(device)\n                attention_mask = inputs['attention_mask'].to(device)\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask) # Fixed call\n                logits = outputs[\"logits\"]\n                probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n                if not isinstance(probs, (np.ndarray, list)): probs = [probs.item()] # Handle single item\n                elif isinstance(probs, np.ndarray): probs = probs.tolist()\n                llm_probs.extend(probs)\n            except Exception as e: \n                print(f\"Error during LLM batch {i // batch_size}: {e}\")\n                if \"out of memory\" in str(e).lower(): print(\"!!! CUDA Out of Memory. Try reducing batch_size. !!!\")\n                llm_probs.extend([0.5] * len(batch_texts))\n            if i % (batch_size * 20) == 0: gc.collect(); torch.cuda.empty_cache()\n            \n    print(f\"LLM ({model_name.split('/')[1]}) prediction feature generated.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); print(\"--- Finished LLM Inference ---\")\n    if len(llm_probs) != len(texts): print(f\"CRITICAL WARNING: Length mismatch {len(llm_probs)} vs {len(texts)}. Padding/Truncating.\"); llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)]\n    return np.array(llm_probs)\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (With New Features)\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, includes llm_pred, + new features.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']; self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']; self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']; self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n        self.stopwords = set(ENGLISH_STOP_WORDS); self.sentence_splitter = re.compile(r'[.!?]+')\n    def _get_sent_len_var(self, text):\n        sentences = self.sentence_splitter.split(text); sentence_lengths = [len(s.split()) for s in sentences if len(s.split()) > 0]\n        if len(sentence_lengths) > 1: return np.var(sentence_lengths)\n        else: return 0\n    def extract_base_features(self, df):\n        features = pd.DataFrame(index=df.index);\n        if 'llm_pred' in df.columns: features['llm_pred'] = df['llm_pred']\n        answers = df['answer'].fillna(''); words = answers.str.split(); word_counts = words.str.len()\n        features['text_length'] = answers.str.len(); features['word_count'] = word_counts; features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6); features['sentence_count'] = answers.str.count(r'[.!?]+'); features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6); features['comma_count'] = answers.str.count(','); features['period_count'] = answers.str.count(r'\\.'); features['exclamation_count'] = answers.str.count(r'!'); features['question_count'] = answers.str.count(r'\\?'); features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6); features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split()))); features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors)); features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words)); features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators)); features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words)); features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6); features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6); features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6); features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6); features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1; features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6); features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        features['em_dash_count'] = answers.str.count(''); features['em_dash_ratio'] = features['em_dash_count'] / (features['word_count'] + 1e-6)\n        features['question_mark_count'] = answers.str.count(r'\\?'); features['exclamation_mark_count'] = answers.str.count(r'!')\n        features['stopword_count'] = words.apply(lambda x: sum(1 for word in x if word.lower() in self.stopwords)); features['stopword_ratio'] = features['stopword_count'] / (features['word_count'] + 1e-6)\n        features['uppercase_word_count'] = words.apply(lambda x: sum(1 for word in x if word.isascii() and word.istitle())); features['uppercase_ratio'] = features['uppercase_word_count'] / (features['word_count'] + 1e-6)\n        features['sentence_length_variance'] = answers.apply(self._get_sent_len_var)\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True); return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (L2 Stack + Repeated CV + Max Reg)\n# -------------------------------------------------------------------\nclass ChampionAIDetector: \n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats and Repeated CV.\"\"\"\n    def __init__(self, n_splits=N_SPLITS_CLASSICAL, n_repeats=N_REPEATS_CLASSICAL, n_features=N_FEATURES_CLASSICAL):\n        self.feature_extractor = ChampionFeatureExtractor(); self.n_splits = n_splits; self.n_repeats = n_repeats; self.n_features = n_features; self.models = {}; self.meta_model = None; self.calibrator = IsotonicRegression(out_of_bounds='clip'); self.scaler = StandardScaler(); self.tfidf_word = None; self.tfidf_char = None; self.selector = None; self.topic_columns = None; self.is_trained = False\n        print(f\"\\nClassical Detector (L2 Stack + Repeated CV): {n_splits} splits, {n_repeats} repeats, SelectKBest(k={n_features}).\")\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        # (Unchanged)\n        series = series.fillna(\"Unknown_Topic\"); dummies = pd.get_dummies(series, prefix='topic', dtype=int, dummy_na=False)\n        if fit_columns:\n            self.topic_columns = dummies.columns\n            if \"topic_Unknown_Topic\" not in self.topic_columns and series.astype(str).str.contains(\"Unknown_Topic\").any(): self.topic_columns = self.topic_columns.append(pd.Index([\"topic_Unknown_Topic\"]))\n            print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates llm_pred.\"\"\"\n        # (Unchanged from v25.3)\n        print(\"Extracting base handcrafted + LLM features...\"); train_base_features_df = self.feature_extractor.extract_base_features(train_df); test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        fit_topic_cols = (self.topic_columns is None) or is_full_training\n        train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        llm_train_feat = train_base_features_df.pop('llm_pred').values.reshape(-1, 1); llm_test_feat = test_base_features_df.pop('llm_pred').values.reshape(-1, 1)\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2500)\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1250)\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        print(\"Combining all feature sets...\"); X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(llm_train_feat)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(llm_test_feat)]).tocsr()\n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            with warnings.catch_warnings(): warnings.filterwarnings('ignore'); self.selector.fit(X_train_full, y_train)\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n    \n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        # (Unchanged from v25.6)\n        y_train = full_train_df['is_cheating'].values\n        print(f\"\\n--- Starting Classical Ensemble Training ---\"); print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        rskf = RepeatedStratifiedKFold(n_splits=self.n_splits, n_repeats=self.n_repeats, random_state=RANDOM_SEED)\n        oof_preds_lgb = np.zeros((len(full_train_df), self.n_repeats)); oof_preds_cat = np.zeros((len(full_train_df), self.n_repeats)); oof_preds_ridge = np.zeros((len(full_train_df), self.n_repeats))\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        print(\"\\nFitting Scalers, TFIDF, and Selector on FULL training data...\")\n        _ = self.prepare_champion_features(full_train_df, full_train_df, is_training_fold=True, is_full_training=True) # Fit preprocessing objects\n        print(\"\\nStarting Repeated K-Fold Training...\")\n        for fold, (train_idx, val_idx) in enumerate(tqdm(rskf.split(full_train_df, y_train), total=self.n_splits * self.n_repeats, desc=\"CV Folds\")):\n            repeat = fold // self.n_splits; split = fold % self.n_splits\n            print(f\"\\n{'='*20} Repeat {repeat+1}/{self.n_repeats}, Split {split+1}/{self.n_splits} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=False, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n            fold_seed = RANDOM_SEED + fold\n            \n            # --- MAX REGULARIZATION ---\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=25, min_child_samples=25, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=0.5, random_state=fold_seed, verbose=-1, n_jobs=-1) # leaves=25, child=25, reg=0.5\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds_lgb[val_idx, repeat] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=7, random_seed=fold_seed, verbose=0, early_stopping_rounds=200, task_type=\"CPU\") # l2=7\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds_cat[val_idx, repeat] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.5, random_state=fold_seed); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores)) # alpha=1.5\n            oof_preds_ridge[val_idx, repeat] = ridge_probs\n            \n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds_lgb[val_idx, repeat]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds_cat[val_idx, repeat]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds_ridge[val_idx, repeat])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"Averaging OOF Scores across repeats:\")\n        oof_lgb_avg = np.mean(oof_preds_lgb, axis=1); oof_cat_avg = np.mean(oof_preds_cat, axis=1); oof_ridge_avg = np.mean(oof_preds_ridge, axis=1)\n        print(f\"  LGB OOF AUC (Averaged): {roc_auc_score(y_train, oof_lgb_avg):.8f}\")\n        print(f\"  CAT OOF AUC (Averaged): {roc_auc_score(y_train, oof_cat_avg):.8f}\")\n        print(f\"  RIDGE OOF AUC (Averaged): {roc_auc_score(y_train, oof_ridge_avg):.8f}\")\n        print(\"\\nTraining Classical L2 Meta-Model on averaged OOFs...\"); X_meta_train = np.stack([oof_lgb_avg, oof_cat_avg, oof_ridge_avg], axis=1)\n        \n        # --- MAX REGULARIZATION ---\n        self.meta_model = LogisticRegression(C=0.2, solver='liblinear', random_state=RANDOM_SEED); self.meta_model.fit(X_meta_train, y_train) # C=0.2\n        \n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCLASSICAL L2 STACKING OOF AUC (Averaged): {oof_ensemble_auc:.8f}\"); print(\"Training Classical Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted classical components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Classical model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Final Classical Ensemble Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final classical model training and prediction...\")\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=True) # Use is_full_training=True\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        \n        # --- MAX REGULARIZATION ---\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=25, min_child_samples=25, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=0.5, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1) # leaves=25, child=25, reg=0.5\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=7, random_seed=RANDOM_SEED, verbose=0, task_type=\"CPU\") # l2=7\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.5, random_state=RANDOM_SEED); ridge_final.fit(X_train_full_scaled, y_train_full) # alpha=1.5\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        \n        print(\"Applying Classical L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Classical Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n# --- (Fallback model - unchanged) ---\ndef champion_fallback():\n    \"\"\"Fallback using basic LGBM, basic features.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler; from scipy.sparse import hstack, csr_matrix;\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor(); train_base_features = feature_extractor.extract_base_features(train_df.drop(columns=['llm_pred'], errors='ignore'))\n        test_base_features = feature_extractor.extract_base_features(test_df.drop(columns=['llm_pred'], errors='ignore'))\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns; test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1); test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english'); train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr(); y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1000, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1, reg_alpha=0.1, reg_lambda=0.1)\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\"); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f'); print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION (Calibrates LLM Pred, uses L2 Stack)\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Runs LLM inference, calibrates feature, runs classical L2 stack.\"\"\"\n    print(\"=\" * 60); print(f\"  Mercor AI Text Detection - CHAMPION v27.2 (Max Reg)\"); print(\"=\" * 60)\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n    # --- Step 1: Generate LLM predictions ---\n    all_texts = pd.concat([train_df['answer'], test_df['answer']])\n    llm_preds_all = get_llm_predictions(all_texts, LLM_MODEL_NAME) # Using desklib\n    llm_oof_preds_orig = llm_preds_all[:len(train_df)]; llm_test_preds_orig = llm_preds_all[len(train_df):]\n    # --- Step 2: Calibrate LLM predictions ---\n    print(\"\\nCalibrating LLM predictions...\"); llm_calibrator = IsotonicRegression(out_of_bounds='clip')\n    llm_calibrator.fit(llm_oof_preds_orig, train_df['is_cheating'].values)\n    llm_oof_calibrated = llm_calibrator.transform(llm_oof_preds_orig)\n    llm_test_calibrated = llm_calibrator.transform(llm_test_preds_orig) # Fixed typo\n    print(f\"Calibrated Desklib OOF AUC: {roc_auc_score(train_df['is_cheating'], llm_oof_calibrated):.8f}\") # Fixed typo\n    train_df['llm_pred'] = llm_oof_calibrated # Add the single, calibrated LLM feature\n    test_df['llm_pred'] = llm_test_calibrated\n    print(\"CALIBRATED LLM feature ('llm_pred') added to dataframes.\")\n    \n    # --- Step 3: Run Classical L2 Stack Ensemble ---\n    classical_detector = ChampionAIDetector(n_splits=N_SPLITS_CLASSICAL, n_repeats=N_REPEATS_CLASSICAL, n_features=N_FEATURES_CLASSICAL) # L2 Stack class\n    oof_auc_classical, oof_preds_classical = classical_detector.train_champion_ensemble(train_df)\n    print(\"\\nStarting Final Test Set Prediction using L2 Stack...\");\n    calibrated_proba, base_proba = classical_detector.predict_champion(train_df, test_df)\n    \n    # Create submission files\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n    # Final Output\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\");\n    print(f\"Final L2 Stack OOF AUC (with Calibrated LLM Feat): {oof_auc_classical:.8f}\")\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv (Backup)\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    start_time = time.time()\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback; traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache(); end_time = time.time()\n        print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"execution":{"iopub.status.busy":"2025-11-01T16:18:57.122277Z","iopub.execute_input":"2025-11-01T16:18:57.123086Z","iopub.status.idle":"2025-11-01T16:28:07.131265Z","shell.execute_reply.started":"2025-11-01T16:18:57.123060Z","shell.execute_reply":"2025-11-01T16:28:07.130562Z"}}},{"cell_type":"code","source":"dd=pd.read_csv(\"/kaggle/working/submission.csv\")\ndd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T16:32:21.547364Z","iopub.execute_input":"2025-11-01T16:32:21.547707Z","iopub.status.idle":"2025-11-01T16:32:21.559568Z","shell.execute_reply.started":"2025-11-01T16:32:21.547686Z","shell.execute_reply":"2025-11-01T16:32:21.558817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv27.6: The \"4-Horsemen\" L3 Ensemble (0.99+ Push)\n- This is the v27.3 (0.99006 LB score) pipeline.\n- KEEPS the 'desklib' LLM feature, all features, SelectKBest(k=850),\n  RepeatedStratifiedKFold, and Max Regularization.\n- KEEPS the L3 Ensemble (L2 Stack + L2 Weighted Avg).\n- ADDS 'XGBoost' (regularized) to the L1 stack.\n- FINAL L1 STACK: LGBM, CatBoost, Ridge, XGBoost.\n- This is the final, most diverse ensemble.\n\"\"\"\n\n# === General Imports ===\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport gc\nimport warnings\nimport time\nimport os\n\n# === Sklearn Imports ===\nfrom sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.utils import shuffle\n\n# === GBDT Imports ===\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nimport xgboost as xgb # --- ADDED XGBOOST ---\n\n# === Hugging Face Imports ===\n# --- ADDED XGBOOST TO INSTALL ---\nprint(\"Installing/Updating transformers...\"); os.system('pip install -q transformers torch lightgbm catboost xgboost'); print(\"Libraries installed.\")\ntry:\n    import torch\n    import torch.nn as nn\n    from transformers import AutoTokenizer, AutoModel, AutoConfig, PreTrainedModel, AutoModelForSequenceClassification\n    from tqdm.auto import tqdm\n    import transformers\n    transformers.logging.set_verbosity_error()\nexcept ImportError as e: print(f\"FATAL ERROR during imports: {e}\"); raise e\nprint(\"All libraries imported successfully!\")\n\n# === Configuration ===\nLLM_MODEL_NAME = \"desklib/ai-text-detector-v1.01\" \nN_SPLITS_CLASSICAL = 5\nN_REPEATS_CLASSICAL = 3\nN_FEATURES_CLASSICAL = 850\nMAX_LEN_LLM = 512\nRANDOM_SEED = 42\n\n# -------------------------------------------------------------------\n# 0a. CUSTOM LLM CLASS (for Desklib)\n# -------------------------------------------------------------------\nclass DesklibAIDetectionModel(PreTrainedModel):\n    config_class = AutoConfig\n    def __init__(self, config):\n        super().__init__(config)\n        self.model = AutoModel.from_config(config)\n        self.classifier = nn.Linear(config.hidden_size, 1)\n        self.init_weights()\n    def forward(self, input_ids, attention_mask=None, labels=None):\n        outputs = self.model(input_ids, attention_mask=attention_mask)\n        last_hidden_state = outputs[0]\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, dim=1)\n        sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n        pooled_output = sum_embeddings / sum_mask\n        logits = self.classifier(pooled_output)\n        loss = None\n        if labels is not None:\n            loss_fct = nn.BCEWithLogitsLoss()\n            loss = loss_fct(logits.view(-1), labels.float())\n        output = {\"logits\": logits}\n        if loss is not None: output[\"loss\"] = loss\n        return output\n\n# -------------------------------------------------------------------\n# 0b. LLM INFERENCE FUNCTION (for Desklib)\n# -------------------------------------------------------------------\ndef get_llm_predictions(texts, model_name):\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\"); model = None; tokenizer = None\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n    if not torch.cuda.is_available(): print(\"!!! WARNING: No GPU. LLM inference will be VERY SLOW. !!!\")\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\"); tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n        print(f\"Loading Model (Custom Class): {model_name}...\"); \n        model = DesklibAIDetectionModel.from_pretrained(model_name, trust_remote_code=True)\n        model.to(device); model.eval()\n        print(\"Model and Tokenizer loaded successfully.\")\n    except Exception as e:\n        print(f\"Error loading model/tokenizer {model_name}: {e}\\nFalling back to 0.5.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); return np.full(len(texts), 0.5)\n    print(f\"Running LLM inference on {len(texts)} texts...\"); llm_probs = []\n    batch_size = 16\n    print(f\"Using batch size: {batch_size}\")\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=f\"LLM ({model_name.split('/')[1]})\"):\n            batch_texts = texts[i : i + batch_size].tolist();\n            if not batch_texts: continue\n            try:\n                inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN_LLM)\n                input_ids = inputs['input_ids'].to(device)\n                attention_mask = inputs['attention_mask'].to(device)\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n                logits = outputs[\"logits\"]\n                probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n                if not isinstance(probs, (np.ndarray, list)): probs = [probs.item()]\n                elif isinstance(probs, np.ndarray): probs = probs.tolist()\n                llm_probs.extend(probs)\n            except Exception as e: \n                print(f\"Error during LLM batch {i // batch_size}: {e}\")\n                if \"out of memory\" in str(e).lower(): print(\"!!! CUDA Out of Memory !!!\")\n                llm_probs.extend([0.5] * len(batch_texts))\n            if i % (batch_size * 20) == 0: gc.collect(); torch.cuda.empty_cache()\n    print(f\"LLM ({model_name.split('/')[1]}) prediction feature generated.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); print(\"--- Finished LLM Inference ---\")\n    if len(llm_probs) != len(texts): print(f\"CRITICAL WARNING: Length mismatch. Padding/Truncating.\"); llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)]\n    return np.array(llm_probs)\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (With New Features)\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, includes llm_pred, + new features.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']; self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']; self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']; self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n        self.stopwords = set(ENGLISH_STOP_WORDS); self.sentence_splitter = re.compile(r'[.!?]+')\n    def _get_sent_len_var(self, text):\n        sentences = self.sentence_splitter.split(text); sentence_lengths = [len(s.split()) for s in sentences if len(s.split()) > 0]\n        if len(sentence_lengths) > 1: return np.var(sentence_lengths)\n        else: return 0\n    def extract_base_features(self, df):\n        features = pd.DataFrame(index=df.index);\n        if 'llm_pred' in df.columns: features['llm_pred'] = df['llm_pred']\n        answers = df['answer'].fillna(''); words = answers.str.split(); word_counts = words.str.len()\n        features['text_length'] = answers.str.len(); features['word_count'] = word_counts; features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6); features['sentence_count'] = answers.str.count(r'[.!?]+'); features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6); features['comma_count'] = answers.str.count(','); features['period_count'] = answers.str.count(r'\\.'); features['exclamation_count'] = answers.str.count(r'!'); features['question_count'] = answers.str.count(r'\\?'); features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6); features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split()))); features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors)); features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words)); features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators)); features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words)); features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6); features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6); features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6); features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6); features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1; features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6); features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        features['em_dash_count'] = answers.str.count(''); features['em_dash_ratio'] = features['em_dash_count'] / (features['word_count'] + 1e-6)\n        features['question_mark_count'] = answers.str.count(r'\\?'); features['exclamation_mark_count'] = answers.str.count(r'!')\n        features['stopword_count'] = words.apply(lambda x: sum(1 for word in x if word.lower() in self.stopwords)); features['stopword_ratio'] = features['stopword_count'] / (features['word_count'] + 1e-6)\n        features['uppercase_word_count'] = words.apply(lambda x: sum(1 for word in x if word.isascii() and word.istitle())); features['uppercase_ratio'] = features['uppercase_word_count'] / (features['word_count'] + 1e-6)\n        features['sentence_length_variance'] = answers.apply(self._get_sent_len_var)\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True); return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (L3 Ensemble + LGBM/XGB/CAT/Ridge)\n# -------------------------------------------------------------------\nclass ChampionAIDetector: \n    \"\"\"Trains L2 Stack AND L2 Weighted Avg (LGBM, XGB, CAT, Ridge), blends them 50/50.\"\"\"\n    def __init__(self, n_splits=N_SPLITS_CLASSICAL, n_repeats=N_REPEATS_CLASSICAL, n_features=N_FEATURES_CLASSICAL):\n        self.feature_extractor = ChampionFeatureExtractor(); self.n_splits = n_splits; self.n_repeats = n_repeats; self.n_features = n_features; self.models = {}; self.meta_model = None; self.calibrator = IsotonicRegression(out_of_bounds='clip'); self.scaler = StandardScaler(); self.tfidf_word = None; self.tfidf_char = None; self.selector = None; self.topic_columns = None; self.is_trained = False\n        self.l1_weights = None # For Model B\n        print(f\"\\nClassical Detector (L3 Ensemble + 4 Models): {n_splits} splits, {n_repeats} repeats, SelectKBest(k={n_features}).\")\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        # (Unchanged)\n        series = series.fillna(\"Unknown_Topic\"); dummies = pd.get_dummies(series, prefix='topic', dtype=int, dummy_na=False)\n        if fit_columns:\n            self.topic_columns = dummies.columns\n            if \"topic_Unknown_Topic\" not in self.topic_columns and series.astype(str).str.contains(\"Unknown_Topic\").any(): self.topic_columns = self.topic_columns.append(pd.Index([\"topic_Unknown_Topic\"]))\n            print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates llm_pred.\"\"\"\n        # (Unchanged)\n        print(\"Extracting base handcrafted + LLM features...\"); train_base_features_df = self.feature_extractor.extract_base_features(train_df); test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        fit_topic_cols = (self.topic_columns is None) or is_full_training\n        train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        llm_train_feat = train_base_features_df.pop('llm_pred').values.reshape(-1, 1); llm_test_feat = test_base_features_df.pop('llm_pred').values.reshape(-1, 1)\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2500)\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1250)\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        print(\"Combining all feature sets...\"); X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(llm_train_feat)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(llm_test_feat)]).tocsr()\n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            with warnings.catch_warnings(): warnings.filterwarnings('ignore'); self.selector.fit(X_train_full, y_train)\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n    \n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains L1 models, then trains L2 Stack AND L2 Weighted Avg.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"\\n--- Starting Classical Ensemble Training ---\"); print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        rskf = RepeatedStratifiedKFold(n_splits=self.n_splits, n_repeats=self.n_repeats, random_state=RANDOM_SEED)\n        \n        # --- OOF arrays for 4 models ---\n        oof_preds_lgb = np.zeros((len(full_train_df), self.n_repeats))\n        oof_preds_cat = np.zeros((len(full_train_df), self.n_repeats)) # --- ADDED CAT ---\n        oof_preds_ridge = np.zeros((len(full_train_df), self.n_repeats))\n        oof_preds_xgb = np.zeros((len(full_train_df), self.n_repeats)) # --- ADDED XGB ---\n        \n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        print(\"\\nFitting Scalers, TFIDF, and Selector on FULL training data...\")\n        _ = self.prepare_champion_features(full_train_df, full_train_df, is_training_fold=True, is_full_training=True) # Fit preprocessing objects\n        print(\"\\nStarting Repeated K-Fold Training...\")\n        for fold, (train_idx, val_idx) in enumerate(tqdm(rskf.split(full_train_df, y_train), total=self.n_splits * self.n_repeats, desc=\"CV Folds\")):\n            repeat = fold // self.n_splits; split = fold % self.n_splits\n            print(f\"\\n{'='*20} Repeat {repeat+1}/{self.n_repeats}, Split {split+1}/{self.n_splits} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=False, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n            fold_seed = RANDOM_SEED + fold\n            \n            # --- Use Max Reg ---\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2700, learning_rate=0.01, max_depth=7, num_leaves=25, min_child_samples=25, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.6, reg_lambda=0.6, random_state=fold_seed, verbose=-1, n_jobs=-1) \n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds_lgb[val_idx, repeat] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            \n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2600, learning_rate=0.02, depth=6, l2_leaf_reg=8, random_seed=fold_seed, verbose=0, early_stopping_rounds=200, task_type=\"CPU\")\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds_cat[val_idx, repeat] = cat_model.predict_proba(X_val_fold)[:, 1]\n\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=2.0, random_state=fold_seed); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds_ridge[val_idx, repeat] = ridge_probs\n            \n            print(\"Training XGBoost...\"); xgb_model = xgb.XGBClassifier(n_estimators=2800, learning_rate=0.01, max_depth=5, min_child_weight=3, subsample=0.7, colsample_bytree=0.6, gamma=0.1, reg_alpha=0.5, reg_lambda=0.5, random_state=fold_seed, eval_metric='logloss', tree_method='hist', early_stopping_rounds=200, n_jobs=-1)\n            xgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], verbose=False); oof_preds_xgb[val_idx, repeat] = xgb_model.predict_proba(X_val_fold)[:, 1]\n\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds_lgb[val_idx, repeat]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds_cat[val_idx, repeat]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds_ridge[val_idx, repeat]); fold_auc_xgb = roc_auc_score(y_val_fold, oof_preds_xgb[val_idx, repeat])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\"); print(f\"Fold {fold+1} XGB AUC: {fold_auc_xgb:.6f}\")\n        \n        print(\"\\n\" + \"=\"*50); print(\"Averaging OOF Scores across repeats:\")\n        oof_lgb_avg = np.mean(oof_preds_lgb, axis=1); oof_cat_avg = np.mean(oof_preds_cat, axis=1); oof_ridge_avg = np.mean(oof_preds_ridge, axis=1); oof_xgb_avg = np.mean(oof_preds_xgb, axis=1)\n        \n        oof_aucs = {\n            'lgb': roc_auc_score(y_train, oof_lgb_avg),\n            'cat': roc_auc_score(y_train, oof_cat_avg),\n            'ridge': roc_auc_score(y_train, oof_ridge_avg),\n            'xgb': roc_auc_score(y_train, oof_xgb_avg)\n        }\n        print(f\"  LGB OOF AUC (Averaged): {oof_aucs['lgb']:.8f}\")\n        print(f\"  CAT OOF AUC (Averaged): {oof_aucs['cat']:.8f}\")\n        print(f\"  RIDGE OOF AUC (Averaged): {oof_aucs['ridge']:.8f}\")\n        print(f\"  XGB OOF AUC (Averaged): {oof_aucs['xgb']:.8f}\")\n        \n        total_auc = sum(oof_aucs.values())\n        self.l1_weights = {name: auc / total_auc for name, auc in oof_aucs.items()}\n        print(\"Calculated L1 Weights (for Model B):\")\n        for name, weight in self.l1_weights.items(): print(f\"  {name.upper()}: {weight:.4f}\")\n\n        # --- Model B: L2 Weighted Average OOF ---\n        oof_weighted_avg = (oof_lgb_avg * self.l1_weights['lgb'] + \n                            oof_cat_avg * self.l1_weights['cat'] + \n                            oof_ridge_avg * self.l1_weights['ridge'] +\n                            oof_xgb_avg * self.l1_weights['xgb'])\n        oof_auc_weighted = roc_auc_score(y_train, oof_weighted_avg)\n        print(f\"\\nL2 Weighted Avg OOF AUC (Model B): {oof_auc_weighted:.8f}\")\n\n        # --- Model A: L2 Stack OOF ---\n        print(\"\\nTraining L2 Meta-Model (Model A)...\"); \n        X_meta_train = np.stack([oof_lgb_avg, oof_cat_avg, oof_ridge_avg, oof_xgb_avg], axis=1) # 4 models\n        self.meta_model = LogisticRegression(C=0.1, solver='liblinear', random_state=RANDOM_SEED); \n        self.meta_model.fit(X_meta_train, y_train)\n        oof_stack_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]\n        oof_auc_stack = roc_auc_score(y_train, oof_stack_preds)\n        print(f\"L2 Stack OOF AUC (Model A): {oof_auc_stack:.8f}\")\n        \n        # --- L3: Blend OOF Preds for Final Calibration ---\n        oof_final_blend = 0.5 * oof_stack_preds + 0.5 * oof_weighted_avg\n        oof_auc_final_blend = roc_auc_score(y_train, oof_final_blend)\n        \n        print(f\"\\nFINAL L3 BLEND OOF AUC (Averaged): {oof_auc_final_blend:.8f}\"); \n        print(\"Training Final Isotonic Calibrator on L3 Blend...\"); \n        self.calibrator.fit(oof_final_blend, y_train)\n        \n        self.is_trained = True; \n        return oof_auc_final_blend, oof_final_blend\n\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using L3 Blend.\"\"\"\n        if not self.is_trained: raise ValueError(\"Classical model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Final Classical Ensemble Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final classical model training and prediction...\")\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=True)\n        y_train_full = full_train_df['is_cheating'].values; test_preds_l1 = {}\n        \n        # --- Train Final L1 Models ---\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=25, min_child_samples=25, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.6, reg_lambda=0.6, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1) \n        lgb_final.fit(X_train_full, y_train_full); test_preds_l1['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=8, random_seed=RANDOM_SEED, verbose=0, task_type=\"CPU\")\n        cat_final.fit(X_train_full, y_train_full); test_preds_l1['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=2.0, random_state=RANDOM_SEED); ridge_final.fit(X_train_full_scaled, y_train_full);\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds_l1['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        \n        print(\"Training final XGBoost...\"); xgb_final = xgb.XGBClassifier(n_estimators=2000, learning_rate=0.01, max_depth=5, min_child_weight=3, subsample=0.7, colsample_bytree=0.6, gamma=0.1, reg_alpha=0.5, reg_lambda=0.5, random_state=RANDOM_SEED, eval_metric='logloss', tree_method='hist', n_jobs=-1)\n        xgb_final.fit(X_train_full, y_train_full, verbose=False); test_preds_l1['xgb'] = xgb_final.predict_proba(X_test)[:, 1]\n\n        # --- Get L2 Predictions ---\n        # Model A: L2 Stack\n        print(\"Applying Classical L2 Meta-Model (Model A)...\"); \n        X_meta_test = np.stack(list(test_preds_l1.values()), axis=1) # 4 models\n        preds_stack_test = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        \n        # Model B: L2 Weighted Average\n        print(\"Applying Classical L2 Weighted Average (Model B)...\"); \n        preds_weighted_test = (test_preds_l1['lgb'] * self.l1_weights['lgb'] +\n                               test_preds_l1['cat'] * self.l1_weights['cat'] +\n                               test_preds_l1['ridge'] * self.l1_weights['ridge'] +\n                               test_preds_l1['xgb'] * self.l1_weights['xgb']) # Add XGB\n                               \n        # --- L3: Blend Final Predictions (70/30) ---\n        print(\"Blending Model A and Model B (30/70 favoring Weighted Avg)...\")\n        final_proba_uncalibrated = 0.3 * preds_stack_test + 0.7 * preds_weighted_test # 70% to weighted avg\n        \n        # --- Final Calibration ---\n        print(\"Applying Final Isotonic Calibration...\"); \n        calibrated_proba = self.calibrator.transform(final_proba_uncalibrated)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        \n        return calibrated_proba, final_proba_uncalibrated # Return blended & calibrated\n\n# --- (Fallback model - unchanged) ---\ndef champion_fallback():\n    \"\"\"Fallback using basic LGBM, basic features.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler; from scipy.sparse import hstack, csr_matrix;\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor(); train_base_features = feature_extractor.extract_base_features(train_df.drop(columns=['llm_pred'], errors='ignore'))\n        test_base_features = feature_extractor.extract_base_features(test_df.drop(columns=['llm_pred'], errors='ignore'))\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns; test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1); test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english'); train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr(); y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1000, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1, reg_alpha=0.1, reg_lambda=0.1)\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\"); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f'); print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION (Calibrates LLM Pred, uses L3 Stack)\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Runs LLM inference, calibrates feature, runs L3 stack.\"\"\"\n    print(\"=\" * 60); print(f\"  Mercor AI Text Detection - CHAMPION v27.6 (L3 + 4 Models)\"); print(\"=\" * 60)\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n    # --- Step 1: Generate LLM predictions ---\n    all_texts = pd.concat([train_df['answer'], test_df['answer']])\n    llm_preds_all = get_llm_predictions(all_texts, LLM_MODEL_NAME) # Using desklib\n    llm_oof_preds_orig = llm_preds_all[:len(train_df)]; llm_test_preds_orig = llm_preds_all[len(train_df):]\n    # --- Step 2: Calibrate LLM predictions ---\n    print(\"\\nCalibrating LLM predictions...\"); llm_calibrator = IsotonicRegression(out_of_bounds='clip')\n    llm_calibrator.fit(llm_oof_preds_orig, train_df['is_cheating'].values)\n    llm_oof_preds_calibrated = llm_calibrator.transform(llm_oof_preds_orig)\n    llm_test_calibrated = llm_calibrator.transform(llm_test_preds_orig)\n    print(\"LLM predictions calibrated.\"); \n    calibrated_oof_auc = roc_auc_score(train_df['is_cheating'], llm_oof_preds_calibrated)\n    print(f\"CalD LLM OOF AUC: {calibrated_oof_auc:.8f}\")\n    train_df['llm_pred'] = llm_oof_preds_calibrated; test_df['llm_pred'] = llm_test_calibrated\n    print(\"CALIBRATED LLM feature ('llm_pred') added to dataframes.\")\n    \n    # --- Step 3: Run Classical L3 Stack Ensemble ---\n    classical_detector = ChampionAIDetector(n_splits=N_SPLITS_CLASSICAL, n_repeats=N_REPEATS_CLASSICAL, n_features=N_FEATURES_CLASSICAL) # L3 Stack class\n    oof_auc_classical, oof_preds_classical = classical_detector.train_champion_ensemble(train_df)\n    print(\"\\nStarting Final Test Set Prediction using L3 Stack...\");\n    calibrated_proba, base_proba = classical_detector.predict_champion(train_df, test_df)\n    \n    # Create submission files\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n    # Final Output\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\");\n    print(f\"Final L3 Stack OOF AUC (with Calibrated LLM Feat): {oof_auc_classical:.8f}\")\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv (Backup)\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    start_time = time.time()\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback; traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache(); end_time = time.time()\n        print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T19:40:12.799402Z","iopub.execute_input":"2025-11-04T19:40:12.799709Z","iopub.status.idle":"2025-11-04T19:48:36.910690Z","shell.execute_reply.started":"2025-11-04T19:40:12.799686Z","shell.execute_reply":"2025-11-04T19:48:36.909882Z"}},"outputs":[{"name":"stdout","text":"Installing/Updating transformers...\nLibraries installed.\nAll libraries imported successfully!\n============================================================\n  Mercor AI Text Detection - CHAMPION v27.6 (L3 + 4 Models)\n============================================================\nTraining data shape: (269, 4)\nTest data shape: (264, 3)\n\n--- Starting LLM Inference (desklib/ai-text-detector-v1.01) ---\nUsing device: cuda\nLoading Tokenizer: desklib/ai-text-detector-v1.01...\nLoading Model (Custom Class): desklib/ai-text-detector-v1.01...\nModel and Tokenizer loaded successfully.\nRunning LLM inference on 533 texts...\nUsing batch size: 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"LLM (ai-text-detector-v1.01):   0%|          | 0/34 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af5765ab30a04110acc96c581319afc3"}},"metadata":{}},{"name":"stdout","text":"LLM (ai-text-detector-v1.01) prediction feature generated.\n--- Finished LLM Inference ---\n\nCalibrating LLM predictions...\nLLM predictions calibrated.\nCalD LLM OOF AUC: 0.96113527\nCALIBRATED LLM feature ('llm_pred') added to dataframes.\n\nClassical Detector (L3 Ensemble + 4 Models): 5 splits, 3 repeats, SelectKBest(k=850).\n\n--- Starting Classical Ensemble Training ---\nTraining set size: 269\nPositive class ratio: 0.546468\nFitting topic columns on full training data...\nIdentified 268 topic columns during fit.\n\nFitting Scalers, TFIDF, and Selector on FULL training data...\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nIdentified 268 topic columns during fit.\nFitting/Transforming dense features (excl. LLM)...\nFitting Word TF-IDF...\nFitting Char TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(269, 3683), Test=(269, 3683)\nFitting SelectKBest (k=850)...\nFinal training feature shape: (269, 850)\nFinal testing feature shape: (269, 850)\n\nStarting Repeated K-Fold Training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"CV Folds:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d11d2f3a74cc4659947fd3423aa93800"}},"metadata":{}},{"name":"stdout","text":"\n==================== Repeat 1/3, Split 1/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3683), Test=(54, 3683)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 1: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 1 LGB AUC: 0.995833\nFold 1 CAT AUC: 0.998611\nFold 1 RIDGE AUC: 0.986111\nFold 1 XGB AUC: 0.998611\n\n==================== Repeat 1/3, Split 2/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3683), Test=(54, 3683)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 2: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 2 LGB AUC: 1.000000\nFold 2 CAT AUC: 0.998611\nFold 2 RIDGE AUC: 0.998611\nFold 2 XGB AUC: 0.998611\n\n==================== Repeat 1/3, Split 3/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3683), Test=(54, 3683)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 3: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 3 LGB AUC: 0.966897\nFold 3 CAT AUC: 0.954483\nFold 3 RIDGE AUC: 0.983448\nFold 3 XGB AUC: 0.972414\n\n==================== Repeat 1/3, Split 4/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3683), Test=(54, 3683)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 4: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 4 LGB AUC: 0.977931\nFold 4 CAT AUC: 0.984828\nFold 4 RIDGE AUC: 0.976552\nFold 4 XGB AUC: 0.982069\n\n==================== Repeat 1/3, Split 5/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(216, 3683), Test=(53, 3683)\nFinal training feature shape: (216, 850)\nFinal testing feature shape: (53, 850)\nFold 5: Train shape (216, 850), Val shape (53, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 5 LGB AUC: 0.988506\nFold 5 CAT AUC: 0.991379\nFold 5 RIDGE AUC: 0.979885\nFold 5 XGB AUC: 0.984195\n\n==================== Repeat 2/3, Split 1/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3683), Test=(54, 3683)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 6: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 6 LGB AUC: 1.000000\nFold 6 CAT AUC: 1.000000\nFold 6 RIDGE AUC: 0.987500\nFold 6 XGB AUC: 0.998611\n\n==================== Repeat 2/3, Split 2/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3683), Test=(54, 3683)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 7: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 7 LGB AUC: 1.000000\nFold 7 CAT AUC: 1.000000\nFold 7 RIDGE AUC: 0.983333\nFold 7 XGB AUC: 1.000000\n\n==================== Repeat 2/3, Split 3/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3683), Test=(54, 3683)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 8: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 8 LGB AUC: 0.965517\nFold 8 CAT AUC: 0.968276\nFold 8 RIDGE AUC: 0.986207\nFold 8 XGB AUC: 0.969655\n\n==================== Repeat 2/3, Split 4/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3683), Test=(54, 3683)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 9: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 9 LGB AUC: 0.953103\nFold 9 CAT AUC: 0.936552\nFold 9 RIDGE AUC: 0.925517\nFold 9 XGB AUC: 0.953103\n\n==================== Repeat 2/3, Split 5/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(216, 3683), Test=(53, 3683)\nFinal training feature shape: (216, 850)\nFinal testing feature shape: (53, 850)\nFold 10: Train shape (216, 850), Val shape (53, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 10 LGB AUC: 1.000000\nFold 10 CAT AUC: 1.000000\nFold 10 RIDGE AUC: 0.995690\nFold 10 XGB AUC: 1.000000\n\n==================== Repeat 3/3, Split 1/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3683), Test=(54, 3683)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 11: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 11 LGB AUC: 0.973611\nFold 11 CAT AUC: 0.979167\nFold 11 RIDGE AUC: 0.995833\nFold 11 XGB AUC: 0.980556\n\n==================== Repeat 3/3, Split 2/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3683), Test=(54, 3683)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 12: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 12 LGB AUC: 0.997222\nFold 12 CAT AUC: 0.988889\nFold 12 RIDGE AUC: 0.986111\nFold 12 XGB AUC: 0.997222\n\n==================== Repeat 3/3, Split 3/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3683), Test=(54, 3683)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 13: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 13 LGB AUC: 0.947586\nFold 13 CAT AUC: 0.932414\nFold 13 RIDGE AUC: 0.947586\nFold 13 XGB AUC: 0.950345\n\n==================== Repeat 3/3, Split 4/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3683), Test=(54, 3683)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 14: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 14 LGB AUC: 0.998621\nFold 14 CAT AUC: 0.997241\nFold 14 RIDGE AUC: 1.000000\nFold 14 XGB AUC: 0.997241\n\n==================== Repeat 3/3, Split 5/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(216, 3683), Test=(53, 3683)\nFinal training feature shape: (216, 850)\nFinal testing feature shape: (53, 850)\nFold 15: Train shape (216, 850), Val shape (53, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nTraining XGBoost...\nFold 15 LGB AUC: 0.981322\nFold 15 CAT AUC: 0.988506\nFold 15 RIDGE AUC: 0.975575\nFold 15 XGB AUC: 0.987069\n\n==================================================\nAveraging OOF Scores across repeats:\n  LGB OOF AUC (Averaged): 0.98566968\n  CAT OOF AUC (Averaged): 0.98522360\n  RIDGE OOF AUC (Averaged): 0.98461024\n  XGB OOF AUC (Averaged): 0.98433144\nCalculated L1 Weights (for Model B):\n  LGB: 0.2502\n  CAT: 0.2501\n  RIDGE: 0.2499\n  XGB: 0.2498\n\nL2 Weighted Avg OOF AUC (Model B): 0.98767704\n\nTraining L2 Meta-Model (Model A)...\nL2 Stack OOF AUC (Model A): 0.98639456\n\nFINAL L3 BLEND OOF AUC (Averaged): 0.98762128\nTraining Final Isotonic Calibrator on L3 Blend...\n\nStarting Final Test Set Prediction using L3 Stack...\n\n==================================================\nGenerating Final Classical Ensemble Predictions...\n==================================================\nPreparing features for final classical model training and prediction...\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nIdentified 268 topic columns during fit.\nFitting/Transforming dense features (excl. LLM)...\nFitting Word TF-IDF...\nFitting Char TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(269, 3683), Test=(264, 3683)\nFitting SelectKBest (k=850)...\nFinal training feature shape: (269, 850)\nFinal testing feature shape: (264, 850)\nTraining final LightGBM...\nTraining final CatBoost...\nTraining final Ridge...\nTraining final XGBoost...\nApplying Classical L2 Meta-Model (Model A)...\nApplying Classical L2 Weighted Average (Model B)...\nBlending Model A and Model B (30/70 favoring Weighted Avg)...\nApplying Final Isotonic Calibration...\n\n============================================================\nCHAMPION PIPELINE COMPLETED SUCCESSFULLY!\nFinal L3 Stack OOF AUC (with Calibrated LLM Feat): 0.98762128\n\nSubmission files created:\n  1. submission.csv (RECOMMENDED)\n  2. submission_base_uncalibrated.csv (Backup)\n\nFinal 'submission.csv' prediction statistics:\n  Min: 0.001000\n  Max: 0.999000\n  Mean: 0.541943\n  Median: 0.957951\n\nTop 10 Predictions:\n              id  is_cheating\nscr_81822029c661     0.137931\nscr_52efb19e0ea9     0.999000\nscr_8fc0f33c559e     0.001000\nscr_bac3f5d3aa12     0.001000\nscr_adfbe009984d     0.001000\nscr_9e08ece19277     0.999000\nscr_0e34514f3cd4     0.974359\nscr_b10d808b5528     0.999000\nscr_2024f1e7bf94     0.137931\nscr_aa0b11f10fff     0.001000\n============================================================\n\nTotal execution time: 8.35 minutes\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}