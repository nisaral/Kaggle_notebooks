{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117171,"databundleVersionId":14089262,"sourceType":"competition"},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256},{"sourceId":28785,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":8318,"modelId":3301},{"sourceId":166355,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":141552,"modelId":164048}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":881.724544,"end_time":"2025-10-13T08:26:55.016349","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-13T08:12:13.291805","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\nTarget: 0.99+ CV AUC by implementing L2 Stacking, improved\nfeature engineering, and tuned hyperparameters.\n\nv3: ANTI-OVERFITTING VERSION\n- Drastically reduced TF-IDF features to combat overfitting.\n- Simplified L1 stack to only LGBM + CatBoost (removed noisy models).\n- Changed to 5-Folds for a more stable validation set.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\nimport warnings\n\n# Suppress all warnings for a cleaner output\nwarnings.filterwarnings('ignore')\n\nprint(\"All libraries imported successfully!\")\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR\n# -------------------------------------------------------------------\n\nclass ChampionFeatureExtractor:\n    \"\"\"\n    Feature Extractor focused on high-impact, proven features\n    for AI text detection.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes lists of keywords proven to be effective.\"\"\"\n        \n        # Words and phrases commonly overused by AI\n        self.ai_connectors = [\n            'in conclusion', 'in summary', 'furthermore', 'moreover', \n            'additionally', 'however', 'therefore', 'thus', 'consequently',\n            'as a result', 'on the other hand', 'for instance', 'for example',\n            'it is important to note', 'it is worth noting', 'that being said'\n        ]\n        \n        # Formal or \"business-speak\" words often preferred by AI\n        self.formal_words = [\n            'utilize', 'facilitate', 'implement', 'methodology', 'paradigm',\n            'leverage', 'robust', 'optimal', 'enhance', 'demonstrate',\n            'comprehensive', 'articulate'\n        ]\n        \n        # Hedging words AI uses to avoid absolute claims\n        self.hedging_words = [\n            'may', 'might', 'could', 'possibly', 'perhaps', \n            'suggests', 'seems', 'appears', 'likely'\n        ]\n        \n        # Simple passive voice indicators\n        self.passive_indicators = [\n            'is made', 'was made', 'is given', 'was given', \n            'is shown', 'was shown', 'is considered', 'was considered'\n        ]\n\n    def extract_champion_features(self, df):\n        \"\"\"\n        Extracts a DataFrame of high-impact features.\n        \"\"\"\n        features = pd.DataFrame(index=df.index)\n        \n        # Handle potential nulls in 'answer' column\n        answers = df['answer'].fillna('')\n        \n        # === Basic Text Statistics ===\n        features['text_length'] = answers.str.len()\n        features['word_count'] = answers.str.split().str.len()\n        features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6)\n        \n        # === Sentence Analysis ===\n        features['sentence_count'] = answers.str.count(r'[.!?]+')\n        features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6)\n        \n        # === Punctuation Patterns ===\n        features['comma_count'] = answers.str.count(',')\n        features['period_count'] = answers.str.count(r'\\.')\n        features['exclamation_count'] = answers.str.count(r'!')\n        features['question_count'] = answers.str.count(r'\\?')\n        features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6)\n\n        # === Lexical Richness ===\n        features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split())))\n        features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6) # Type-Token Ratio\n        \n        # === AI-Specific Patterns ===\n        def count_phrases(text, phrases):\n            text_lower = str(text).lower()\n            return sum(1 for phrase in phrases if phrase in text_lower)\n            \n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors))\n        features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words))\n        features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators))\n        \n        # === NEW: Hedging Words (AI tell) ===\n        features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words))\n        \n        # === Ratios (Density is often more powerful) ===\n        features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6)\n        features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6)\n        features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6)\n        features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n\n        # === Structural Features ===\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6)\n        \n        # === NEW: Paragraph Count ===\n        features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1\n        features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6)\n        \n        # === Consistency Metrics ===\n        features['word_length_std'] = answers.apply(\n            lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0\n        )\n        \n        # === Topic Features ===\n        topic_dummies = pd.get_dummies(df['topic'], prefix='topic', dtype=int)\n        \n        # Replace inf/-inf with 0 (e.g., from 0/0)\n        features.replace([np.inf, -np.inf], 0, inplace=True)\n        # Fill any remaining NaNs (e.g., from std of 1 word) with 0\n        features.fillna(0, inplace=True)\n        \n        return pd.concat([features, topic_dummies], axis=1)\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (STACKING ENSEMBLE)\n# -------------------------------------------------------------------\n\nclass ChampionAIDetector:\n    \"\"\"\n    Trains a powerful L2 Stacking Ensemble of LGBM, XGB, CatBoost, and LR\n    on a rich feature set (handcrafted + TF-IDF).\n    \"\"\"\n    \n    # *** CHANGE 1: Using 5 folds for a more stable validation set ***\n    def __init__(self, n_folds=5):\n        self.feature_extractor = ChampionFeatureExtractor()\n        self.n_folds = n_folds\n        self.models = {}\n        self.meta_model = None\n        self.calibrator = IsotonicRegression(out_of_bounds='clip')\n        self.is_trained = False\n        print(f\"ChampionAIDetector initialized with {self.n_folds} folds.\")\n\n    def prepare_champion_features(self, train_df, test_df):\n        \"\"\"\n        Prepares handcrafted + TF-IDF features for training and testing.\n        TF-IDF vectorizers are fit ONLY on the train_df.\n        \"\"\"\n        print(\"Extracting handcrafted features...\")\n        train_features_df = self.feature_extractor.extract_champion_features(train_df)\n        test_features_df = self.feature_extractor.extract_champion_features(test_df)\n        \n        # Align columns to ensure test set has same features as train set\n        test_features_df = test_features_df.reindex(columns=train_features_df.columns, fill_value=0)\n        \n        # Scale handcrafted features\n        print(\"Scaling handcrafted features...\")\n        self.scaler = StandardScaler()\n        train_features_scaled = self.scaler.fit_transform(train_features_df)\n        test_features_scaled = self.scaler.transform(test_features_df)\n        \n        # --- TF-IDF Features (Tuned for high performance) ---\n        print(\"Creating Word TF-IDF features...\")\n        \n        # *** CHANGE 2: Drastically reducing features to prevent overfitting ***\n        self.tfidf_word = TfidfVectorizer(\n            max_features=500,        # Was 5000\n            ngram_range=(1, 3),\n            min_df=3,\n            max_df=0.9,\n            sublinear_tf=True,\n            stop_words='english'\n        )\n        \n        train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna(''))\n        test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n        \n        print(\"Creating Char TF-IDF features...\")\n        self.tfidf_char = TfidfVectorizer(\n            max_features=250,        # Was 2000\n            analyzer='char_wb',\n            ngram_range=(3, 5),\n            min_df=3,\n            sublinear_tf=True\n        )\n        \n        train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna(''))\n        test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        \n        # Combine all features\n        print(\"Combining all feature sets...\")\n        X_train = np.hstack([\n            train_tfidf_word.toarray(),\n            train_tfidf_char.toarray(),\n            train_features_scaled\n        ])\n        \n        X_test = np.hstack([\n            test_tfidf_word.toarray(),\n            test_tfidf_char.toarray(),\n            test_features_scaled\n        ])\n        \n        print(f\"Final training feature shape: {X_train.shape}\")\n        print(f\"Final testing feature shape: {X_test.shape}\")\n        \n        return X_train, X_test, train_features_df.columns\n\n    def train_champion_ensemble(self, train_df):\n        \"\"\"\n        Trains the full L2 Stacking ensemble using Stratified K-Fold.\n        Level 1: LGBM, CatBoost (Simplified Stack)\n        Level 2: Logistic Regression (Meta-Model)\n        \"\"\"\n        \n        y_train = train_df['is_cheating'].values\n        \n        print(f\"Training set size: {len(train_df)}\")\n        print(f\"Positive class (cheating) ratio: {y_train.mean():.6f}\")\n        \n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n        \n        # Arrays to store Out-of-Fold (OOF) predictions from L1 models\n        # *** CHANGE 3: Simplified stack, removed xgb and lr ***\n        oof_preds = {\n            'lgb': np.zeros(len(train_df)),\n            'cat': np.zeros(len(train_df)),\n        }\n        \n        # --- Step 2: K-Fold Training of L1 Models ---\n        for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, y_train)):\n            print(f\"\\n{'='*20} FOLD {fold+1}/{self.n_folds} {'='*20}\")\n            \n            # Create fold-specific data\n            train_fold_df, val_fold_df = train_df.iloc[train_idx], train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            \n            # --- CRITICAL: Feature prep is done INSIDE the fold ---\n            X_train_fold, X_val_fold, _ = self.prepare_champion_features(train_fold_df, val_fold_df)\n            \n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n\n            # === LightGBM (Tuned) ===\n            print(\"Training LightGBM...\")\n            lgb_model = lgb.LGBMClassifier(\n                n_estimators=2500,\n                learning_rate=0.01,\n                max_depth=7,\n                num_leaves=48,\n                min_child_samples=10,\n                subsample=0.8,\n                colsample_bytree=0.7,\n                reg_alpha=0.1,\n                reg_lambda=0.1,\n                random_state=42 + fold,\n                verbose=-1,\n                n_jobs=-1\n            )\n            lgb_model.fit(\n                X_train_fold, y_train_fold,\n                eval_set=[(X_val_fold, y_val_fold)],\n                callbacks=[lgb.early_stopping(200, verbose=False)]\n            )\n            oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            \n            \n            # === XGBoost (REMOVED - TOO NOISY) ===\n            # print(\"Training XGBoost...\")\n            \n            \n            # === CatBoost (Tuned) ===\n            print(\"Training CatBoost...\")\n            cat_model = CatBoostClassifier(\n                iterations=2500,\n                learning_rate=0.02,\n                depth=6,\n                l2_leaf_reg=3,\n                random_seed=42 + fold,\n                verbose=0,\n                early_stopping_rounds=200,\n                task_type=\"CPU\" # or \"GPU\" if available\n            )\n            cat_model.fit(\n                X_train_fold, y_train_fold,\n                eval_set=(X_val_fold, y_val_fold),\n                verbose=False\n            )\n            oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            \n            \n            # === Logistic Regression (REMOVED - TOO NOISY) ===\n            # print(\"Training Logistic Regression...\")\n            \n\n            # --- Fold AUC Score ---\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx])\n            fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx])\n            \n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\")\n            print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\")\n\n        # --- Step 3: Evaluate OOF L1 Models ---\n        print(\"\\n\" + \"=\"*50)\n        print(\"L1 Model OOF (Out-of-Fold) Scores:\")\n        for name, preds in oof_preds.items():\n            auc = roc_auc_score(y_train, preds)\n            print(f\"  {name.upper()} OOF AUC: {auc:.8f}\")\n            \n        # --- Step 4: Train L2 Meta-Model ---\n        print(\"\\nTraining L2 Meta-Model (Stacking)...\")\n        # *** CHANGE 4: Meta-feature matrix now only has 2 columns ***\n        X_meta_train = np.stack([oof_preds['lgb'], oof_preds['cat']], axis=1)\n        \n        self.meta_model = LogisticRegression(C=1.0, solver='liblinear', random_state=42)\n        self.meta_model.fit(X_meta_train, y_train)\n        \n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]\n        oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        \n        print(f\"\\nCHAMPION L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\")\n        \n        # --- Step 5: Train Calibrator ---\n        print(\"Training Isotonic Regression Calibrator...\")\n        self.calibrator.fit(oof_ensemble_preds, y_train)\n        \n        self.is_trained = True\n        return oof_ensemble_auc, oof_ensemble_preds\n\n    def predict_champion(self, train_df, test_df):\n        \"\"\"\n        Generates final predictions on the test set.\n        \"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Model has not been trained yet! Call train_champion_ensemble() first.\")\n        \n        print(\"\\n\" + \"=\"*50)\n        print(\"Generating Test Set Predictions...\")\n        print(\"=\"*50)\n\n        # --- Step 1: Prepare features for full training and testing ---\n        X_train_full, X_test, feature_names = self.prepare_champion_features(train_df, test_df)\n        y_train_full = train_df['is_cheating'].values\n        \n        # *** CHANGE 5: Simplified test_preds dictionary ***\n        test_preds = {}\n\n        # === Step 2: Train Final L1 Models on Full Data ===\n\n        # === LightGBM Final ===\n        print(\"Training final LightGBM model...\")\n        lgb_final = lgb.LGBMClassifier(\n            n_estimators=2000, \n            learning_rate=0.01, max_depth=7, num_leaves=48, min_child_samples=10,\n            subsample=0.8, colsample_bytree=0.7, reg_alpha=0.1, reg_lambda=0.1,\n            random_state=42, verbose=-1, n_jobs=-1\n        )\n        lgb_final.fit(X_train_full, y_train_full)\n        test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        \n        \n        # === XGBoost Final (REMOVED) ===\n        \n        \n        # === CatBoost Final ===\n        print(\"Training final CatBoost model...\")\n        cat_final = CatBoostClassifier(\n            iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=3,\n            random_seed=42, verbose=0, task_type=\"CPU\"\n        )\n        cat_final.fit(X_train_full, y_train_full)\n        test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        \n        \n        # === Logistic Regression Final (REMOVED) ===\n\n\n        # --- Step 3: Apply L2 Meta-Model ---\n        print(\"Applying L2 Meta-Model to test predictions...\")\n        # *** CHANGE 6: Meta-test matrix now only has 2 columns ***\n        X_meta_test = np.stack([test_preds['lgb'], test_preds['cat']], axis=1)\n        \n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        \n        # --- Step 4: Calibrate Final Predictions ---\n        print(\"Applying Isotonic Calibration...\")\n        calibrated_proba = self.calibrator.transform(final_proba)\n        \n        # Clip probabilities to avoid 0/1, as AUC dislikes extremes\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        \n        return calibrated_proba, final_proba\n\n# -------------------------------------------------------------------\n# 3. FALLBACK MODEL\n# -------------------------------------------------------------------\n\ndef champion_fallback():\n    \"\"\"\n    A simple, robust fallback model (LGBM on features)\n    in case the main ensemble fails for any reason.\n    \"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    \n    try:\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv')\n        test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        \n        # Use the same high-quality feature extractor\n        feature_extractor = ChampionFeatureExtractor()\n        train_features = feature_extractor.extract_champion_features(train_df)\n        test_features = feature_extractor.extract_champion_features(test_df)\n        \n        test_features = test_features.reindex(columns=train_features.columns, fill_value=0)\n        \n        # Simpler TF-IDF\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english')\n        train_tfidf = tfid.fit_transform(train_df['answer'].fillna(''))\n        test_tfidf = tfid.transform(test_df['answer'].fillna(''))\n        \n        # Combine features\n        X_train = np.hstack([train_tfidf.toarray(), train_features.values])\n        X_test = np.hstack([test_tfidf.toarray(), test_features.values])\n        y_train = train_df['is_cheating']\n        \n        # Scale data\n        scaler = StandardScaler()\n        X_train = scaler.fit_transform(X_train)\n        X_test = scaler.transform(X_test)\n        \n        # Train robust LGBM\n        model = lgb.LGBMClassifier(\n            n_estimators=1200,\n            learning_rate=0.01,\n            max_depth=7,\n            num_leaves=63,\n            random_state=42,\n            verbose=-1,\n            n_jobs=-1\n        )\n        \n        model.fit(X_train, y_train)\n        test_proba = model.predict_proba(X_test)[:, 1]\n        \n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba})\n        submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        \n        print(\"Fallback submission.csv created successfully.\")\n        return submission\n        \n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\")\n        # As a last resort, create a submission of all 0.5s\n        test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5})\n        submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\")\n        return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION\n# -------------------------------------------------------------------\n\ndef champion_main():\n    \"\"\"\n    Main function to run the full training and prediction pipeline.\n    \"\"\"\n    print(\"=\" * 60)\n    print(\"  Mercor AI Text Detection - CHAMPION STACKING v3 (ANTI-OVERFITTING)\")\n    print(\"=\" * 60)\n    \n    # Load data\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv')\n    test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    \n    print(f\"Training data shape: {train_df.shape}\")\n    print(f\"Test data shape: {test_df.shape}\")\n    \n    # Pre-fill NaNs\n    train_df['answer'] = train_df['answer'].fillna('')\n    test_df['answer'] = test_df['answer'].fillna('')\n    \n    # Initialize detector\n    detector = ChampionAIDetector(n_folds=5) # Using 5 folds\n    \n    # Train model\n    print(\"\\nStarting Champion Ensemble Training...\")\n    oof_auc, oof_predictions = detector.train_champion_ensemble(train_df)\n    \n    # Predict on test set\n    print(\"\\nStarting Test Set Prediction...\")\n    calibrated_proba, base_proba = detector.predict_champion(train_df, test_df)\n    \n    # Create submission file (as requested)\n    submission_calibrated = pd.DataFrame({\n        'id': test_df['id'],\n        'is_cheating': calibrated_proba\n    })\n    \n    # Create a non-calibrated version just in case\n    submission_base = pd.DataFrame({\n        'id': test_df['id'],\n        'is_cheating': base_proba\n    })\n    \n    # Save files\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f')\n    submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\")\n    print(f\"Final OOF (Out-of-Fold) AUC: {oof_auc:.8f}\")\n    print(\"\\nSubmission files created:\")\n    print(f\"  1. submission.csv (RECOMMENDED - Calibrated L2 Stack)\")\n    print(f\"  2. submission_base_uncalibrated.csv (Uncalibrated L2 Stack)\")\n    \n    # Display statistics of final predictions\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\")\n    print(f\"  Min: {calibrated_proba.min():.6f}\")\n    print(f\"  Max: {calibrated_proba.max():.6f}\")\n    print(f\"  Mean: {calibrated_proba.mean():.6f}\")\n    print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    \n    print(\"\\nTop 10 Predictions:\")\n    print(submission_calibrated.head(10).to_string(index=False))\n    print(\"=\" * 60)\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    try:\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback\n        traceback.print_exc()\n        champion_fallback()","metadata":{}},{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv14: FIXED Accelerate Device Conflict\n- Removed the conflicting 'device' argument from the pipeline()\n  call when using device_map=\"auto\" during model loading.\n- Pipeline now correctly uses the device(s) assigned by accelerate.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nimport warnings\nimport torch\nimport gc # Garbage Collection\n\n# --- Imports for Local LLM ---\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom tqdm.auto import tqdm\nfrom scipy.sparse import hstack, csr_matrix\n\n# Suppress warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"All libraries imported successfully!\")\n\n# --- CONFIGURATION ---\n# *** REPLACE WITH YOUR ACTUAL KAGGLE INPUT PATH ***\nQWEN_MODEL_PATH = \"/kaggle/input/qwen2.5/transformers/7b-instruct-awq/1\" # <-- SET THIS PATH\n\n# -------------------------------------------------------------------\n# 0. LOCAL LLM PREDICTION LAYER (Qwen - Fixed Pipeline Init)\n# -------------------------------------------------------------------\n\ndef get_llm_predictions(texts, model_path):\n    \"\"\"\n    Uses a local Qwen model to classify text as 'AI' or 'Human' via prompting,\n    then assigns probabilities.\n    \"\"\"\n    print(f\"Loading LOCAL LLM detector from: {model_path}...\")\n    # NOTE: We don't specify device here, let device_map handle it\n    print(f\"Device mapping will be handled by accelerate.\")\n\n    try:\n        print(\"Loading tokenizer...\")\n        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n        print(\"Loading model (AWQ) with device_map='auto'...\")\n        model = AutoModelForCausalLM.from_pretrained(\n            model_path,\n            torch_dtype=torch.float16, # Using float16 based on previous warning\n            device_map=\"auto\",\n            trust_remote_code=True\n        )\n        model.eval()\n        # Get the device the model (or its first part) ended up on for logging\n        loaded_device = model.device\n        print(f\"Model loaded successfully on device(s) via accelerate (example device: {loaded_device})\")\n\n    except Exception as e:\n        print(f\"Error loading local Qwen model: {e}\")\n        print(\"Falling back to assigning 0.5 probability to all.\")\n        return np.full(len(texts), 0.5)\n\n    # Use a pipeline for easier text generation handling\n    print(\"Initializing text-generation pipeline...\")\n    pipe = pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        # --- THIS IS THE FIX ---\n        # REMOVED device=model.device, # <--- REMOVED THIS ARGUMENT\n        max_new_tokens=5,\n        temperature=0.01,\n        do_sample=False\n    )\n    print(f\"Pipeline initialized, will use device(s): {pipe.device}\") # Log pipeline device\n\n    print(f\"Running Qwen inference on {len(texts)} texts...\")\n    qwen_probs = []\n    batch_size = 8\n    prompt_template = \"Analyze the following text. Was it written by a human or generated by an AI? Respond with ONLY the word 'Human' or the word 'AI'. Text: {}\"\n\n    for i in tqdm(range(0, len(texts), batch_size)):\n        batch_texts = texts[i : i + batch_size].tolist()\n        # Truncate input text to avoid overly long prompts\n        batch_prompts = [prompt_template.format(text[:1500]) for text in batch_texts] # Increased limit slightly\n\n        try:\n            # Generate responses\n            outputs = pipe(batch_prompts, batch_size=len(batch_prompts)) # Process batch\n\n            for output in outputs:\n                # Extract only the newly generated text\n                # Accessing the first (and likely only) generated sequence\n                full_generated_text = output[0]['generated_text']\n\n                # Find where the prompt ends in the output. This is more robust.\n                prompt_end_index = full_generated_text.find(batch_prompts[outputs.index(output)][-20:]) # Find ~end of prompt\n                if prompt_end_index != -1:\n                     response_start = prompt_end_index + len(batch_prompts[outputs.index(output)][-20:])\n                     response = full_generated_text[response_start:].strip().lower()\n                else:\n                    # If prompt not found, try a simpler heuristic (less reliable)\n                    response = full_generated_text.split(\"Text:\")[-1].strip().lower()\n\n\n                # Assign probability based on classification\n                # Check for specific words at the START of the response\n                if response.startswith(\"ai\"):\n                    qwen_probs.append(0.95)\n                elif response.startswith(\"human\"):\n                    qwen_probs.append(0.05)\n                else:\n                    print(f\"Warning: Unexpected Qwen response start: '{response[:20]}...'. Full: '{full_generated_text}'. Assigning 0.5.\")\n                    qwen_probs.append(0.5)\n\n        except Exception as e:\n            print(f\"Error during Qwen batch inference {i // batch_size}: {e}\")\n            qwen_probs.extend([0.5] * len(batch_texts))\n\n        # Memory cleanup\n        gc.collect(); torch.cuda.empty_cache()\n\n    print(\"Qwen prediction feature generated successfully.\")\n    del model; del tokenizer; del pipe; gc.collect(); torch.cuda.empty_cache()\n    return np.array(qwen_probs)\n\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (Extracts base + adds qwen_pred later)\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, topic dummies handled later.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']\n        self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']\n        self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']\n        self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n\n    def extract_base_features(self, df):\n        \"\"\"Extracts NON-TOPIC features and adds qwen_pred if present.\"\"\"\n        features = pd.DataFrame(index=df.index)\n        if 'qwen_pred' in df.columns: features['qwen_pred'] = df['qwen_pred']\n        answers = df['answer'].fillna('')\n        features['text_length'] = answers.str.len()\n        features['word_count'] = answers.str.split().str.len()\n        features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6)\n        features['sentence_count'] = answers.str.count(r'[.!?]+')\n        features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6)\n        features['comma_count'] = answers.str.count(',')\n        features['period_count'] = answers.str.count(r'\\.')\n        features['exclamation_count'] = answers.str.count(r'!')\n        features['question_count'] = answers.str.count(r'\\?')\n        features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6)\n        features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split())))\n        features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors))\n        features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words))\n        features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators))\n        features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words))\n        features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6)\n        features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6)\n        features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6)\n        features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6)\n        features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1\n        features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6)\n        features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True)\n        return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (Unchanged from v12)\n# -------------------------------------------------------------------\n\nclass ChampionAIDetector:\n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats including the Qwen feature.\"\"\"\n    def __init__(self, n_folds=5, n_features=750):\n        self.feature_extractor = ChampionFeatureExtractor()\n        self.n_folds = n_folds; self.n_features = n_features\n        self.models = {}; self.meta_model = None\n        self.calibrator = IsotonicRegression(out_of_bounds='clip')\n        self.scaler = StandardScaler(); self.tfidf_word = None\n        self.tfidf_char = None; self.selector = None\n        self.topic_columns = None; self.is_trained = False\n        print(f\"Detector initialized: {n_folds} folds, SelectKBest(k={n_features}).\")\n\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        \"\"\"Gets dummy variables for topics, ensuring consistent columns.\"\"\"\n        dummies = pd.get_dummies(series, prefix='topic', dtype=int)\n        if fit_columns: self.topic_columns = dummies.columns; print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates qwen_pred.\"\"\"\n        print(\"Extracting base handcrafted + Qwen features...\")\n        train_base_features_df = self.feature_extractor.extract_base_features(train_df)\n        test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        if is_training_fold or is_full_training: fit_topic_cols = (self.topic_columns is None) or is_full_training; train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        else: train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=False); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        qwen_train_feat = train_base_features_df.pop('qwen_pred').values.reshape(-1, 1); qwen_test_feat = test_base_features_df.pop('qwen_pred').values.reshape(-1, 1)\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. Qwen) with StandardScaler...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. Qwen) using fitted StandardScaler...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2000)\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1000)\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        print(\"Combining all feature sets...\"); X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(qwen_train_feat)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(qwen_test_feat)]).tocsr()\n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            self.selector.fit(X_train_full, y_train); X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n\n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n        oof_preds = {'lgb': np.zeros(len(full_train_df)), 'cat': np.zeros(len(full_train_df)), 'ridge': np.zeros(len(full_train_df))}\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, y_train)):\n            print(f\"\\n{'='*20} FOLD {fold+1}/{self.n_folds} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            is_first_fold = (fold == 0); X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=is_first_fold, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=0.5, random_state=42 + fold, verbose=-1, n_jobs=-1)\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=5, random_seed=42 + fold, verbose=0, early_stopping_rounds=200, task_type=\"CPU\")\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.0, random_state=42 + fold); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds['ridge'][val_idx] = ridge_probs\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds['ridge'][val_idx])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"L1 Model OOF Scores:\"); [print(f\"  {name.upper()} OOF AUC: {roc_auc_score(y_train, preds):.8f}\") for name, preds in oof_preds.items()]\n        print(\"\\nTraining L2 Meta-Model...\"); X_meta_train = np.stack(list(oof_preds.values()), axis=1)\n        self.meta_model = LogisticRegression(C=1.0, solver='liblinear', random_state=42); self.meta_model.fit(X_meta_train, y_train)\n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCHAMPION L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\"); print(\"Training Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Test Set Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final model training and prediction...\")\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=True)\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=0.5, random_state=42, verbose=-1, n_jobs=-1)\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=5, random_seed=42, verbose=0, task_type=\"CPU\")\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.0, random_state=42); ridge_final.fit(X_train_full_scaled, y_train_full)\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        print(\"Applying L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n# -------------------------------------------------------------------\n# 3. FALLBACK MODEL (Unchanged from v12)\n# -------------------------------------------------------------------\ndef champion_fallback():\n    \"\"\"Fallback using LGBM, fixed scaler.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler\n        from scipy.sparse import hstack, csr_matrix\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor()\n        train_base_features = feature_extractor.extract_base_features(train_df); test_base_features = feature_extractor.extract_base_features(test_df)\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns\n        test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1)\n        test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english')\n        train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr()\n        y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1200, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=42, verbose=-1, n_jobs=-1, reg_alpha=0.3, reg_lambda=0.3)\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\")\n        test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION (Modified for Qwen Feature)\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Runs Qwen feature gen + classical stack.\"\"\"\n    print(\"=\" * 60); print(\"  Mercor AI Text Detection - CHAMPION v14 (Local Qwen + Fix)\"); print(\"=\" * 60)\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n    print(\"\\nStarting Qwen Feature Generation...\")\n    all_texts = pd.concat([train_df['answer'], test_df['answer']])\n    qwen_preds = get_llm_predictions(all_texts, QWEN_MODEL_PATH)\n    train_df['qwen_pred'] = qwen_preds[:len(train_df)]; test_df['qwen_pred'] = qwen_preds[len(train_df):]\n    print(\"Qwen feature ('qwen_pred') added to dataframes.\")\n    detector = ChampionAIDetector(n_folds=5, n_features=750)\n    print(\"\\nStarting Champion Ensemble Training (with Qwen feature)...\")\n    oof_auc, oof_predictions = detector.train_champion_ensemble(train_df)\n    print(\"\\nStarting Test Set Prediction...\")\n    calibrated_proba, base_proba = detector.predict_champion(train_df, test_df)\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\"); print(f\"Final OOF (Out-of-Fold) AUC: {oof_auc:.8f}\")\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback\n        traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2025-10-26T09:29:25.794609Z","iopub.execute_input":"2025-10-26T09:29:25.794928Z","iopub.status.idle":"2025-10-26T09:35:42.684657Z","shell.execute_reply.started":"2025-10-26T09:29:25.794907Z","shell.execute_reply":"2025-10-26T09:35:42.683994Z"}}},{"cell_type":"markdown","source":"# === Hugging Face Imports ===\n# Install necessary libraries silently\nprint(\"Installing specific pyarrow version...\")\n# Force install pyarrow 14.0.1 FIRST to resolve conflicts\nos.system('pip install -q pyarrow==14.0.1')\nprint(\"Installing/Updating Hugging Face libraries...\")\n# Now install the HF libraries\nos.system('pip install -q datasets evaluate accelerate transformers')\nprint(\"Libraries installed.\")\n\n# (Rest of your imports)\nimport torch\nfrom datasets import Dataset, DatasetDict\n# ... etc ...","metadata":{}},{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv21: Inference-Only Feature from abhi099k + Classical Ensemble\n- ABANDONED fine-tuning due to persistent pyarrow/datasets import errors.\n- Uses the 'abhi099k/ai-text-detector-v-n4.0' model purely for INFERENCE.\n- Loads model/tokenizer directly using transformers (no datasets/Trainer).\n- Creates 'llm_pred' feature via manual batch inference loop.\n- Adds 'llm_pred' feature to the v12 classical pipeline\n  (SelectKBest + LGBM + CatBoost + Ridge).\n- Simplified installation - no datasets/evaluate/accelerate.\n\"\"\"\n\n# === General Imports ===\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport gc\nimport warnings\nimport time\nimport os\n\n# === Sklearn Imports ===\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom scipy.sparse import hstack, csr_matrix\n\n# === GBDT Imports ===\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n# === Hugging Face Imports ===\n# Simplified Install - ONLY transformers + torch\nprint(\"Installing/Updating transformers...\")\nos.system('pip install -q transformers torch') # Keep torch for GPU\nprint(\"Libraries installed.\")\n\ntry:\n    import torch\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n    from tqdm.auto import tqdm\n    # Set transformers verbosity to error\n    import transformers\n    transformers.logging.set_verbosity_error()\nexcept ImportError as e:\n    print(f\"FATAL ERROR during imports: {e}\")\n    raise e\n\n\nprint(\"All libraries imported successfully!\")\n\n# === Configuration ===\nLLM_MODEL_NAME = \"abhi099k/ai-text-detector-v-n4.0\"\nN_SPLITS_CLASSICAL = 5\nN_FEATURES_CLASSICAL = 750 # For SelectKBest\nMAX_LEN_LLM = 512 # Max sequence length for tokenizer\n\n# -------------------------------------------------------------------\n# 0. LLM INFERENCE FUNCTION (Manual Loop)\n# -------------------------------------------------------------------\n\ndef get_llm_predictions(texts, model_name):\n    \"\"\"Generates predictions using the specified model via manual inference.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\")\n    model = None; tokenizer = None\n    # Determine device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\")\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n        print(f\"Loading Model: {model_name}...\")\n        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n        model.to(device) # Move model to GPU/CPU\n        model.eval() # Set to evaluation mode\n        print(\"Model and Tokenizer loaded successfully.\")\n        \n        # --- Determine positive label ID ---\n        # Assuming label '1' corresponds to AI/Cheating\n        positive_label_id = 1\n        if hasattr(model.config, \"label2id\"):\n             print(f\"Model labels found: {model.config.label2id}\")\n             # You could add logic here to find the 'AI' label if needed,\n             # but assuming ID 1 is standard for binary tasks like this.\n        print(f\"Assuming positive label ID (AI/Cheating) is: {positive_label_id}\")\n\n\n    except Exception as e:\n        print(f\"Error loading model or tokenizer {model_name}: {e}\\nFalling back to 0.5 probability.\")\n        del model; del tokenizer; gc.collect(); torch.cuda.empty_cache()\n        return np.full(len(texts), 0.5)\n\n    print(f\"Running LLM inference on {len(texts)} texts...\")\n    llm_probs = []\n    batch_size = 32 # Can likely use a larger batch size for inference\n\n    # Disable gradient calculations for inference\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=\"LLM Inference Batches\"):\n            batch_texts = texts[i : i + batch_size].tolist()\n            if not batch_texts: continue\n\n            try:\n                # Tokenize batch\n                inputs = tokenizer(\n                    batch_texts,\n                    return_tensors=\"pt\",\n                    truncation=True,\n                    padding=True,\n                    max_length=MAX_LEN_LLM\n                ).to(device) # Move tokenized inputs to the same device as the model\n\n                # Get model outputs (logits)\n                outputs = model(**inputs)\n                logits = outputs.logits\n\n                # Apply Softmax to get probabilities\n                # Check shape to handle potential single-output models (less likely for classification)\n                if logits.shape[-1] == 1: # Single output logit\n                    probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n                elif logits.shape[-1] == 2: # Two output logits\n                    probs_all = torch.softmax(logits, dim=-1)\n                    # Get probability of the positive class (assumed index 1)\n                    probs = probs_all[:, positive_label_id].cpu().numpy()\n                else:\n                     print(f\"Warning: Unexpected logit shape {logits.shape} in batch {i//batch_size}. Assigning 0.5.\")\n                     probs = np.full(len(batch_texts), 0.5)\n\n                llm_probs.extend(probs.tolist())\n\n            except Exception as e:\n                 print(f\"Error during LLM inference batch {i // batch_size}: {e}\")\n                 print(f\"Assigning 0.5 for {len(batch_texts)} failed batch items.\")\n                 llm_probs.extend([0.5] * len(batch_texts))\n\n            # Minimal cleanup within loop\n            if i % (batch_size * 20) == 0:\n                gc.collect()\n\n    print(\"LLM prediction feature generated successfully.\")\n    del model; del tokenizer; gc.collect(); torch.cuda.empty_cache() # Final cleanup\n    print(\"--- Finished LLM Inference ---\")\n\n    # Final length check\n    if len(llm_probs) != len(texts):\n        print(f\"CRITICAL WARNING: Output probability list length ({len(llm_probs)}) != input text length ({len(texts)}). Padding/Truncating.\")\n        llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)] # Pad/truncate\n\n    return np.array(llm_probs)\n\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (Handles 'llm_pred') - Unchanged\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, includes llm_pred if present.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']; self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']; self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']; self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n    def extract_base_features(self, df):\n        features = pd.DataFrame(index=df.index);\n        if 'llm_pred' in df.columns: features['llm_pred'] = df['llm_pred']\n        answers = df['answer'].fillna(''); features['text_length'] = answers.str.len(); features['word_count'] = answers.str.split().str.len(); features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6); features['sentence_count'] = answers.str.count(r'[.!?]+'); features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6); features['comma_count'] = answers.str.count(','); features['period_count'] = answers.str.count(r'\\.'); features['exclamation_count'] = answers.str.count(r'!'); features['question_count'] = answers.str.count(r'\\?'); features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6); features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split()))); features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors)); features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words)); features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators)); features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words)); features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6); features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6); features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6); features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6); features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1; features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6); features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True); return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (Handles llm_pred) - Unchanged\n# -------------------------------------------------------------------\nclass ChampionAIDetector:\n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats including llm_pred.\"\"\"\n    def __init__(self, n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL):\n        self.feature_extractor = ChampionFeatureExtractor(); self.n_folds = n_folds; self.n_features = n_features; self.models = {}; self.meta_model = None; self.calibrator = IsotonicRegression(out_of_bounds='clip'); self.scaler = StandardScaler(); self.tfidf_word = None; self.tfidf_char = None; self.selector = None; self.topic_columns = None; self.is_trained = False; print(f\"\\nClassical Detector initialized: {n_folds} folds, SelectKBest(k={n_features}).\")\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        dummies = pd.get_dummies(series, prefix='topic', dtype=int);\n        if fit_columns: self.topic_columns = dummies.columns; print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates llm_pred.\"\"\"\n        print(\"Extracting base handcrafted + LLM features...\"); train_base_features_df = self.feature_extractor.extract_base_features(train_df); test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        if is_training_fold or is_full_training: fit_topic_cols = (self.topic_columns is None) or is_full_training; train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        else: train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=False); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        llm_train_feat = train_base_features_df.pop('llm_pred').values.reshape(-1, 1); llm_test_feat = test_base_features_df.pop('llm_pred').values.reshape(-1, 1)\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2000)\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1000)\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        print(\"Combining all feature sets...\"); X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(llm_train_feat)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(llm_test_feat)]).tocsr()\n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            self.selector.fit(X_train_full, y_train); X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"\\n--- Starting Classical Ensemble Training ---\")\n        print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n        oof_preds = {'lgb': np.zeros(len(full_train_df)), 'cat': np.zeros(len(full_train_df)), 'ridge': np.zeros(len(full_train_df))}\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, y_train)):\n            print(f\"\\n{'='*20} Classical Fold {fold+1}/{self.n_folds} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            is_first_fold = (fold == 0); X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=is_first_fold, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=0.3, random_state=42 + fold, verbose=-1, n_jobs=-1)\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=4, random_seed=42 + fold, verbose=0, early_stopping_rounds=200, task_type=\"CPU\")\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.0, random_state=42 + fold); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds['ridge'][val_idx] = ridge_probs\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds['ridge'][val_idx])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"Classical L1 Model OOF Scores:\"); [print(f\"  {name.upper()} OOF AUC: {roc_auc_score(y_train, preds):.8f}\") for name, preds in oof_preds.items()]\n        print(\"\\nTraining Classical L2 Meta-Model...\"); X_meta_train = np.stack(list(oof_preds.values()), axis=1)\n        self.meta_model = LogisticRegression(C=1.0, solver='liblinear', random_state=42); self.meta_model.fit(X_meta_train, y_train)\n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCLASSICAL L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\"); print(\"Training Classical Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted classical components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Classical model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Final Classical Ensemble Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final classical model training and prediction...\")\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=True)\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=0.3, random_state=42, verbose=-1, n_jobs=-1)\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=4, random_seed=42, verbose=0, task_type=\"CPU\")\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.0, random_state=42); ridge_final.fit(X_train_full_scaled, y_train_full)\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        print(\"Applying Classical L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Classical Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n# --- (Fallback model - unchanged) ---\ndef champion_fallback():\n    \"\"\"Fallback using basic LGBM, fixed scaler.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler; from scipy.sparse import hstack, csr_matrix\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor(); train_base_features = feature_extractor.extract_base_features(train_df.drop(columns=['llm_pred'], errors='ignore')) # Generic drop\n        test_base_features = feature_extractor.extract_base_features(test_df.drop(columns=['llm_pred'], errors='ignore'))\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns; test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1); test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english'); train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr(); y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1200, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=42, verbose=-1, n_jobs=-1, reg_alpha=0.3, reg_lambda=0.3)\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\"); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f'); print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Runs LLM inference feature gen + classical stack.\"\"\"\n    print(\"=\" * 60); print(f\"  Mercor AI Text Detection - CHAMPION v21 ({LLM_MODEL_NAME} Inference + Classical)\"); print(\"=\" * 60)\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n\n    # --- Step 1: Generate LLM predictions ---\n    all_texts = pd.concat([train_df['answer'], test_df['answer']])\n    llm_preds = get_llm_predictions(all_texts, LLM_MODEL_NAME)\n    train_df['llm_pred'] = llm_preds[:len(train_df)]; test_df['llm_pred'] = llm_preds[len(train_df):]\n    print(\"LLM feature ('llm_pred') added to dataframes.\")\n\n    # --- Step 2: Run Classical Ensemble ---\n    classical_detector = ChampionAIDetector(n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL)\n    oof_auc_classical, oof_preds_classical = classical_detector.train_champion_ensemble(train_df)\n    print(\"\\nStarting Final Test Set Prediction using Classical Ensemble...\")\n    calibrated_proba, base_proba = classical_detector.predict_champion(train_df, test_df)\n\n    # Create submission files\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n\n    # Final Output\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\");\n    print(f\"Final Classical Ensemble OOF AUC (with LLM feature): {oof_auc_classical:.8f}\")\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    start_time = time.time()\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback\n        traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache()\n        end_time = time.time()\n        print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"execution":{"iopub.status.busy":"2025-10-26T14:20:56.329840Z","iopub.execute_input":"2025-10-26T14:20:56.330608Z","iopub.status.idle":"2025-10-26T14:24:54.701077Z","shell.execute_reply.started":"2025-10-26T14:20:56.330580Z","shell.execute_reply":"2025-10-26T14:24:54.700442Z"}}},{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv22: Hyperparameter Tuning on v21\n- Increased SelectKBest k from 750 to 850.\n- Increased TF-IDF max_features pool (Word: 2500, Char: 1250).\n- LGBM: Increased num_leaves back to 31.\n- L2 Logistic Regression Meta-Model: Changed C from 1.0 to 0.5.\n- Kept abhi099k model for inference feature.\n\"\"\"\n\n# === General Imports ===\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport gc\nimport warnings\nimport time\nimport os\n\n# === Sklearn Imports ===\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom scipy.sparse import hstack, csr_matrix\n\n# === GBDT Imports ===\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n# === Hugging Face Imports ===\n# Simplified Install - ONLY transformers + torch\nprint(\"Installing/Updating transformers...\")\nos.system('pip install -q transformers torch')\nprint(\"Libraries installed.\")\n\ntry:\n    import torch\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n    from tqdm.auto import tqdm\n    import transformers\n    transformers.logging.set_verbosity_error()\nexcept ImportError as e:\n    print(f\"FATAL ERROR during imports: {e}\"); raise e\n\nprint(\"All libraries imported successfully!\")\n\n# === Configuration ===\nLLM_MODEL_NAME = \"abhi099k/ai-text-detector-v-n4.0\"\nN_SPLITS_CLASSICAL = 5\n# --- TUNED ---\nN_FEATURES_CLASSICAL = 850 # Increased k\nMAX_LEN_LLM = 512\n\n# -------------------------------------------------------------------\n# 0. LLM INFERENCE FUNCTION (Manual Loop - Unchanged from v21)\n# -------------------------------------------------------------------\ndef get_llm_predictions(texts, model_name):\n    \"\"\"Generates predictions using the specified model via manual inference.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\"); model = None; tokenizer = None\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\"); tokenizer = AutoTokenizer.from_pretrained(model_name)\n        print(f\"Loading Model: {model_name}...\"); model = AutoModelForSequenceClassification.from_pretrained(model_name); model.to(device); model.eval()\n        print(\"Model and Tokenizer loaded successfully.\")\n        positive_label_id = 1; # Assume AI is label 1\n        if hasattr(model.config, \"label2id\"): print(f\"Model labels found: {model.config.label2id}\")\n        print(f\"Assuming positive label ID (AI/Cheating) is: {positive_label_id}\")\n    except Exception as e:\n        print(f\"Error loading model/tokenizer {model_name}: {e}\\nFalling back to 0.5.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); return np.full(len(texts), 0.5)\n    print(f\"Running LLM inference on {len(texts)} texts...\"); llm_probs = []\n    batch_size = 32\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=\"LLM Inference Batches\"):\n            batch_texts = texts[i : i + batch_size].tolist();\n            if not batch_texts: continue\n            try:\n                inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN_LLM).to(device)\n                outputs = model(**inputs); logits = outputs.logits\n                if logits.shape[-1] == 1: probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n                elif logits.shape[-1] == 2: probs_all = torch.softmax(logits, dim=-1); probs = probs_all[:, positive_label_id].cpu().numpy()\n                else: print(f\"Warning: Unexpected logit shape {logits.shape}. Assigning 0.5.\"); probs = np.full(len(batch_texts), 0.5)\n                llm_probs.extend(probs.tolist())\n            except Exception as e: print(f\"Error during LLM batch {i // batch_size}: {e}\"); llm_probs.extend([0.5] * len(batch_texts))\n            if i % (batch_size * 20) == 0: gc.collect()\n    print(\"LLM prediction feature generated.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); print(\"--- Finished LLM Inference ---\")\n    if len(llm_probs) != len(texts): print(f\"CRITICAL WARNING: Length mismatch {len(llm_probs)} vs {len(texts)}. Padding/Truncating.\"); llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)]\n    return np.array(llm_probs)\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (Handles 'llm_pred') - Unchanged\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, includes llm_pred if present.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']; self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']; self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']; self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n    def extract_base_features(self, df):\n        features = pd.DataFrame(index=df.index);\n        if 'llm_pred' in df.columns: features['llm_pred'] = df['llm_pred']\n        answers = df['answer'].fillna(''); features['text_length'] = answers.str.len(); features['word_count'] = answers.str.split().str.len(); features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6); features['sentence_count'] = answers.str.count(r'[.!?]+'); features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6); features['comma_count'] = answers.str.count(','); features['period_count'] = answers.str.count(r'\\.'); features['exclamation_count'] = answers.str.count(r'!'); features['question_count'] = answers.str.count(r'\\?'); features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6); features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split()))); features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors)); features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words)); features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators)); features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words)); features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6); features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6); features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6); features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6); features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1; features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6); features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True); return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (Handles llm_pred, Tuned Params)\n# -------------------------------------------------------------------\nclass ChampionAIDetector:\n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats including llm_pred.\"\"\"\n    def __init__(self, n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL):\n        self.feature_extractor = ChampionFeatureExtractor(); self.n_folds = n_folds; self.n_features = n_features; self.models = {}; self.meta_model = None; self.calibrator = IsotonicRegression(out_of_bounds='clip'); self.scaler = StandardScaler(); self.tfidf_word = None; self.tfidf_char = None; self.selector = None; self.topic_columns = None; self.is_trained = False; print(f\"\\nClassical Detector initialized: {n_folds} folds, SelectKBest(k={n_features}).\")\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        dummies = pd.get_dummies(series, prefix='topic', dtype=int);\n        if fit_columns: self.topic_columns = dummies.columns; print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates llm_pred.\"\"\"\n        print(\"Extracting base handcrafted + LLM features...\"); train_base_features_df = self.feature_extractor.extract_base_features(train_df); test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        if is_training_fold or is_full_training: fit_topic_cols = (self.topic_columns is None) or is_full_training; train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        else: train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=False); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        llm_train_feat = train_base_features_df.pop('llm_pred').values.reshape(-1, 1); llm_test_feat = test_base_features_df.pop('llm_pred').values.reshape(-1, 1)\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            # --- TUNED ---\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2500) # Increased pool\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1250) # Increased pool\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        print(\"Combining all feature sets...\"); X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(llm_train_feat)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(llm_test_feat)]).tocsr()\n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            # Handle potential warnings/errors during fitting SelectKBest\n            with warnings.catch_warnings():\n                 warnings.filterwarnings('ignore', category=RuntimeWarning) # Ignore division by zero etc.\n                 warnings.filterwarnings('ignore', category=UserWarning) # Ignore constant feature warning\n                 self.selector.fit(X_train_full, y_train)\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n\n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"\\n--- Starting Classical Ensemble Training ---\")\n        print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n        oof_preds = {'lgb': np.zeros(len(full_train_df)), 'cat': np.zeros(len(full_train_df)), 'ridge': np.zeros(len(full_train_df))}\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, y_train)):\n            print(f\"\\n{'='*20} Classical Fold {fold+1}/{self.n_folds} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            is_first_fold = (fold == 0); X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=is_first_fold, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n\n            # --- TUNED ---\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=0.3, random_state=42 + fold, verbose=-1, n_jobs=-1) # leaves=31\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=4, random_seed=42 + fold, verbose=0, early_stopping_rounds=200, task_type=\"CPU\") # l2=4\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.0, random_state=42 + fold); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds['ridge'][val_idx] = ridge_probs\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds['ridge'][val_idx])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"Classical L1 Model OOF Scores:\"); [print(f\"  {name.upper()} OOF AUC: {roc_auc_score(y_train, preds):.8f}\") for name, preds in oof_preds.items()]\n\n        # --- TUNED ---\n        print(\"\\nTraining Classical L2 Meta-Model...\"); X_meta_train = np.stack(list(oof_preds.values()), axis=1)\n        self.meta_model = LogisticRegression(C=0.5, solver='liblinear', random_state=42); self.meta_model.fit(X_meta_train, y_train) # C=0.5\n\n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCLASSICAL L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\"); print(\"Training Classical Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted classical components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Classical model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Final Classical Ensemble Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final classical model training and prediction...\")\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=True)\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        # --- TUNED ---\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=0.3, random_state=42, verbose=-1, n_jobs=-1) # leaves=31\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=4, random_seed=42, verbose=0, task_type=\"CPU\") # l2=4\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.0, random_state=42); ridge_final.fit(X_train_full_scaled, y_train_full)\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        print(\"Applying Classical L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Classical Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n\n# --- (Fallback model - unchanged) ---\ndef champion_fallback():\n    \"\"\"Fallback using basic LGBM, fixed scaler.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler; from scipy.sparse import hstack, csr_matrix\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor(); train_base_features = feature_extractor.extract_base_features(train_df.drop(columns=['llm_pred'], errors='ignore')) # Generic drop\n        test_base_features = feature_extractor.extract_base_features(test_df.drop(columns=['llm_pred'], errors='ignore'))\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns; test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1); test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english'); train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr(); y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1200, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=42, verbose=-1, n_jobs=-1, reg_alpha=0.3, reg_lambda=0.3)\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\"); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f'); print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Runs LLM inference feature gen + classical stack.\"\"\"\n    print(\"=\" * 60); print(f\"  Mercor AI Text Detection - CHAMPION v22 (Tuned {LLM_MODEL_NAME} + Classical)\"); print(\"=\" * 60)\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n    all_texts = pd.concat([train_df['answer'], test_df['answer']])\n    llm_preds = get_llm_predictions(all_texts, LLM_MODEL_NAME)\n    train_df['llm_pred'] = llm_preds[:len(train_df)]; test_df['llm_pred'] = llm_preds[len(train_df):]\n    print(\"LLM feature ('llm_pred') added to dataframes.\")\n    classical_detector = ChampionAIDetector(n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL)\n    oof_auc_classical, oof_preds_classical = classical_detector.train_champion_ensemble(train_df)\n    print(\"\\nStarting Final Test Set Prediction using Classical Ensemble...\")\n    calibrated_proba, base_proba = classical_detector.predict_champion(train_df, test_df)\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\"); print(f\"Final Classical Ensemble OOF AUC (with LLM feature): {oof_auc_classical:.8f}\")\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    start_time = time.time()\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback; traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache(); end_time = time.time()\n        print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"execution":{"iopub.status.busy":"2025-10-26T14:31:57.342548Z","iopub.execute_input":"2025-10-26T14:31:57.342966Z","iopub.status.idle":"2025-10-26T14:35:41.999716Z","shell.execute_reply.started":"2025-10-26T14:31:57.342939Z","shell.execute_reply":"2025-10-26T14:35:41.999100Z"},"jupyter":{"source_hidden":true}}},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T14:38:29.196608Z","iopub.execute_input":"2025-10-26T14:38:29.196945Z","iopub.status.idle":"2025-10-26T14:38:29.216277Z","shell.execute_reply.started":"2025-10-26T14:38:29.196923Z","shell.execute_reply":"2025-10-26T14:38:29.215686Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv24: External Data Augmentation (DAIGT V2) + v22 Pipeline\n- Adds external data from 'thedrcat/daigt-v2-train-dataset'.\n- Formats DAIGT data to match competition structure.\n- Combines competition train data with DAIGT data (downsampled).\n- Runs the v22 pipeline (inference feature from abhi099k + classical ensemble\n  with tuned params) on the augmented dataset.\n- Aims to significantly boost performance by increasing training data size.\n\"\"\"\n\n# === General Imports ===\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport gc\nimport warnings\nimport time\nimport os\n\n# === Sklearn Imports ===\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler # Keep MinMaxScaler for NB fallback\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.utils import shuffle # To shuffle combined data\n\n# === GBDT Imports ===\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n# === Hugging Face Imports ===\nprint(\"Installing/Updating transformers...\")\nos.system('pip install -q transformers torch') # Keep install simple\nprint(\"Libraries installed.\")\ntry:\n    import torch\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n    from tqdm.auto import tqdm\n    import transformers\n    transformers.logging.set_verbosity_error()\nexcept ImportError as e: print(f\"FATAL ERROR during imports: {e}\"); raise e\n\nprint(\"All libraries imported successfully!\")\n\n# === Configuration ===\nLLM_MODEL_NAME = \"abhi099k/ai-text-detector-v-n4.0\"\nN_SPLITS_CLASSICAL = 5\nN_FEATURES_CLASSICAL = 850 # Keep tuned k from v22\nMAX_LEN_LLM = 512\n# --- NEW: External Data Config ---\n# *** VERIFY THIS PATH IS CORRECT IN YOUR KAGGLE NOTEBOOK ***\nEXTERNAL_DATA_PATH = '/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv'\nMAX_EXTERNAL_SAMPLES = 20000 # Limit external data size (adjust as needed, max ~44k)\nRANDOM_SEED = 42\n\n# -------------------------------------------------------------------\n# 0. LLM INFERENCE FUNCTION (Manual Loop - Unchanged from v21)\n# -------------------------------------------------------------------\n# (Keep the get_llm_predictions function exactly as in v21/v22)\ndef get_llm_predictions(texts, model_name):\n    \"\"\"Generates predictions using the specified model via manual inference.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\"); model = None; tokenizer = None\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\"); tokenizer = AutoTokenizer.from_pretrained(model_name)\n        print(f\"Loading Model: {model_name}...\"); model = AutoModelForSequenceClassification.from_pretrained(model_name); model.to(device); model.eval()\n        print(\"Model and Tokenizer loaded successfully.\")\n        positive_label_id = 1; # Assume AI is label 1\n        if hasattr(model.config, \"label2id\"): print(f\"Model labels found: {model.config.label2id}\")\n        print(f\"Assuming positive label ID (AI/Cheating) is: {positive_label_id}\")\n    except Exception as e:\n        print(f\"Error loading model/tokenizer {model_name}: {e}\\nFalling back to 0.5.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); return np.full(len(texts), 0.5)\n    print(f\"Running LLM inference on {len(texts)} texts...\"); llm_probs = []\n    batch_size = 32\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=\"LLM Inference Batches\"):\n            batch_texts = texts[i : i + batch_size].tolist();\n            if not batch_texts: continue\n            try:\n                inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN_LLM).to(device)\n                outputs = model(**inputs); logits = outputs.logits\n                if logits.shape[-1] == 1: probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n                elif logits.shape[-1] == 2: probs_all = torch.softmax(logits, dim=-1); probs = probs_all[:, positive_label_id].cpu().numpy()\n                else: print(f\"Warning: Unexpected logit shape {logits.shape}. Assigning 0.5.\"); probs = np.full(len(batch_texts), 0.5)\n                llm_probs.extend(probs.tolist())\n            except Exception as e: print(f\"Error during LLM batch {i // batch_size}: {e}\"); llm_probs.extend([0.5] * len(batch_texts))\n            if i % (batch_size * 20) == 0: gc.collect()\n    print(\"LLM prediction feature generated.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); print(\"--- Finished LLM Inference ---\")\n    if len(llm_probs) != len(texts): print(f\"CRITICAL WARNING: Length mismatch {len(llm_probs)} vs {len(texts)}. Padding/Truncating.\"); llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)]\n    return np.array(llm_probs)\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (Handles 'llm_pred') - Unchanged\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, includes llm_pred if present.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']; self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']; self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']; self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n    def extract_base_features(self, df):\n        features = pd.DataFrame(index=df.index);\n        if 'llm_pred' in df.columns: features['llm_pred'] = df['llm_pred']\n        answers = df['answer'].fillna(''); features['text_length'] = answers.str.len(); features['word_count'] = answers.str.split().str.len(); features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6); features['sentence_count'] = answers.str.count(r'[.!?]+'); features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6); features['comma_count'] = answers.str.count(','); features['period_count'] = answers.str.count(r'\\.'); features['exclamation_count'] = answers.str.count(r'!'); features['question_count'] = answers.str.count(r'\\?'); features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6); features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split()))); features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors)); features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words)); features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators)); features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words)); features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6); features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6); features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6); features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6); features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1; features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6); features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True); return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (Handles llm_pred, Tuned Params from v22)\n# -------------------------------------------------------------------\n# (Keep the ChampionAIDetector class exactly as in v22)\nclass ChampionAIDetector:\n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats including llm_pred.\"\"\"\n    def __init__(self, n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL):\n        self.feature_extractor = ChampionFeatureExtractor(); self.n_folds = n_folds; self.n_features = n_features; self.models = {}; self.meta_model = None; self.calibrator = IsotonicRegression(out_of_bounds='clip'); self.scaler = StandardScaler(); self.tfidf_word = None; self.tfidf_char = None; self.selector = None; self.topic_columns = None; self.is_trained = False; print(f\"\\nClassical Detector initialized: {n_folds} folds, SelectKBest(k={n_features}).\")\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        # Handles potential NaN topics gracefully\n        series = series.fillna(\"Unknown_Topic\") # Use a specific name for NaN topics\n        dummies = pd.get_dummies(series, prefix='topic', dtype=int, dummy_na=False) # No dummy_na needed if filled\n        if fit_columns:\n            self.topic_columns = dummies.columns\n            # Ensure 'topic_Unknown_Topic' column exists if NaNs were present\n            if \"topic_Unknown_Topic\" not in self.topic_columns and series.astype(str).str.contains(\"Unknown_Topic\").any():\n                 self.topic_columns = self.topic_columns.append(pd.Index([\"topic_Unknown_Topic\"]))\n            print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates llm_pred.\"\"\"\n        print(\"Extracting base handcrafted + LLM features...\"); train_base_features_df = self.feature_extractor.extract_base_features(train_df); test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        fit_topic_cols = (self.topic_columns is None) or is_full_training\n        train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols)\n        test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        llm_train_feat = train_base_features_df.pop('llm_pred').values.reshape(-1, 1); llm_test_feat = test_base_features_df.pop('llm_pred').values.reshape(-1, 1)\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2500)\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1250)\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        print(\"Combining all feature sets...\"); X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(llm_train_feat)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(llm_test_feat)]).tocsr()\n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            with warnings.catch_warnings(): warnings.filterwarnings('ignore'); self.selector.fit(X_train_full, y_train)\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"\\n--- Starting Classical Ensemble Training ---\"); print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=RANDOM_SEED)\n        oof_preds = {'lgb': np.zeros(len(full_train_df)), 'cat': np.zeros(len(full_train_df)), 'ridge': np.zeros(len(full_train_df))}\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, y_train)):\n            print(f\"\\n{'='*20} Classical Fold {fold+1}/{self.n_folds} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            is_first_fold = (fold == 0); X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=is_first_fold, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=0.3, random_state=RANDOM_SEED + fold, verbose=-1, n_jobs=-1)\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=4, random_seed=RANDOM_SEED + fold, verbose=0, early_stopping_rounds=200, task_type=\"CPU\")\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.0, random_state=RANDOM_SEED + fold); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds['ridge'][val_idx] = ridge_probs\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds['ridge'][val_idx])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"Classical L1 Model OOF Scores:\"); [print(f\"  {name.upper()} OOF AUC: {roc_auc_score(y_train, preds):.8f}\") for name, preds in oof_preds.items()]\n        print(\"\\nTraining Classical L2 Meta-Model...\"); X_meta_train = np.stack(list(oof_preds.values()), axis=1)\n        self.meta_model = LogisticRegression(C=0.5, solver='liblinear', random_state=RANDOM_SEED); self.meta_model.fit(X_meta_train, y_train)\n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCLASSICAL L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\"); print(\"Training Classical Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted classical components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Classical model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Final Classical Ensemble Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final classical model training and prediction...\")\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=True)\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=0.3, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1)\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=4, random_seed=RANDOM_SEED, verbose=0, task_type=\"CPU\")\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.0, random_state=RANDOM_SEED); ridge_final.fit(X_train_full_scaled, y_train_full)\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        print(\"Applying Classical L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Classical Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n# --- (Fallback model - unchanged) ---\ndef champion_fallback():\n    \"\"\"Fallback using basic LGBM, fixed scaler.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler; from scipy.sparse import hstack, csr_matrix; from sklearn.naive_bayes import MultinomialNB\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor(); train_base_features = feature_extractor.extract_base_features(train_df.drop(columns=['llm_pred'], errors='ignore')) # Generic drop\n        test_base_features = feature_extractor.extract_base_features(test_df.drop(columns=['llm_pred'], errors='ignore'))\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns; test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1); test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english'); train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr(); y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1200, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1, reg_alpha=0.3, reg_lambda=0.3)\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\"); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f'); print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION (Loads External Data)\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Augments data, runs LLM inference, runs classical stack.\"\"\"\n    print(\"=\" * 60); print(f\"  Mercor AI Text Detection - CHAMPION v24 (External Data + {LLM_MODEL_NAME})\"); print(\"=\" * 60)\n\n    # --- Load Competition Data ---\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv');\n    test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Original training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n    train_df['source'] = 'competition' # Add source marker\n\n    # --- Load and Prepare External Data ---\n    print(f\"\\nLoading external data from: {EXTERNAL_DATA_PATH}\")\n    try:\n        external_df = pd.read_csv(EXTERNAL_DATA_PATH)\n        print(f\"Loaded external data shape: {external_df.shape}\")\n        # Keep only relevant columns and rename\n        external_df = external_df[['text', 'label', 'source']].copy()\n        external_df.rename(columns={'text': 'answer', 'label': 'is_cheating'}, inplace=True)\n        external_df['is_cheating'] = external_df['is_cheating'].astype(int)\n        # Drop duplicates based on 'answer'\n        external_df.drop_duplicates(subset=['answer'], inplace=True, keep='first')\n        # Assign generic topic\n        external_df['topic'] = 'External_DAIGT'\n        # Add placeholder IDs (optional, but good for structure)\n        external_df['id'] = [f'ext_{i}' for i in range(len(external_df))]\n\n        # Downsample external data\n        if len(external_df) > MAX_EXTERNAL_SAMPLES:\n            print(f\"Downsampling external data from {len(external_df)} to {MAX_EXTERNAL_SAMPLES}...\")\n            # Sample proportionally by class\n            n_samples_per_class = MAX_EXTERNAL_SAMPLES // 2\n            external_df = external_df.groupby('is_cheating', group_keys=False).apply(\n                lambda x: x.sample(min(len(x), n_samples_per_class), random_state=RANDOM_SEED)\n            )\n            print(f\"Downsampled external data shape: {external_df.shape}\")\n\n        # --- Combine Datasets ---\n        print(\"Combining competition and external training data...\")\n        # Select consistent columns before concat\n        cols_to_keep = ['id', 'topic', 'answer', 'is_cheating', 'source']\n        train_df_augmented = pd.concat([train_df[cols_to_keep], external_df[cols_to_keep]], ignore_index=True)\n        train_df_augmented = shuffle(train_df_augmented, random_state=RANDOM_SEED).reset_index(drop=True) # Shuffle and reset index\n        print(f\"Augmented training data shape: {train_df_augmented.shape}\")\n        print(f\"Augmented data cheating ratio: {train_df_augmented['is_cheating'].mean():.4f}\")\n\n    except FileNotFoundError: print(f\"ERROR: External data not found: {EXTERNAL_DATA_PATH}. Using competition data only.\"); train_df_augmented = train_df.copy()\n    except Exception as e: print(f\"ERROR loading external data: {e}. Using competition data only.\"); train_df_augmented = train_df.copy()\n\n    # --- Step 1: Generate LLM predictions ---\n    print(\"\\nGenerating LLM features for combined train data and original test data...\")\n    llm_train_texts = train_df_augmented['answer']\n    llm_test_texts = test_df['answer']\n    llm_preds_combined = get_llm_predictions(pd.concat([llm_train_texts, llm_test_texts]), LLM_MODEL_NAME)\n    train_df_augmented['llm_pred'] = llm_preds_combined[:len(train_df_augmented)]\n    test_df['llm_pred'] = llm_preds_combined[len(train_df_augmented):]\n    print(\"LLM feature ('llm_pred') added to dataframes.\")\n\n    # --- Step 2: Run Classical Ensemble on AUGMENTED data ---\n    classical_detector = ChampionAIDetector(n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL)\n    oof_auc_classical, oof_preds_classical = classical_detector.train_champion_ensemble(train_df_augmented)\n\n    # --- Step 3: Predict on ORIGINAL test data ---\n    print(\"\\nStarting Final Test Set Prediction using Classical Ensemble...\")\n    calibrated_proba, base_proba = classical_detector.predict_champion(train_df_augmented, test_df)\n\n    # Create submission files\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n\n    # Final Output\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\");\n    print(f\"Final Classical Ensemble OOF AUC (on augmented data): {oof_auc_classical:.8f}\")\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    start_time = time.time()\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback; traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache(); end_time = time.time()\n        print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"execution":{"iopub.status.busy":"2025-10-28T06:19:01.704916Z","iopub.execute_input":"2025-10-28T06:19:01.705157Z","iopub.status.idle":"2025-10-28T07:49:22.652218Z","shell.execute_reply.started":"2025-10-28T06:19:01.705139Z","shell.execute_reply":"2025-10-28T07:49:22.651497Z"},"jupyter":{"source_hidden":true}}},{"cell_type":"code","source":"\"\"\"\nMercor AI Text Detection - 0.99+ AUC CHAMPION VERSION\n=====================================================\n\nv25: NO External Data + v22 Pipeline + More Regularization\n- REMOVED external data augmentation (DAIGT V2) due to distribution shift.\n- Uses ONLY the original 269 competition training samples.\n- Runs the v22 pipeline:\n    - Inference feature ('llm_pred') from 'abhi099k/ai-text-detector-v-n4.0'.\n    - SelectKBest(k=850).\n    - Classical Ensemble (LGBM, CatBoost, Ridge).\n    - L2 Meta-Model (Logistic Regression).\n- INCREASED regularization slightly again (LGBM alpha/lambda=0.4, CatBoost l2=5, Meta C=0.3).\n\"\"\"\n\n# === General Imports ===\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport gc\nimport warnings\nimport time\nimport os\n\n# === Sklearn Imports ===\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.utils import shuffle # Still useful for internal shuffling if needed\n\n# === GBDT Imports ===\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n# === Hugging Face Imports ===\nprint(\"Installing/Updating transformers...\")\nos.system('pip install -q transformers torch')\nprint(\"Libraries installed.\")\ntry:\n    import torch\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n    from tqdm.auto import tqdm\n    import transformers\n    transformers.logging.set_verbosity_error()\nexcept ImportError as e: print(f\"FATAL ERROR during imports: {e}\"); raise e\n\nprint(\"All libraries imported successfully!\")\n\n# === Configuration ===\nLLM_MODEL_NAME = \"abhi099k/ai-text-detector-v-n4.0\"\nN_SPLITS_CLASSICAL = 5\nN_FEATURES_CLASSICAL = 850\nMAX_LEN_LLM = 512\nRANDOM_SEED = 42\n\n# -------------------------------------------------------------------\n# 0. LLM INFERENCE FUNCTION (Manual Loop - Unchanged)\n# -------------------------------------------------------------------\n# (Keep the get_llm_predictions function exactly as in v21/v22/v25)\ndef get_llm_predictions(texts, model_name):\n    \"\"\"Generates predictions using the specified model via manual inference.\"\"\"\n    print(f\"\\n--- Starting LLM Inference ({model_name}) ---\"); model = None; tokenizer = None\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n    try:\n        print(f\"Loading Tokenizer: {model_name}...\"); tokenizer = AutoTokenizer.from_pretrained(model_name)\n        print(f\"Loading Model: {model_name}...\"); model = AutoModelForSequenceClassification.from_pretrained(model_name); model.to(device); model.eval()\n        print(\"Model and Tokenizer loaded successfully.\")\n        positive_label_id = 1; # Assume AI is label 1\n        if hasattr(model.config, \"label2id\"): print(f\"Model labels found: {model.config.label2id}\")\n        print(f\"Assuming positive label ID (AI/Cheating) is: {positive_label_id}\")\n    except Exception as e:\n        print(f\"Error loading model/tokenizer {model_name}: {e}\\nFalling back to 0.5.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); return np.full(len(texts), 0.5)\n    print(f\"Running LLM inference on {len(texts)} texts...\"); llm_probs = []\n    batch_size = 32\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=\"LLM Inference Batches\"):\n            batch_texts = texts[i : i + batch_size].tolist();\n            if not batch_texts: continue\n            try:\n                inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN_LLM).to(device)\n                outputs = model(**inputs); logits = outputs.logits\n                if logits.shape[-1] == 1: probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n                elif logits.shape[-1] == 2: probs_all = torch.softmax(logits, dim=-1); probs = probs_all[:, positive_label_id].cpu().numpy()\n                else: print(f\"Warning: Unexpected logit shape {logits.shape}. Assigning 0.5.\"); probs = np.full(len(batch_texts), 0.5)\n                llm_probs.extend(probs.tolist())\n            except Exception as e: print(f\"Error during LLM batch {i // batch_size}: {e}\"); llm_probs.extend([0.5] * len(batch_texts))\n            if i % (batch_size * 20) == 0: gc.collect(); torch.cuda.empty_cache() # More frequent cleanup\n    print(\"LLM prediction feature generated.\"); del model; del tokenizer; gc.collect(); torch.cuda.empty_cache(); print(\"--- Finished LLM Inference ---\")\n    if len(llm_probs) != len(texts): print(f\"CRITICAL WARNING: Length mismatch {len(llm_probs)} vs {len(texts)}. Padding/Truncating.\"); llm_probs = (llm_probs + [0.5] * len(texts))[:len(texts)]\n    return np.array(llm_probs)\n\n# -------------------------------------------------------------------\n# 1. CHAMPION FEATURE EXTRACTOR (Handles 'llm_pred') - Unchanged\n# -------------------------------------------------------------------\nclass ChampionFeatureExtractor:\n    \"\"\"Extracts base features, includes llm_pred if present.\"\"\"\n    def __init__(self):\n        self.ai_connectors = ['in conclusion', 'in summary', 'furthermore', 'moreover', 'additionally', 'however', 'therefore', 'thus', 'consequently', 'as a result', 'on the other hand', 'for instance', 'for example', 'it is important to note', 'it is worth noting', 'that being said']; self.formal_words = ['utilize', 'facilitate', 'implement', 'methodology', 'paradigm', 'leverage', 'robust', 'optimal', 'enhance', 'demonstrate', 'comprehensive', 'articulate']; self.hedging_words = ['may', 'might', 'could', 'possibly', 'perhaps', 'suggests', 'seems', 'appears', 'likely']; self.passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown', 'is considered', 'was considered']\n    def extract_base_features(self, df):\n        features = pd.DataFrame(index=df.index);\n        if 'llm_pred' in df.columns: features['llm_pred'] = df['llm_pred']\n        answers = df['answer'].fillna(''); features['text_length'] = answers.str.len(); features['word_count'] = answers.str.split().str.len(); features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1e-6); features['sentence_count'] = answers.str.count(r'[.!?]+'); features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1e-6); features['comma_count'] = answers.str.count(','); features['period_count'] = answers.str.count(r'\\.'); features['exclamation_count'] = answers.str.count(r'!'); features['question_count'] = answers.str.count(r'\\?'); features['punctuation_ratio'] = (features['comma_count'] + features['period_count']) / (features['word_count'] + 1e-6); features['unique_words'] = answers.apply(lambda x: len(set(str(x).lower().split()))); features['ttr'] = features['unique_words'] / (features['word_count'] + 1e-6)\n        def count_phrases(text, phrases): text_lower = str(text).lower(); return sum(1 for phrase in phrases if phrase in text_lower)\n        features['ai_connector_count'] = answers.apply(lambda x: count_phrases(x, self.ai_connectors)); features['formal_word_count'] = answers.apply(lambda x: count_phrases(x, self.formal_words)); features['passive_voice_count'] = answers.apply(lambda x: count_phrases(x, self.passive_indicators)); features['hedging_word_count'] = answers.apply(lambda x: count_phrases(x, self.hedging_words)); features['ai_connector_ratio'] = features['ai_connector_count'] / (features['word_count'] + 1e-6); features['formal_word_ratio'] = features['formal_word_count'] / (features['word_count'] + 1e-6); features['passive_voice_ratio'] = features['passive_voice_count'] / (features['word_count'] + 1e-6); features['hedging_ratio'] = features['hedging_word_count'] / (features['word_count'] + 1e-6)\n        features['subordinate_ratio'] = answers.str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1e-6); features['paragraph_count'] = answers.str.count(r'\\n\\n') + 1; features['avg_paragraph_len'] = features['word_count'] / (features['paragraph_count'] + 1e-6); features['word_length_std'] = answers.apply(lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0)\n        # --- Added Em Dash Features ---\n        features['em_dash_count'] = answers.str.count('')\n        features['em_dash_ratio'] = features['em_dash_count'] / (features['word_count'] + 1e-6)\n        # --- End Em Dash ---\n        features.replace([np.inf, -np.inf], 0, inplace=True); features.fillna(0, inplace=True); return features\n\n# -------------------------------------------------------------------\n# 2. CHAMPION AI DETECTOR (Handles llm_pred, MORE Regularization)\n# -------------------------------------------------------------------\nclass ChampionAIDetector:\n    \"\"\"Trains L2 Stack (LGBM+CatBoost+Ridge) using SelectKBest feats including llm_pred.\"\"\"\n    def __init__(self, n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL):\n        self.feature_extractor = ChampionFeatureExtractor(); self.n_folds = n_folds; self.n_features = n_features; self.models = {}; self.meta_model = None; self.calibrator = IsotonicRegression(out_of_bounds='clip'); self.scaler = StandardScaler(); self.tfidf_word = None; self.tfidf_char = None; self.selector = None; self.topic_columns = None; self.is_trained = False; print(f\"\\nClassical Detector initialized: {n_folds} folds, SelectKBest(k={n_features}).\")\n    def _get_consistent_topic_dummies(self, series, fit_columns=False):\n        series = series.fillna(\"Unknown_Topic\"); dummies = pd.get_dummies(series, prefix='topic', dtype=int, dummy_na=False)\n        if fit_columns:\n            self.topic_columns = dummies.columns\n            if \"topic_Unknown_Topic\" not in self.topic_columns and series.astype(str).str.contains(\"Unknown_Topic\").any(): self.topic_columns = self.topic_columns.append(pd.Index([\"topic_Unknown_Topic\"]))\n            print(f\"Identified {len(self.topic_columns)} topic columns during fit.\"); return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        elif self.topic_columns is not None: return dummies.reindex(columns=self.topic_columns, fill_value=0)\n        else: raise ValueError(\"Topic columns not fitted.\")\n    def prepare_champion_features(self, train_df, test_df, is_training_fold=False, is_full_training=False):\n        \"\"\"Prepares features. Fits objects if training. Separates llm_pred.\"\"\"\n        print(\"Extracting base handcrafted + LLM features...\"); train_base_features_df = self.feature_extractor.extract_base_features(train_df); test_base_features_df = self.feature_extractor.extract_base_features(test_df)\n        print(\"Processing topic features...\")\n        fit_topic_cols = (self.topic_columns is None) or is_full_training\n        train_topic_dummies = self._get_consistent_topic_dummies(train_df['topic'], fit_columns=fit_topic_cols); test_topic_dummies = self._get_consistent_topic_dummies(test_df['topic'], fit_columns=False)\n        llm_train_feat = train_base_features_df.pop('llm_pred').values.reshape(-1, 1); llm_test_feat = test_base_features_df.pop('llm_pred').values.reshape(-1, 1)\n        train_dense_features_df = pd.concat([train_base_features_df, train_topic_dummies], axis=1); test_dense_features_df = pd.concat([test_base_features_df, test_topic_dummies], axis=1)\n        test_dense_features_df = test_dense_features_df.reindex(columns=train_dense_features_df.columns, fill_value=0)\n        if is_training_fold or is_full_training: print(\"Fitting/Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.fit_transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        else: print(\"Transforming dense features (excl. LLM)...\"); train_features_scaled = self.scaler.transform(train_dense_features_df); test_features_scaled = self.scaler.transform(test_dense_features_df)\n        if is_training_fold or is_full_training:\n            print(\"Fitting Word TF-IDF...\"); self.tfidf_word = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, sublinear_tf=True, stop_words='english', max_features=2500) # Keep moderate size\n            train_tfidf_word = self.tfidf_word.fit_transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            print(\"Fitting Char TF-IDF...\"); self.tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=3, sublinear_tf=True, max_features=1250) # Keep moderate size\n            train_tfidf_char = self.tfidf_char.fit_transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        else:\n            if not self.tfidf_word or not self.tfidf_char: raise ValueError(\"TF-IDF vectorizers not fitted.\")\n            print(\"Transforming text using fitted TF-IDF...\"); train_tfidf_word = self.tfidf_word.transform(train_df['answer'].fillna('')); test_tfidf_word = self.tfidf_word.transform(test_df['answer'].fillna(''))\n            train_tfidf_char = self.tfidf_char.transform(train_df['answer'].fillna('')); test_tfidf_char = self.tfidf_char.transform(test_df['answer'].fillna(''))\n        print(\"Combining all feature sets...\"); X_train_full = hstack([csr_matrix(train_features_scaled), train_tfidf_word, train_tfidf_char, csr_matrix(llm_train_feat)]).tocsr()\n        X_test_full = hstack([csr_matrix(test_features_scaled), test_tfidf_word, test_tfidf_char, csr_matrix(llm_test_feat)]).tocsr()\n        print(f\"Shape before feature selection: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n        if is_training_fold or is_full_training:\n            y_train = train_df['is_cheating'].values; print(f\"Fitting SelectKBest (k={self.n_features})...\"); self.selector = SelectKBest(f_classif, k=min(self.n_features, X_train_full.shape[1]))\n            with warnings.catch_warnings(): warnings.filterwarnings('ignore'); self.selector.fit(X_train_full, y_train)\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        else:\n            if not self.selector: raise ValueError(\"SelectKBest not fitted.\"); print(f\"Transforming features using fitted SelectKBest (k={self.n_features})...\")\n            X_train_selected = self.selector.transform(X_train_full); X_test_selected = self.selector.transform(X_test_full)\n        X_train_final = X_train_selected.toarray(); X_test_final = X_test_selected.toarray()\n        print(f\"Final training feature shape: {X_train_final.shape}\"); print(f\"Final testing feature shape: {X_test_final.shape}\")\n        return X_train_final, X_test_final\n\n    def train_champion_ensemble(self, full_train_df):\n        \"\"\"Trains the L2 Stacking ensemble. Fits Scaler/TFIDF/Selector on first fold.\"\"\"\n        y_train = full_train_df['is_cheating'].values\n        print(f\"\\n--- Starting Classical Ensemble Training ---\"); print(f\"Training set size: {len(full_train_df)}\"); print(f\"Positive class ratio: {y_train.mean():.6f}\")\n        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=RANDOM_SEED)\n        oof_preds = {'lgb': np.zeros(len(full_train_df)), 'cat': np.zeros(len(full_train_df)), 'ridge': np.zeros(len(full_train_df))}\n        print(\"Fitting topic columns on full training data...\"); _ = self._get_consistent_topic_dummies(full_train_df['topic'], fit_columns=True)\n        # --- Fit preprocessing ONCE before folding ---\n        print(\"\\nFitting Scalers, TFIDF, and Selector on FULL training data...\")\n        _ = self.prepare_champion_features(full_train_df, full_train_df, is_training_fold=True, is_full_training=True) # Fit preprocessing objects\n        print(\"\\nStarting K-Fold Training...\")\n\n        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, y_train)):\n            print(f\"\\n{'='*20} Classical Fold {fold+1}/{self.n_folds} {'='*20}\")\n            train_fold_df, val_fold_df = full_train_df.iloc[train_idx], full_train_df.iloc[val_idx]\n            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n            # --- Prepare features using FITTED objects ---\n            X_train_fold, X_val_fold = self.prepare_champion_features(train_fold_df, val_fold_df, is_training_fold=False, is_full_training=False)\n            print(f\"Fold {fold+1}: Train shape {X_train_fold.shape}, Val shape {X_val_fold.shape}\")\n\n            fold_seed = RANDOM_SEED + fold\n            # --- MORE Regularization ---\n            print(\"Training LightGBM...\"); lgb_model = lgb.LGBMClassifier(n_estimators=2500, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.4, reg_lambda=0.4, random_state=fold_seed, verbose=-1, n_jobs=-1)\n            lgb_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], callbacks=[lgb.early_stopping(200, verbose=False)]); oof_preds['lgb'][val_idx] = lgb_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training CatBoost...\"); cat_model = CatBoostClassifier(iterations=2500, learning_rate=0.02, depth=6, l2_leaf_reg=5, random_seed=fold_seed, verbose=0, early_stopping_rounds=200, task_type=\"CPU\")\n            cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False); oof_preds['cat'][val_idx] = cat_model.predict_proba(X_val_fold)[:, 1]\n            print(\"Training Ridge Classifier...\"); ridge_scaler = StandardScaler(); X_train_fold_scaled = ridge_scaler.fit_transform(X_train_fold); X_val_fold_scaled = ridge_scaler.transform(X_val_fold)\n            ridge_model = RidgeClassifier(alpha=1.0, random_state=fold_seed); ridge_model.fit(X_train_fold_scaled, y_train_fold); ridge_scores = ridge_model.decision_function(X_val_fold_scaled); ridge_probs = 1 / (1 + np.exp(-ridge_scores))\n            oof_preds['ridge'][val_idx] = ridge_probs\n            fold_auc_lgb = roc_auc_score(y_val_fold, oof_preds['lgb'][val_idx]); fold_auc_cat = roc_auc_score(y_val_fold, oof_preds['cat'][val_idx]); fold_auc_ridge = roc_auc_score(y_val_fold, oof_preds['ridge'][val_idx])\n            print(f\"Fold {fold+1} LGB AUC: {fold_auc_lgb:.6f}\"); print(f\"Fold {fold+1} CAT AUC: {fold_auc_cat:.6f}\"); print(f\"Fold {fold+1} RIDGE AUC: {fold_auc_ridge:.6f}\")\n        print(\"\\n\" + \"=\"*50); print(\"Classical L1 Model OOF Scores:\"); [print(f\"  {name.upper()} OOF AUC: {roc_auc_score(y_train, preds):.8f}\") for name, preds in oof_preds.items()]\n        # --- MORE Regularization ---\n        print(\"\\nTraining Classical L2 Meta-Model...\"); X_meta_train = np.stack(list(oof_preds.values()), axis=1)\n        self.meta_model = LogisticRegression(C=0.3, solver='liblinear', random_state=RANDOM_SEED); self.meta_model.fit(X_meta_train, y_train)\n        oof_ensemble_preds = self.meta_model.predict_proba(X_meta_train)[:, 1]; oof_ensemble_auc = roc_auc_score(y_train, oof_ensemble_preds)\n        print(f\"\\nCLASSICAL L2 STACKING OOF AUC: {oof_ensemble_auc:.8f}\"); print(\"Training Classical Isotonic Calibrator...\"); self.calibrator.fit(oof_ensemble_preds, y_train)\n        self.is_trained = True; return oof_ensemble_auc, oof_ensemble_preds\n\n    def predict_champion(self, full_train_df, test_df):\n        \"\"\"Generates final predictions using fitted classical components.\"\"\"\n        if not self.is_trained: raise ValueError(\"Classical model not trained!\")\n        print(\"\\n\" + \"=\"*50); print(\"Generating Final Classical Ensemble Predictions...\"); print(\"=\"*50)\n        print(\"Preparing features for final classical model training and prediction...\")\n        # Use FITTED preprocessing objects\n        X_train_full, X_test = self.prepare_champion_features(full_train_df, test_df, is_training_fold=False, is_full_training=False) # Use is_full_training=False\n        y_train_full = full_train_df['is_cheating'].values; test_preds = {}\n        # --- MORE Regularization ---\n        print(\"Training final LightGBM...\"); lgb_final = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.01, max_depth=7, num_leaves=31, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.4, reg_lambda=0.4, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1)\n        lgb_final.fit(X_train_full, y_train_full); test_preds['lgb'] = lgb_final.predict_proba(X_test)[:, 1]\n        print(\"Training final CatBoost...\"); cat_final = CatBoostClassifier(iterations=2200, learning_rate=0.02, depth=6, l2_leaf_reg=5, random_seed=RANDOM_SEED, verbose=0, task_type=\"CPU\")\n        cat_final.fit(X_train_full, y_train_full); test_preds['cat'] = cat_final.predict_proba(X_test)[:, 1]\n        print(\"Training final Ridge...\"); ridge_scaler = StandardScaler(); X_train_full_scaled = ridge_scaler.fit_transform(X_train_full); X_test_scaled = ridge_scaler.transform(X_test)\n        ridge_final = RidgeClassifier(alpha=1.0, random_state=RANDOM_SEED); ridge_final.fit(X_train_full_scaled, y_train_full)\n        ridge_scores = ridge_final.decision_function(X_test_scaled); test_preds['ridge'] = 1 / (1 + np.exp(-ridge_scores))\n        print(\"Applying Classical L2 Meta-Model...\"); X_meta_test = np.stack(list(test_preds.values()), axis=1)\n        final_proba = self.meta_model.predict_proba(X_meta_test)[:, 1]\n        print(\"Applying Classical Isotonic Calibration...\"); calibrated_proba = self.calibrator.transform(final_proba)\n        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n        return calibrated_proba, final_proba\n\n# --- (Fallback model - unchanged) ---\ndef champion_fallback():\n    \"\"\"Fallback using basic LGBM, basic features.\"\"\"\n    print(\"CRITICAL ERROR: Main pipeline failed. Using CHAMPION FALLBACK model...\")\n    try:\n        from sklearn.preprocessing import StandardScaler; from scipy.sparse import hstack, csr_matrix;\n        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n        feature_extractor = ChampionFeatureExtractor(); train_base_features = feature_extractor.extract_base_features(train_df)\n        test_base_features = feature_extractor.extract_base_features(test_df)\n        train_topic_dummies = pd.get_dummies(train_df['topic'], prefix='topic', dtype=int); fallback_topic_columns = train_topic_dummies.columns; test_topic_dummies = pd.get_dummies(test_df['topic'], prefix='topic', dtype=int).reindex(columns=fallback_topic_columns, fill_value=0)\n        train_dense_features = pd.concat([train_base_features, train_topic_dummies], axis=1); test_dense_features = pd.concat([test_base_features, test_topic_dummies], axis=1).reindex(columns=train_dense_features.columns, fill_value=0)\n        scaler = StandardScaler(); train_dense_scaled = scaler.fit_transform(train_dense_features); test_dense_scaled = scaler.transform(test_dense_features)\n        tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1, 3), stop_words='english'); train_tfidf = tfidf.fit_transform(train_df['answer'].fillna('')); test_tfidf = tfidf.transform(test_df['answer'].fillna(''))\n        X_train = hstack([csr_matrix(train_dense_scaled), train_tfidf]).tocsr(); X_test = hstack([csr_matrix(test_dense_scaled), test_tfidf]).tocsr(); y_train = train_df['is_cheating']\n        model = lgb.LGBMClassifier(n_estimators=1000, learning_rate=0.01, max_depth=7, num_leaves=63, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1, reg_alpha=0.1, reg_lambda=0.1) # Basic params\n        model.fit(X_train, y_train); test_proba = model.predict_proba(X_test.toarray())[:, 1]\n        submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': test_proba}); submission.to_csv('submission.csv', index=False, float_format='%.10f')\n        print(\"Fallback submission.csv created successfully.\"); return submission\n    except Exception as e:\n        print(f\"Fallback model ALSO failed: {e}\"); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv'); submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': 0.5}); submission.to_csv('submission.csv', index=False, float_format='%.10f'); print(\"CRITICAL: Created dummy submission.csv with 0.5 probability.\"); return submission\n\n# -------------------------------------------------------------------\n# 4. MAIN EXECUTION (No External Data)\n# -------------------------------------------------------------------\ndef champion_main():\n    \"\"\"Main function: Runs LLM inference feature gen + classical stack on original data.\"\"\"\n    print(\"=\" * 60); print(f\"  Mercor AI Text Detection - CHAMPION v25 (No External Data + More Regularization)\"); print(\"=\" * 60)\n    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv'); test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n    print(f\"Training data shape: {train_df.shape}\"); print(f\"Test data shape: {test_df.shape}\")\n    train_df['answer'] = train_df['answer'].fillna(''); test_df['answer'] = test_df['answer'].fillna('')\n    # --- Step 1: Generate LLM predictions on ORIGINAL train/test ---\n    all_texts = pd.concat([train_df['answer'], test_df['answer']])\n    llm_preds = get_llm_predictions(all_texts, LLM_MODEL_NAME)\n    train_df['llm_pred'] = llm_preds[:len(train_df)]; test_df['llm_pred'] = llm_preds[len(train_df):]\n    print(\"LLM feature ('llm_pred') added to dataframes.\")\n    # --- Step 2: Run Classical Ensemble ---\n    classical_detector = ChampionAIDetector(n_folds=N_SPLITS_CLASSICAL, n_features=N_FEATURES_CLASSICAL)\n    oof_auc_classical, oof_preds_classical = classical_detector.train_champion_ensemble(train_df)\n    print(\"\\nStarting Final Test Set Prediction using Classical Ensemble...\")\n    calibrated_proba, base_proba = classical_detector.predict_champion(train_df, test_df)\n    # Create submission files\n    submission_calibrated = pd.DataFrame({'id': test_df['id'], 'is_cheating': calibrated_proba}); submission_base = pd.DataFrame({'id': test_df['id'], 'is_cheating': base_proba})\n    submission_calibrated.to_csv('submission.csv', index=False, float_format='%.10f'); submission_base.to_csv('submission_base_uncalibrated.csv', index=False, float_format='%.10f')\n    # Final Output\n    print(\"\\n\" + \"=\"*60); print(\"CHAMPION PIPELINE COMPLETED SUCCESSFULLY!\");\n    print(f\"Final Classical Ensemble OOF AUC (NO external data): {oof_auc_classical:.8f}\") # Added note\n    print(\"\\nSubmission files created:\"); print(f\"  1. submission.csv (RECOMMENDED)\"); print(f\"  2. submission_base_uncalibrated.csv\")\n    print(f\"\\nFinal 'submission.csv' prediction statistics:\"); print(f\"  Min: {calibrated_proba.min():.6f}\"); print(f\"  Max: {calibrated_proba.max():.6f}\"); print(f\"  Mean: {calibrated_proba.mean():.6f}\"); print(f\"  Median: {np.median(calibrated_proba):.6f}\")\n    print(\"\\nTop 10 Predictions:\"); print(submission_calibrated.head(10).to_string(index=False)); print(\"=\" * 60)\n\n# --- Run the Champion Pipeline ---\nif __name__ == \"__main__\":\n    start_time = time.time()\n    try:\n        gc.collect(); torch.cuda.empty_cache()\n        champion_main()\n    except Exception as e:\n        print(f\"\\n!!! AN ERROR OCCURRED IN THE MAIN PIPELINE !!!: {e}\")\n        import traceback; traceback.print_exc()\n        champion_fallback()\n    finally:\n        gc.collect(); torch.cuda.empty_cache(); end_time = time.time()\n        print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T16:20:58.566973Z","iopub.execute_input":"2025-10-29T16:20:58.567204Z","iopub.status.idle":"2025-10-29T16:26:31.561594Z","shell.execute_reply.started":"2025-10-29T16:20:58.567185Z","shell.execute_reply":"2025-10-29T16:26:31.560946Z"}},"outputs":[{"name":"stdout","text":"Installing/Updating transformers...\n    363.4/363.4 MB 4.7 MB/s eta 0:00:00\n    13.8/13.8 MB 101.1 MB/s eta 0:00:00\n    24.6/24.6 MB 80.1 MB/s eta 0:00:00\n    883.7/883.7 kB 45.0 MB/s eta 0:00:00\n    664.8/664.8 MB 2.5 MB/s eta 0:00:00\n    211.5/211.5 MB 5.5 MB/s eta 0:00:00\n    56.3/56.3 MB 30.7 MB/s eta 0:00:00\n    127.9/127.9 MB 13.3 MB/s eta 0:00:00\n    207.5/207.5 MB 2.1 MB/s eta 0:00:00\n    21.1/21.1 MB 83.4 MB/s eta 0:00:00\n    566.1/566.1 kB 33.4 MB/s eta 0:00:00\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n","output_type":"stream"},{"name":"stdout","text":"Libraries installed.\nAll libraries imported successfully!\n============================================================\n  Mercor AI Text Detection - CHAMPION v25 (No External Data + More Regularization)\n============================================================\nTraining data shape: (269, 4)\nTest data shape: (264, 3)\n\n--- Starting LLM Inference (abhi099k/ai-text-detector-v-n4.0) ---\nUsing device: cuda\nLoading Tokenizer: abhi099k/ai-text-detector-v-n4.0...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a88998ece224782826b8a6b25cc0e0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaac3ec9cfc943269bba5d5c5ee34ad7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97654d88184f4303925fb7f624f3f07e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"808a6cef3b914aa2bd06f98535ee6041"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"603dbcddf33746c0aafdb146de58e559"}},"metadata":{}},{"name":"stdout","text":"Loading Model: abhi099k/ai-text-detector-v-n4.0...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/888 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baf015526064491e8be43d62d1712d5f"}},"metadata":{}},{"name":"stderr","text":"2025-10-29 16:22:32.727305: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761754952.946672      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761754953.008324      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"416748ee2b9e4c999a7bf4e5efc06696"}},"metadata":{}},{"name":"stdout","text":"Model and Tokenizer loaded successfully.\nModel labels found: {'LABEL_0': 0, 'LABEL_1': 1}\nAssuming positive label ID (AI/Cheating) is: 1\nRunning LLM inference on 533 texts...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"LLM Inference Batches:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43acfd22ad1c42ad908116b4b5483366"}},"metadata":{}},{"name":"stdout","text":"LLM prediction feature generated.\n--- Finished LLM Inference ---\nLLM feature ('llm_pred') added to dataframes.\n\nClassical Detector initialized: 5 folds, SelectKBest(k=850).\n\n--- Starting Classical Ensemble Training ---\nTraining set size: 269\nPositive class ratio: 0.546468\nFitting topic columns on full training data...\nIdentified 268 topic columns during fit.\n\nFitting Scalers, TFIDF, and Selector on FULL training data...\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nIdentified 268 topic columns during fit.\nFitting/Transforming dense features (excl. LLM)...\nFitting Word TF-IDF...\nFitting Char TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(269, 3676), Test=(269, 3676)\nFitting SelectKBest (k=850)...\nFinal training feature shape: (269, 850)\nFinal testing feature shape: (269, 850)\n\nStarting K-Fold Training...\n\n==================== Classical Fold 1/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3676), Test=(54, 3676)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 1: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nFold 1 LGB AUC: 0.990278\nFold 1 CAT AUC: 0.993056\nFold 1 RIDGE AUC: 0.983333\n\n==================== Classical Fold 2/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3676), Test=(54, 3676)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 2: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nFold 2 LGB AUC: 0.987500\nFold 2 CAT AUC: 0.994444\nFold 2 RIDGE AUC: 0.998611\n\n==================== Classical Fold 3/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3676), Test=(54, 3676)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 3: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nFold 3 LGB AUC: 0.980690\nFold 3 CAT AUC: 0.971034\nFold 3 RIDGE AUC: 0.983448\n\n==================== Classical Fold 4/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(215, 3676), Test=(54, 3676)\nFinal training feature shape: (215, 850)\nFinal testing feature shape: (54, 850)\nFold 4: Train shape (215, 850), Val shape (54, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nFold 4 LGB AUC: 0.976552\nFold 4 CAT AUC: 0.962759\nFold 4 RIDGE AUC: 0.971034\n\n==================== Classical Fold 5/5 ====================\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(216, 3676), Test=(53, 3676)\nFinal training feature shape: (216, 850)\nFinal testing feature shape: (53, 850)\nFold 5: Train shape (216, 850), Val shape (53, 850)\nTraining LightGBM...\nTraining CatBoost...\nTraining Ridge Classifier...\nFold 5 LGB AUC: 0.995690\nFold 5 CAT AUC: 0.995690\nFold 5 RIDGE AUC: 0.984195\n\n==================================================\nClassical L1 Model OOF Scores:\n  LGB OOF AUC: 0.98176648\n  CAT OOF AUC: 0.98427568\n  RIDGE OOF AUC: 0.98076280\n\nTraining Classical L2 Meta-Model...\n\nCLASSICAL L2 STACKING OOF AUC: 0.98812312\nTraining Classical Isotonic Calibrator...\n\nStarting Final Test Set Prediction using Classical Ensemble...\n\n==================================================\nGenerating Final Classical Ensemble Predictions...\n==================================================\nPreparing features for final classical model training and prediction...\nExtracting base handcrafted + LLM features...\nProcessing topic features...\nTransforming dense features (excl. LLM)...\nTransforming text using fitted TF-IDF...\nCombining all feature sets...\nShape before feature selection: Train=(269, 3676), Test=(264, 3676)\nFinal training feature shape: (269, 850)\nFinal testing feature shape: (264, 850)\nTraining final LightGBM...\nTraining final CatBoost...\nTraining final Ridge...\nApplying Classical L2 Meta-Model...\nApplying Classical Isotonic Calibration...\n\n============================================================\nCHAMPION PIPELINE COMPLETED SUCCESSFULLY!\nFinal Classical Ensemble OOF AUC (NO external data): 0.98812312\n\nSubmission files created:\n  1. submission.csv (RECOMMENDED)\n  2. submission_base_uncalibrated.csv\n\nFinal 'submission.csv' prediction statistics:\n  Min: 0.001000\n  Max: 0.999000\n  Mean: 0.557748\n  Median: 0.970588\n\nTop 10 Predictions:\n              id  is_cheating\nscr_81822029c661     0.166667\nscr_52efb19e0ea9     0.999000\nscr_8fc0f33c559e     0.166667\nscr_bac3f5d3aa12     0.333333\nscr_adfbe009984d     0.001000\nscr_9e08ece19277     0.999000\nscr_0e34514f3cd4     0.970588\nscr_b10d808b5528     0.999000\nscr_2024f1e7bf94     0.714286\nscr_aa0b11f10fff     0.001000\n============================================================\n\nTotal execution time: 4.08 minutes\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"d=pd.read_csv(\"/kaggle/working/submission.csv\")\nd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T14:31:09.214437Z","iopub.execute_input":"2025-10-29T14:31:09.214726Z","iopub.status.idle":"2025-10-29T14:31:09.233294Z","shell.execute_reply.started":"2025-10-29T14:31:09.214707Z","shell.execute_reply":"2025-10-29T14:31:09.232709Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                   id  is_cheating\n0    scr_81822029c661     0.996701\n1    scr_52efb19e0ea9     0.999000\n2    scr_8fc0f33c559e     0.494624\n3    scr_bac3f5d3aa12     0.137097\n4    scr_adfbe009984d     0.015537\n..                ...          ...\n259  scr_9497704e40c5     0.494624\n260  scr_df97a5fa0b8f     0.997403\n261  scr_6175540a0c81     0.927039\n262  scr_fa79a8d5de1c     0.935484\n263  scr_8f2dde6f6734     0.999000\n\n[264 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>is_cheating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>scr_81822029c661</td>\n      <td>0.996701</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scr_52efb19e0ea9</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>scr_8fc0f33c559e</td>\n      <td>0.494624</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>scr_bac3f5d3aa12</td>\n      <td>0.137097</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>scr_adfbe009984d</td>\n      <td>0.015537</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>scr_9497704e40c5</td>\n      <td>0.494624</td>\n    </tr>\n    <tr>\n      <th>260</th>\n      <td>scr_df97a5fa0b8f</td>\n      <td>0.997403</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>scr_6175540a0c81</td>\n      <td>0.927039</td>\n    </tr>\n    <tr>\n      <th>262</th>\n      <td>scr_fa79a8d5de1c</td>\n      <td>0.935484</td>\n    </tr>\n    <tr>\n      <th>263</th>\n      <td>scr_8f2dde6f6734</td>\n      <td>0.999000</td>\n    </tr>\n  </tbody>\n</table>\n<p>264 rows  2 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}